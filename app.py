import streamlit as st
import pandas as pd
import io
import json
from datetime import datetime
import time
import logging
from typing import Optional, Dict, Any, List
import hashlib
import pickle
import traceback
from contextlib import contextmanager
from qcloud_cos import CosConfig, CosS3Client
from qcloud_cos.cos_exception import CosServiceError, CosClientError
import openpyxl

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é—¨åº—æŠ¥è¡¨æŸ¥è¯¢ç³»ç»Ÿ", 
    page_icon="ğŸ“Š",
    layout="wide"
)

# ç³»ç»Ÿé…ç½®
ADMIN_PASSWORD = "admin123"
MAX_RETRIES = 3
RETRY_DELAY = 1
CACHE_DURATION = 300  # ç¼“å­˜5åˆ†é’Ÿ

# CSSæ ·å¼
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 2rem;
    }
    .store-info {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .admin-panel {
        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #fdcb6e;
        margin: 1rem 0;
    }
    .receivable-positive {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
        color: #721c24;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #f093fb;
        margin: 1rem 0;
        text-align: center;
    }
    .receivable-negative {
        background: linear-gradient(135deg, #a8edea 0%, #d299c2 100%);
        color: #0c4128;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #48cab2;
        margin: 1rem 0;
        text-align: center;
    }
    .status-success {
        background: #d4edda;
        color: #155724;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
        margin: 0.5rem 0;
    }
    .status-error {
        background: #f8d7da;
        color: #721c24;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #f5c6cb;
        margin: 0.5rem 0;
    }
    .status-warning {
        background: #fff3cd;
        color: #856404;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

class CosOperationError(Exception):
    """è…¾è®¯äº‘COSæ“ä½œå¼‚å¸¸"""
    pass

class DataProcessingError(Exception):
    """æ•°æ®å¤„ç†å¼‚å¸¸"""
    pass

@contextmanager
def error_handler(operation_name: str):
    """é€šç”¨é”™è¯¯å¤„ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    try:
        yield
    except Exception as e:
        logger.error(f"{operation_name} å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        st.error(f"âŒ {operation_name} å¤±è´¥: {str(e)}")
        raise

def retry_operation(func, *args, max_retries=MAX_RETRIES, delay=RETRY_DELAY, **kwargs):
    """é‡è¯•æ“ä½œè£…é¥°å™¨"""
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if attempt == max_retries - 1:
                logger.error(f"æ“ä½œå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {str(e)}")
                raise
            logger.warning(f"æ“ä½œå¤±è´¥ï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•: {str(e)}")
            time.sleep(delay * (attempt + 1))

def get_cache_key(operation: str, params: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    return hashlib.md5(f"{operation}_{params}".encode()).hexdigest()

def set_cache(key: str, data: Any, duration: int = CACHE_DURATION):
    """è®¾ç½®ç¼“å­˜"""
    try:
        cache_data = {
            'data': data,
            'timestamp': time.time(),
            'duration': duration
        }
        st.session_state[f"cache_{key}"] = cache_data
        logger.info(f"ç¼“å­˜å·²è®¾ç½®: {key}")
    except Exception as e:
        logger.warning(f"è®¾ç½®ç¼“å­˜å¤±è´¥: {str(e)}")

def get_cache(key: str) -> Optional[Any]:
    """è·å–ç¼“å­˜"""
    try:
        cache_key = f"cache_{key}"
        if cache_key in st.session_state:
            cache_data = st.session_state[cache_key]
            if time.time() - cache_data['timestamp'] < cache_data['duration']:
                logger.info(f"ç¼“å­˜å‘½ä¸­: {key}")
                return cache_data['data']
            else:
                del st.session_state[cache_key]
                logger.info(f"ç¼“å­˜è¿‡æœŸ: {key}")
    except Exception as e:
        logger.warning(f"è·å–ç¼“å­˜å¤±è´¥: {str(e)}")
    return None

def validate_cos_config(config: dict) -> bool:
    """éªŒè¯è…¾è®¯äº‘COSé…ç½®"""
    required_keys = ["region", "secret_id", "secret_key", "bucket_name", "permissions_file"]
    for key in required_keys:
        if key not in config or not config[key]:
            logger.error(f"COSé…ç½®ç¼ºå°‘å¿…è¦å‚æ•°: {key}")
            return False
    return True

@st.cache_resource(show_spinner="è¿æ¥è…¾è®¯äº‘å­˜å‚¨...")
def get_cos_client():
    """è·å–è…¾è®¯äº‘COSå®¢æˆ·ç«¯ - ä½¿ç”¨ç¼“å­˜"""
    try:
        if "tencent_cloud" not in st.secrets:
            raise CosOperationError("æœªæ‰¾åˆ°è…¾è®¯äº‘é…ç½®ï¼Œè¯·æ£€æŸ¥ secrets.toml æ–‡ä»¶")
        
        cos_config = st.secrets["tencent_cloud"]
        
        # éªŒè¯é…ç½®
        if not validate_cos_config(cos_config):
            raise CosOperationError("è…¾è®¯äº‘é…ç½®ä¸å®Œæ•´")
        
        config = CosConfig(
            Region=cos_config["region"],
            SecretId=cos_config["secret_id"],
            SecretKey=cos_config["secret_key"],
            Scheme='https'  # ä½¿ç”¨HTTPSåè®®
        )
        
        client = CosS3Client(config)
        
        # æµ‹è¯•è¿æ¥
        try:
            client.head_bucket(Bucket=cos_config["bucket_name"])
            logger.info("è…¾è®¯äº‘COSå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸï¼Œè¿æ¥æµ‹è¯•é€šè¿‡")
        except CosServiceError as e:
            logger.error(f"COSè¿æ¥æµ‹è¯•å¤±è´¥: {e.get_error_code()} - {e.get_error_msg()}")
            raise CosOperationError(f"å­˜å‚¨æ¡¶è¿æ¥å¤±è´¥: {e.get_error_msg()}")
        
        return client, cos_config["bucket_name"], cos_config["permissions_file"]
    
    except Exception as e:
        logger.error(f"è…¾è®¯äº‘COSå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {str(e)}")
        raise CosOperationError(f"è¿æ¥å¤±è´¥: {str(e)}")

def safe_cos_operation(operation_func, *args, **kwargs):
    """å®‰å…¨çš„COSæ“ä½œ"""
    return retry_operation(operation_func, *args, **kwargs)

def safe_format_number(value, default_value=0):
    """å®‰å…¨çš„æ•°å­—æ ¼å¼åŒ–å‡½æ•°"""
    try:
        if isinstance(value, str):
            # å°è¯•è½¬æ¢å­—ç¬¦ä¸²ä¸ºæ•°å­—
            if value.isdigit():
                return int(value)
            else:
                return float(value)
        elif isinstance(value, (int, float)):
            return value
        else:
            return default_value
    except (ValueError, TypeError):
        return default_value

def create_excel_buffer(data, sheet_name="æ•°æ®", file_type="general"):
    """ç»Ÿä¸€çš„Excelæ–‡ä»¶åˆ›å»ºå‡½æ•°"""
    try:
        if isinstance(data, pd.DataFrame):
            df = data
        elif isinstance(data, list) and len(data) > 0:
            # å¦‚æœæ˜¯åˆ—è¡¨æ•°æ®ï¼Œè½¬æ¢ä¸ºDataFrame
            if isinstance(data[0], list):
                # ç¬¬ä¸€è¡Œä½œä¸ºè¡¨å¤´
                df = pd.DataFrame(data[1:], columns=data[0])
            else:
                df = pd.DataFrame(data)
        else:
            raise ValueError("æ•°æ®æ ¼å¼ä¸æ”¯æŒ")
        
        # åˆ›å»ºExcelç¼“å†²åŒº
        excel_buffer = io.BytesIO()
        
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            # å·¥ä½œè¡¨åé™åˆ¶31å­—ç¬¦
            safe_sheet_name = sheet_name[:31] if len(sheet_name) <= 31 else sheet_name[:28] + "..."
            df.to_excel(writer, index=False, sheet_name=safe_sheet_name)
        
        excel_content = excel_buffer.getvalue()
        
        logger.info(f"Excelæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—, å¤§å°: {len(excel_content)} å­—èŠ‚")
        
        return excel_content, len(df), len(df.columns)
        
    except Exception as e:
        logger.error(f"Excelæ–‡ä»¶åˆ›å»ºå¤±è´¥: {str(e)}")
        raise DataProcessingError(f"Excelæ–‡ä»¶åˆ›å»ºå¤±è´¥: {str(e)}")

def _upload_cos_file_with_integrity_check(cos_client, bucket_name, file_key, excel_content, content_type, metadata):
    """
    è¾…åŠ©å‡½æ•°ï¼šä¸Šä¼ æ–‡ä»¶åˆ°COSå¹¶éªŒè¯å®Œæ•´æ€§ã€‚
    å¦‚æœéªŒè¯å¤±è´¥ï¼Œåˆ™æŠ›å‡ºIOErrorã€‚
    """
    # ä¸Šä¼ æ–‡ä»¶
    cos_client.put_object(
        Bucket=bucket_name,
        Body=excel_content,
        Key=file_key,
        ContentType=content_type,
        Metadata=metadata
    )
    
    # ç«‹å³éªŒè¯ä¸Šä¼ ç»“æœ
    head_response = cos_client.head_object(Bucket=bucket_name, Key=file_key)
    uploaded_size = safe_format_number(head_response.get('Content-Length', 0), 0)
    
    if uploaded_size != len(excel_content):
        raise IOError(f"ä¸Šä¼ æ–‡ä»¶å¤§å°ä¸åŒ¹é…! é¢„æœŸ: {len(excel_content)}, å®é™…: {uploaded_size}. è¯·é‡è¯•ä¸Šä¼ ã€‚")
    
    # è¿›ä¸€æ­¥éªŒè¯ï¼šä¸‹è½½å‰å‡ ä¸ªå­—èŠ‚æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨
    verify_response = cos_client.get_object(Bucket=bucket_name, Key=file_key, Range='bytes=0-1023')
    verify_content = verify_response['Body'].read()
    
    if verify_content[:2] != b'PK':
        raise IOError("ä¸Šä¼ æ–‡ä»¶å¤´éƒ¨éªŒè¯å¤±è´¥ï¼Œæ–‡ä»¶å¯èƒ½æŸåã€‚")
    
    return True

def unified_upload_to_cos(cos_client, bucket_name: str, file_key: str, excel_content: bytes, 
                         metadata: Dict[str, str], file_type: str = "file") -> bool:
    """ç»Ÿä¸€çš„COSä¸Šä¼ å‡½æ•° - ä½¿ç”¨é‡è¯•æœºåˆ¶ç¡®ä¿å®Œæ•´ä¸Šä¼ """
    try:
        logger.info(f"å¼€å§‹ä¸Šä¼  {file_type}: {file_key}, å¤§å°: {len(excel_content)} å­—èŠ‚")
        
        # æ˜¾ç¤ºä¸Šä¼ ä¿¡æ¯
        st.info(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼  {file_type}: {file_key}")
        st.write(f"- æ–‡ä»¶å¤§å°: {len(excel_content):,} å­—èŠ‚")
        
        # ä½¿ç”¨retry_operationç¡®ä¿å®Œæ•´ä¸Šä¼ 
        with st.spinner("ä¸Šä¼ ä¸­..."):
            upload_success = retry_operation(
                _upload_cos_file_with_integrity_check,
                cos_client, bucket_name, file_key, excel_content, 
                'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                metadata,
                max_retries=MAX_RETRIES,
                delay=RETRY_DELAY
            )
        
        if upload_success:
            st.success(f"âœ… ä¸Šä¼ éªŒè¯æˆåŠŸ: {len(excel_content):,} å­—èŠ‚")
            logger.info(f"ä¸Šä¼ æˆåŠŸ: {file_key}")
            return True
        else:
            st.error(f"âŒ æ–‡ä»¶ '{file_key}' ä¸Šä¼ å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œç»è¿‡ {MAX_RETRIES} æ¬¡é‡è¯•ä»æ— æ³•æˆåŠŸã€‚")
            logger.error(f"æ–‡ä»¶ '{file_key}' ç»è¿‡ {MAX_RETRIES} æ¬¡é‡è¯•ä»æ— æ³•ä¸Šä¼ å®Œæ•´")
            return False
        
    except Exception as e:
        logger.error(f"ä¸Šä¼ å¤±è´¥: {str(e)}")
        st.error(f"âŒ ä¸Šä¼ å¤±è´¥: {str(e)}")
        return False

def _fetch_cos_file_content_with_integrity_check(cos_client, bucket_name, key, expected_size):
    """
    è¾…åŠ©å‡½æ•°ï¼šä»COSè·å–æ–‡ä»¶å†…å®¹ï¼Œå¹¶æ£€æŸ¥ä¸‹è½½å†…å®¹çš„å®Œæ•´æ€§ã€‚
    å¦‚æœå¤§å°ä¸åŒ¹é…ï¼Œåˆ™æŠ›å‡ºIOErrorã€‚
    """
    file_response = cos_client.get_object(Bucket=bucket_name, Key=key)
    excel_content = file_response['Body'].read()
    
    actual_size = len(excel_content)
    if actual_size != expected_size:
        raise IOError(f"ä¸‹è½½æ–‡ä»¶å¤§å°ä¸åŒ¹é…! é¢„æœŸ: {expected_size}, å®é™…: {actual_size}. è¯·é‡è¯•ä¸‹è½½ã€‚")
    
    return excel_content

def unified_download_from_cos(cos_client, bucket_name: str, file_key: str, file_type: str = "file") -> Optional[bytes]:
    """ç»Ÿä¸€çš„COSä¸‹è½½å‡½æ•° - ä½¿ç”¨é‡è¯•æœºåˆ¶ç¡®ä¿å®Œæ•´ä¸‹è½½"""
    try:
        logger.info(f"å¼€å§‹ä¸‹è½½ {file_type}: {file_key}")
        
        # 1. è·å–æ–‡ä»¶å…ƒæ•°æ®
        head_response = cos_client.head_object(Bucket=bucket_name, Key=file_key)
        expected_size = safe_format_number(head_response.get('Content-Length', 0), 0)
        content_type = head_response.get('Content-Type', '')
        last_modified = head_response.get('Last-Modified', '')
        
        st.info(f"ğŸ“¥ å‡†å¤‡ä¸‹è½½ {file_type}: {file_key}")
        st.write(f"- é¢„æœŸå¤§å°: {expected_size:,} å­—èŠ‚")
        st.write(f"- Content-Type: {content_type}")
        st.write(f"- æœ€åä¿®æ”¹: {last_modified}")
        
        # 2. ä½¿ç”¨retry_operationç¡®ä¿å®Œæ•´ä¸‹è½½
        with st.spinner("ä¸‹è½½ä¸­..."):
            excel_content = retry_operation(
                _fetch_cos_file_content_with_integrity_check,
                cos_client, bucket_name, file_key, expected_size,
                max_retries=MAX_RETRIES,
                delay=RETRY_DELAY
            )
        
        if excel_content is None:
            st.error(f"âŒ æ–‡ä»¶ '{file_key}' ä¸‹è½½å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–COSæ–‡ä»¶ã€‚")
            logger.error(f"æ–‡ä»¶ '{file_key}' ç»è¿‡ {MAX_RETRIES} æ¬¡é‡è¯•ä»æ— æ³•è·å–å®Œæ•´å†…å®¹ã€‚")
            return None
        
        # 3. éªŒè¯ä¸‹è½½ç»“æœ
        actual_size = len(excel_content)
        st.success(f"âœ… ä¸‹è½½å®Œæˆ: {actual_size:,} å­—èŠ‚")
        
        # éªŒè¯æ–‡ä»¶å¤´éƒ¨
        if len(excel_content) >= 2 and excel_content[:2] == b'PK':
            st.success("âœ… æ–‡ä»¶æ ¼å¼éªŒè¯é€šè¿‡")
            logger.info(f"ä¸‹è½½æˆåŠŸ: {file_key}, å¤§å°: {actual_size} å­—èŠ‚")
            return excel_content
        else:
            st.error("âŒ æ–‡ä»¶æ ¼å¼éªŒè¯å¤±è´¥")
            logger.warning(f"æ–‡ä»¶å¤´éƒ¨éªŒè¯å¤±è´¥: {excel_content[:4].hex() if len(excel_content) >= 4 else 'N/A'}")
            return None
            
    except Exception as e:
        logger.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
        st.error(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        return None

def unified_excel_parser(excel_content: bytes, file_type: str = "file") -> Optional[pd.DataFrame]:
    """ç»Ÿä¸€çš„Excelè§£æå‡½æ•°"""
    try:
        st.info(f"ğŸ” è§£æExcelæ–‡ä»¶...")
        
        # åˆ›å»ºå­—èŠ‚æµ
        excel_buffer = io.BytesIO(excel_content)
        excel_buffer.seek(0)
        
        # è§£æExcel
        df = pd.read_excel(excel_buffer, engine='openpyxl')
        
        st.success(f"âœ… Excelè§£ææˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
        
        # æ˜¾ç¤ºåˆ—å
        st.write(f"**åˆ—å**: {df.columns.tolist()}")
        
        # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        if len(df) > 0:
            with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰", expanded=False):
                st.dataframe(df.head(), use_container_width=True)
        
        logger.info(f"Excelè§£ææˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
        return df
        
    except Exception as e:
        logger.error(f"Excelè§£æå¤±è´¥: {str(e)}")
        st.error(f"âŒ Excelè§£æå¤±è´¥: {str(e)}")
        
        # æä¾›è¯¦ç»†é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        st.write(f"**é”™è¯¯ç±»å‹**: {error_type}")
        st.write(f"**é”™è¯¯è¯¦æƒ…**: {str(e)}")
        
        return None

def unified_file_processor(cos_client, bucket_name: str, file_key: str, file_type: str = "file") -> Optional[pd.DataFrame]:
    """ç»Ÿä¸€çš„æ–‡ä»¶å¤„ç†å‡½æ•° - ä¸‹è½½å’Œè§£æ"""
    try:
        st.subheader(f"ğŸ” {file_type} å¤„ç†æµç¨‹")
        
        # 1. ä¸‹è½½æ–‡ä»¶
        excel_content = unified_download_from_cos(cos_client, bucket_name, file_key, file_type)
        
        if excel_content is None:
            return None
        
        # 2. è§£æExcel
        df = unified_excel_parser(excel_content, file_type)
        
        return df
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        st.error(f"âŒ {file_type} å¤„ç†å¤±è´¥: {str(e)}")
        return None

def unified_excel_reader(cos_client, bucket_name: str, file_key: str, file_type: str = "unknown") -> Optional[pd.DataFrame]:
    """ç»Ÿä¸€çš„Excelæ–‡ä»¶è¯»å–å™¨ - ç”¨äºæƒé™è¡¨å’ŒæŠ¥è¡¨æ–‡ä»¶"""
    try:
        logger.info(f"å¼€å§‹è¯»å– {file_type} æ–‡ä»¶: {file_key}")
        
        # 1. è·å–æ–‡ä»¶å…ƒæ•°æ®
        try:
            head_response = cos_client.head_object(Bucket=bucket_name, Key=file_key)
            file_size_raw = head_response.get('Content-Length', 0)
            content_type = head_response.get('Content-Type', '')
            last_modified = head_response.get('Last-Modified', '')
            
            # å®‰å…¨æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
            file_size = safe_format_number(file_size_raw, 0)
            
            logger.info(f"æ–‡ä»¶å…ƒæ•°æ® - å¤§å°: {file_size} å­—èŠ‚, ç±»å‹: {content_type}, ä¿®æ”¹æ—¶é—´: {last_modified}")
            
            # åœ¨Streamlitä¸­æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
            st.info(f"ğŸ“ {file_type} æ–‡ä»¶ä¿¡æ¯: {file_key}")
            st.write(f"- æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚")
            st.write(f"- Content-Type: {content_type}")
            st.write(f"- æœ€åä¿®æ”¹: {last_modified}")
            
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å…ƒæ•°æ®å¤±è´¥: {str(e)}")
            st.error(f"âŒ è·å–æ–‡ä»¶ {file_key} çš„å…ƒæ•°æ®å¤±è´¥: {str(e)}")
            return None
        
        # 2. ä¸‹è½½æ–‡ä»¶å†…å®¹
        try:
            response = cos_client.get_object(Bucket=bucket_name, Key=file_key)
            raw_content = response['Body'].read()
            
            actual_size = len(raw_content)
            logger.info(f"ä¸‹è½½å®Œæˆ - å®é™…å¤§å°: {actual_size} å­—èŠ‚")
            
            # éªŒè¯ä¸‹è½½å¤§å°
            if actual_size != file_size:
                logger.warning(f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…! é¢„æœŸ: {file_size}, å®é™…: {actual_size}")
                st.warning(f"âš ï¸ æ–‡ä»¶å¤§å°ä¸åŒ¹é…! é¢„æœŸ: {file_size:,}, å®é™…: {actual_size:,}")
            
            # æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨ï¼ˆExcelæ–‡ä»¶åº”è¯¥ä»¥PKå¼€å¤´ï¼‰
            if len(raw_content) >= 2:
                file_header = raw_content[:2]
                hex_header = file_header.hex().upper()
                logger.info(f"æ–‡ä»¶å¤´éƒ¨: {hex_header}")
                
                # Excelæ–‡ä»¶åº”è¯¥ä»¥PKå¼€å¤´ï¼ˆzipæ ¼å¼ï¼‰
                if file_header != b'PK':
                    logger.error(f"æ–‡ä»¶å¤´éƒ¨ä¸æ˜¯Excelæ ¼å¼! å¤´éƒ¨: {hex_header}")
                    st.error(f"âŒ æ–‡ä»¶å¤´éƒ¨ä¸æ˜¯Excelæ ¼å¼! å¤´éƒ¨: {hex_header}")
                    
                    # æ˜¾ç¤ºæ–‡ä»¶å‰64ä¸ªå­—èŠ‚ç”¨äºè°ƒè¯•
                    preview_bytes = raw_content[:64]
                    st.code(f"æ–‡ä»¶å‰64å­—èŠ‚: {preview_bytes.hex()}")
                    
                    # å°è¯•ä»¥æ–‡æœ¬å½¢å¼æ˜¾ç¤º
                    try:
                        preview_text = preview_bytes.decode('utf-8', errors='ignore')
                        st.code(f"æ–‡æœ¬é¢„è§ˆ: {preview_text}")
                    except:
                        pass
                    
                    return None
                else:
                    st.success(f"âœ… æ–‡ä»¶å¤´éƒ¨éªŒè¯é€šè¿‡: {hex_header}")
            
        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}")
            st.error(f"âŒ ä¸‹è½½æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
        
        # 3. è¯»å–Excelæ–‡ä»¶
        try:
            # åˆ›å»ºå­—èŠ‚æµå¹¶ç¡®ä¿æŒ‡é’ˆåœ¨å¼€å§‹ä½ç½®
            excel_buffer = io.BytesIO(raw_content)
            excel_buffer.seek(0)
            
            logger.info("å¼€å§‹è§£æExcelæ–‡ä»¶...")
            
            # ä½¿ç”¨pandasè¯»å–Excel
            df = pd.read_excel(excel_buffer, engine='openpyxl')
            
            logger.info(f"Excelè§£ææˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
            st.success(f"âœ… Excelè§£ææˆåŠŸ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
            
            # æ˜¾ç¤ºåˆ—å
            st.write(f"**åˆ—å**: {df.columns.tolist()}")
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            if len(df) > 0:
                with st.expander("ğŸ“Š æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰", expanded=False):
                    st.dataframe(df.head(), use_container_width=True)
            
            return df
            
        except Exception as e:
            logger.error(f"Excelè§£æå¤±è´¥: {str(e)}")
            st.error(f"âŒ Excelè§£æå¤±è´¥: {str(e)}")
            
            # æä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_type = type(e).__name__
            st.write(f"**é”™è¯¯ç±»å‹**: {error_type}")
            st.write(f"**é”™è¯¯è¯¦æƒ…**: {str(e)}")
            
            # å¦‚æœæ˜¯BadZipFileé”™è¯¯ï¼Œæä¾›æ›´å¤šè°ƒè¯•ä¿¡æ¯
            if "zip" in str(e).lower():
                st.write("**å¯èƒ½åŸå› **:")
                st.write("- æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„Excelæ ¼å¼")
                st.write("- æ–‡ä»¶åœ¨ä¼ è¾“è¿‡ç¨‹ä¸­æŸå")
                st.write("- æ–‡ä»¶å®é™…ä¸Šæ˜¯å…¶ä»–æ ¼å¼ä½†æ‰©å±•åä¸º.xlsx")
            
            return None
            
    except Exception as e:
        logger.error(f"ç»Ÿä¸€Excelè¯»å–å™¨å‡ºé”™: {str(e)}")
        st.error(f"âŒ è¯»å– {file_type} æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return None

def load_permissions_from_cos_enhanced_v2(cos_client, bucket_name: str, permissions_file: str, force_reload: bool = False) -> Optional[pd.DataFrame]:
    """æƒé™è¡¨è¯»å–å™¨ - ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶å¤„ç†æœºåˆ¶"""
    
    # ç¼“å­˜å¤„ç†
    if not force_reload:
        cache_key = get_cache_key("permissions", "load")
        cached_data = get_cache(cache_key)
        if cached_data is not None:
            logger.info("ä½¿ç”¨ç¼“å­˜æ•°æ®")
            st.info("ğŸ“¦ ä½¿ç”¨ç¼“å­˜æ•°æ®")
            return cached_data
    
    st.subheader("ğŸ” æƒé™è¡¨è¯»å–è¯Šæ–­")
    
    with error_handler("åŠ è½½æƒé™æ•°æ®"):
        def _load_operation():
            # ç¡®å®šæ–‡ä»¶å - æ™ºèƒ½è·¯å¾„å¤„ç†
            if permissions_file.endswith('.csv'):
                excel_permissions_file = permissions_file.replace('.csv', '.xlsx')
            elif permissions_file.endswith('.xlsx'):
                excel_permissions_file = permissions_file
            else:
                excel_permissions_file = permissions_file + '.xlsx'
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰åˆ™å¯èƒ½éœ€è¦æ·»åŠ 
            if '/' not in excel_permissions_file:
                # å°è¯•å¸¸è§çš„è·¯å¾„å‰ç¼€
                possible_paths = [
                    excel_permissions_file,  # åŸå§‹æ–‡ä»¶å
                    f"permissions/{excel_permissions_file}",  # permissionsæ–‡ä»¶å¤¹
                    f"user/{excel_permissions_file}",  # useræ–‡ä»¶å¤¹
                    f"auth/{excel_permissions_file}"  # authæ–‡ä»¶å¤¹
                ]
            else:
                possible_paths = [excel_permissions_file]
            
            st.write(f"ğŸ“ é…ç½®æ–‡ä»¶å: `{permissions_file}`")
            st.write(f"ğŸ“ è½¬æ¢åæ–‡ä»¶å: `{excel_permissions_file}`")
            
            # å°è¯•æŸ¥æ‰¾æ–‡ä»¶
            df = None
            found_file = None
            
            for file_path in possible_paths:
                st.write(f"ğŸ” å°è¯•æŸ¥æ‰¾: `{file_path}`")
                try:
                    # å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    cos_client.head_object(Bucket=bucket_name, Key=file_path)
                    found_file = file_path
                    st.success(f"âœ… æ‰¾åˆ°æ–‡ä»¶: `{file_path}`")
                    break
                except Exception as e:
                    st.write(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: `{file_path}` - {str(e)}")
                    continue
            
            if found_file is None:
                st.error("âŒ æœªæ‰¾åˆ°æƒé™æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥é…ç½®æˆ–ä¸Šä¼ æ–‡ä»¶")
                return None
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶å¤„ç†å‡½æ•°
            df = unified_file_processor(cos_client, bucket_name, found_file, "æƒé™è¡¨")
            
            if df is None:
                st.warning("âš ï¸ Excelæ ¼å¼è¯»å–å¤±è´¥ï¼Œå°è¯•CSVæ ¼å¼...")
                
                # å°è¯•CSVæ ¼å¼å›é€€
                csv_file = permissions_file if permissions_file.endswith('.csv') else permissions_file.replace('.xlsx', '.csv')
                
                # å¯¹CSVæ–‡ä»¶ä¹Ÿå°è¯•ä¸åŒè·¯å¾„
                if '/' not in csv_file:
                    csv_paths = [csv_file, f"permissions/{csv_file}"]
                else:
                    csv_paths = [csv_file]
                
                for csv_path in csv_paths:
                    try:
                        st.write(f"ğŸ” å°è¯•CSVæ ¼å¼: `{csv_path}`")
                        response = cos_client.get_object(Bucket=bucket_name, Key=csv_path)
                        csv_content = response['Body'].read().decode('utf-8-sig')
                        df = pd.read_csv(io.StringIO(csv_content))
                        st.success(f"âœ… CSVæ ¼å¼è¯»å–æˆåŠŸ: {len(df)} è¡Œ")
                        break
                    except Exception as e:
                        st.write(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: `{csv_path}` - {str(e)}")
                        continue
                
                if df is None:
                    st.error("âŒ Excelå’ŒCSVæ ¼å¼éƒ½å¤±è´¥")
                    return None
            
            if df is None or len(df) == 0:
                st.warning("âš ï¸ æƒé™è¡¨ä¸ºç©ºæˆ–æ— æ•ˆ")
                return None
            
            # æƒé™è¡¨æ•°æ®å¤„ç†
            if len(df.columns) < 2:
                st.error("âŒ æƒé™è¡¨æ ¼å¼é”™è¯¯ï¼šéœ€è¦è‡³å°‘ä¸¤åˆ—")
                return None
            
            # æ ‡å‡†åŒ–å¤„ç†
            result_df = df.iloc[:, :2].copy()
            result_df.columns = ['é—¨åº—åç§°', 'äººå‘˜ç¼–å·']
            
            # æ•°æ®æ¸…ç†
            original_count = len(result_df)
            result_df['é—¨åº—åç§°'] = result_df['é—¨åº—åç§°'].astype(str).str.strip()
            result_df['äººå‘˜ç¼–å·'] = result_df['äººå‘˜ç¼–å·'].astype(str).str.strip()
            
            # ç§»é™¤æ— æ•ˆæ•°æ®
            result_df = result_df[
                (result_df['é—¨åº—åç§°'] != '') & 
                (result_df['äººå‘˜ç¼–å·'] != '') &
                (result_df['é—¨åº—åç§°'] != 'nan') &
                (result_df['äººå‘˜ç¼–å·'] != 'nan')
            ]
            
            final_count = len(result_df)
            st.write(f"ğŸ“Š æ•°æ®æ¸…ç†: {original_count} â†’ {final_count} æ¡è®°å½•")
            
            if final_count == 0:
                st.warning("âš ï¸ æ¸…ç†åæƒé™æ•°æ®ä¸ºç©º")
                return None
            
            # æ˜¾ç¤ºå¤„ç†åçš„æ•°æ®é¢„è§ˆ
            with st.expander("ğŸ“‹ æƒé™æ•°æ®é¢„è§ˆï¼ˆå‰10è¡Œï¼‰", expanded=False):
                st.dataframe(result_df.head(10), use_container_width=True)
            
            logger.info(f"æƒé™æ•°æ®åŠ è½½æˆåŠŸ: {final_count} æ¡è®°å½•")
            
            # è®¾ç½®ç¼“å­˜
            if not force_reload:
                cache_key = get_cache_key("permissions", "load")
                set_cache(cache_key, result_df)
            
            return result_df
        
        return safe_cos_operation(_load_operation)

def get_single_report_from_cos_v2(cos_client, bucket_name: str, store_name: str) -> Optional[pd.DataFrame]:
    """æŠ¥è¡¨æ–‡ä»¶è¯»å–å™¨ - ä½¿ç”¨ç»Ÿä¸€çš„Excelè¯»å–é€»è¾‘"""
    cache_key = get_cache_key("single_report", store_name)
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        st.info("ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„æŠ¥è¡¨æ•°æ®")
        return cached_data
    
    st.subheader(f"ğŸ” æŠ¥è¡¨æ–‡ä»¶è¯»å–è¯Šæ–­ - {store_name}")
    
    with error_handler(f"åŠ è½½é—¨åº— {store_name} çš„æŠ¥è¡¨"):
        def _load_operation():
            # æŸ¥æ‰¾æ–‡ä»¶
            safe_store_name = store_name.replace(' ', '_')
            
            try:
                response = cos_client.list_objects(
                    Bucket=bucket_name,
                    Prefix=f'reports/{safe_store_name}_',
                    MaxKeys=100
                )
                
                if 'Contents' not in response or len(response['Contents']) == 0:
                    st.warning(f"âš ï¸ æœªæ‰¾åˆ°é—¨åº— {store_name} çš„æŠ¥è¡¨æ–‡ä»¶")
                    return None
                
                # æŸ¥æ‰¾æœ€æ–°æ–‡ä»¶
                latest_file = None
                latest_time = None
                
                st.write(f"ğŸ“ æ‰¾åˆ° {len(response['Contents'])} ä¸ªæ–‡ä»¶:")
                for obj in response['Contents']:
                    key = obj['Key']
                    file_time = obj['LastModified']
                    file_size_raw = obj['Size']
                    file_size = safe_format_number(file_size_raw, 0)
                    
                    st.write(f"- {key} ({file_size:,} å­—èŠ‚, {file_time})")
                    
                    if key.endswith('.xlsx'):
                        if latest_time is None or file_time > latest_time:
                            latest_time = file_time
                            latest_file = key
                
                if latest_file is None:
                    st.error(f"âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„Excelæ–‡ä»¶")
                    return None
                
                st.success(f"âœ… é€‰æ‹©æœ€æ–°æ–‡ä»¶: {latest_file}")
                
                # ä½¿ç”¨ç»Ÿä¸€çš„Excelè¯»å–å™¨
                df = unified_excel_reader(cos_client, bucket_name, latest_file, f"æŠ¥è¡¨({store_name})")
                
                if df is not None:
                    # æŠ¥è¡¨æ•°æ®å¤„ç†
                    processed_df = process_report_dataframe(df)
                    
                    # è®¾ç½®ç¼“å­˜
                    set_cache(cache_key, processed_df)
                    
                    return processed_df
                else:
                    return None
                
            except Exception as e:
                st.error(f"âŒ æŸ¥æ‰¾æŠ¥è¡¨æ–‡ä»¶å¤±è´¥: {str(e)}")
                return None
        
        return safe_cos_operation(_load_operation)

def compare_file_properties(cos_client, bucket_name: str, permissions_file: str, store_name: str):
    """å¯¹æ¯”æƒé™è¡¨å’ŒæŠ¥è¡¨æ–‡ä»¶çš„å±æ€§"""
    st.subheader("ğŸ” æ–‡ä»¶å±æ€§å¯¹æ¯”")
    
    try:
        # æƒé™è¡¨æ–‡ä»¶ - æ™ºèƒ½è·¯å¾„å¤„ç†
        if permissions_file.endswith('.csv'):
            excel_permissions_file = permissions_file.replace('.csv', '.xlsx')
        elif permissions_file.endswith('.xlsx'):
            excel_permissions_file = permissions_file
        else:
            excel_permissions_file = permissions_file + '.xlsx'
        
        # å¦‚æœæ²¡æœ‰è·¯å¾„å‰ç¼€ï¼Œå°è¯•æ·»åŠ 
        if '/' not in excel_permissions_file:
            possible_paths = [excel_permissions_file, f"permissions/{excel_permissions_file}"]
        else:
            possible_paths = [excel_permissions_file]
        
        # æŸ¥æ‰¾æƒé™æ–‡ä»¶
        perm_info = None
        for file_path in possible_paths:
            try:
                perm_head = cos_client.head_object(Bucket=bucket_name, Key=file_path)
                perm_size_raw = perm_head.get('Content-Length', 0)
                perm_size = safe_format_number(perm_size_raw, 0)
                perm_info = {
                    'file': file_path,
                    'size': perm_size,
                    'type': perm_head.get('Content-Type', ''),
                    'modified': perm_head.get('Last-Modified', '')
                }
                break
            except Exception:
                continue
        
        if perm_info is None:
            perm_info = {'error': 'Permission file not found in any expected location'}
        
        # æŠ¥è¡¨æ–‡ä»¶
        safe_store_name = store_name.replace(' ', '_')
        try:
            list_response = cos_client.list_objects(
                Bucket=bucket_name,
                Prefix=f'reports/{safe_store_name}_',
                MaxKeys=1
            )
            
            if 'Contents' in list_response and len(list_response['Contents']) > 0:
                report_key = list_response['Contents'][0]['Key']
                report_head = cos_client.head_object(Bucket=bucket_name, Key=report_key)
                report_size_raw = report_head.get('Content-Length', 0)
                report_size = safe_format_number(report_size_raw, 0)
                report_info = {
                    'file': report_key,
                    'size': report_size,
                    'type': report_head.get('Content-Type', ''),
                    'modified': report_head.get('Last-Modified', '')
                }
            else:
                report_info = {'error': 'No report file found'}
        except Exception as e:
            report_info = {'error': str(e)}
        
        # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**æƒé™è¡¨æ–‡ä»¶**")
            if 'error' in perm_info:
                st.error(f"âŒ {perm_info['error']}")
            else:
                st.success(f"âœ… {perm_info['file']}")
                st.write(f"- å¤§å°: {perm_info['size']:,} å­—èŠ‚")
                st.write(f"- ç±»å‹: {perm_info['type']}")
                st.write(f"- ä¿®æ”¹: {perm_info['modified']}")
        
        with col2:
            st.write("**æŠ¥è¡¨æ–‡ä»¶**")
            if 'error' in report_info:
                st.error(f"âŒ {report_info['error']}")
            else:
                st.success(f"âœ… {report_info['file']}")
                st.write(f"- å¤§å°: {report_info['size']:,} å­—èŠ‚")
                st.write(f"- ç±»å‹: {report_info['type']}")
                st.write(f"- ä¿®æ”¹: {report_info['modified']}")
        
        # å¯¹æ¯”åˆ†æ
        if 'error' not in perm_info and 'error' not in report_info:
            st.write("**å¯¹æ¯”åˆ†æ**:")
            if perm_info['type'] == report_info['type']:
                st.success("âœ… Content-Type ä¸€è‡´")
            else:
                st.warning(f"âš ï¸ Content-Type ä¸ä¸€è‡´: {perm_info['type']} vs {report_info['type']}")
            
            if perm_info['size'] > 0 and report_info['size'] > 0:
                st.success("âœ… æ–‡ä»¶å¤§å°éƒ½å¤§äº0")
            else:
                st.error("âŒ å­˜åœ¨ç©ºæ–‡ä»¶")
    
    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶å±æ€§å¯¹æ¯”å¤±è´¥: {str(e)}")

def save_permissions_to_cos(df: pd.DataFrame, cos_client, bucket_name: str, permissions_file: str) -> bool:
    """ä¿å­˜æƒé™æ•°æ®åˆ°COS - ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶å¤„ç†æœºåˆ¶"""
    with error_handler("ä¿å­˜æƒé™æ•°æ®"):
        def _save_operation():
            # æ•°æ®éªŒè¯
            if df is None or len(df) == 0:
                raise DataProcessingError("æƒé™æ•°æ®ä¸ºç©º")
            
            if len(df.columns) < 2:
                raise DataProcessingError("æƒé™æ•°æ®æ ¼å¼é”™è¯¯ï¼šéœ€è¦è‡³å°‘ä¸¤åˆ—ï¼ˆé—¨åº—åç§°ã€äººå‘˜ç¼–å·ï¼‰")
            
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # åˆ›å»ºè¯¦ç»†çš„å¤„ç†æŠ¥å‘Š
            processing_report = {
                'original_rows': len(df),
                'original_columns': len(df.columns),
                'processed_rows': 0,
                'skipped_rows': [],
                'error_rows': [],
                'duplicate_rows': [],
                'empty_rows': [],
                'step_by_step': []
            }
            
            # æ­¥éª¤1ï¼šæ˜¾ç¤ºåŸå§‹æ•°æ®ç»Ÿè®¡
            st.info(f"ğŸ“Š æ­¥éª¤1: æ¥æ”¶åˆ°åŸå§‹æ•°æ® {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
            
            # æ˜¾ç¤ºåŸå§‹æ•°æ®é¢„è§ˆ
            with st.expander("ğŸ” æ­¥éª¤1: åŸå§‹æ•°æ®é¢„è§ˆï¼ˆå‰10è¡Œï¼‰", expanded=True):
                st.dataframe(df.head(10), use_container_width=True)
                st.write(f"**åˆ—å**: {df.columns.tolist()}")
                
                # æ˜¾ç¤ºæ•°æ®ç±»å‹
                st.write("**æ•°æ®ç±»å‹**:")
                for col in df.columns:
                    st.write(f"- {col}: {df[col].dtype}")
            
            # æ­¥éª¤2ï¼šæ•°æ®å¤„ç†
            st.info(f"ğŸ“Š æ­¥éª¤2: å¼€å§‹é€è¡Œå¤„ç† {len(df)} è¡Œæ•°æ®")
            
            # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„åˆ—
            store_col = df.columns[0]
            user_col = df.columns[1]
            
            # åˆ›å»ºæƒé™æ•°æ®
            permissions_data = []
            permissions_data.append(['é—¨åº—åç§°', 'äººå‘˜ç¼–å·', 'æ›´æ–°æ—¶é—´'])
            
            # åˆ›å»ºè¿›åº¦æ¡
            progress_container = st.container()
            with progress_container:
                progress_bar = st.progress(0)
                status_text = st.empty()
            
            processed_count = 0
            seen_combinations = set()  # ç”¨äºæ£€æµ‹é‡å¤æ•°æ®
            
            # é€è¡Œå¤„ç†æ•°æ®
            for idx, row in df.iterrows():
                try:
                    progress = (idx + 1) / len(df)
                    progress_bar.progress(progress)
                    status_text.text(f"å¤„ç†ç¬¬ {idx + 1}/{len(df)} è¡Œ...")
                    
                    # è·å–åŸå§‹å€¼
                    raw_store = row[store_col] if pd.notna(row[store_col]) else ""
                    raw_user = row[user_col] if pd.notna(row[user_col]) else ""
                    
                    # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶æ¸…ç†
                    store_name = str(raw_store).strip()
                    user_id = str(raw_user).strip()
                    
                    # æ•°æ®éªŒè¯å’Œæ¸…ç†é€»è¾‘ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    if (not store_name or store_name in ['nan', 'None']) and \
                       (not user_id or user_id in ['nan', 'None']):
                        processing_report['empty_rows'].append({
                            'row': idx + 1,
                            'store': raw_store,
                            'user': raw_user,
                            'reason': 'é—¨åº—å’Œç¼–å·éƒ½ä¸ºç©º'
                        })
                        continue
                    
                    if not store_name or store_name in ['nan', 'None']:
                        processing_report['skipped_rows'].append({
                            'row': idx + 1,
                            'store': raw_store,
                            'user': raw_user,
                            'reason': 'é—¨åº—åç§°ä¸ºç©º'
                        })
                        continue
                    
                    if not user_id or user_id in ['nan', 'None']:
                        processing_report['skipped_rows'].append({
                            'row': idx + 1,
                            'store': raw_store,
                            'user': raw_user,
                            'reason': 'äººå‘˜ç¼–å·ä¸ºç©º'
                        })
                        continue
                    
                    # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
                    store_name = store_name.replace('\n', ' ').replace('\r', ' ').replace('\t', ' ')
                    user_id = user_id.replace('\n', '').replace('\r', '').replace('\t', '')
                    
                    # å»é™¤å¤šä½™ç©ºæ ¼
                    store_name = ' '.join(store_name.split())
                    user_id = ' '.join(user_id.split())
                    
                    # æœ€ç»ˆéªŒè¯
                    if len(store_name) == 0 or len(user_id) == 0:
                        processing_report['skipped_rows'].append({
                            'row': idx + 1,
                            'store': raw_store,
                            'user': raw_user,
                            'reason': 'æ¸…ç†åæ•°æ®ä¸ºç©º'
                        })
                        continue
                    
                    # æ£€æŸ¥é‡å¤æ•°æ®
                    combination = (store_name.lower(), user_id.lower())
                    if combination in seen_combinations:
                        processing_report['duplicate_rows'].append({
                            'row': idx + 1,
                            'store': store_name,
                            'user': user_id,
                            'reason': 'é‡å¤çš„é—¨åº—-ç¼–å·ç»„åˆ'
                        })
                        continue
                    
                    seen_combinations.add(combination)
                    permissions_data.append([store_name, user_id, current_time])
                    processed_count += 1
                    
                except Exception as e:
                    processing_report['error_rows'].append({
                        'row': idx + 1,
                        'store': raw_store if 'raw_store' in locals() else 'N/A',
                        'user': raw_user if 'raw_user' in locals() else 'N/A',
                        'reason': f'å¤„ç†é”™è¯¯: {str(e)}'
                    })
                    logger.warning(f"å¤„ç†ç¬¬{idx+1}è¡Œæ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # æ¸…é™¤è¿›åº¦æ˜¾ç¤º
            progress_container.empty()
            
            # æ›´æ–°å¤„ç†æŠ¥å‘Š
            processing_report['processed_rows'] = processed_count
            
            # æ˜¾ç¤ºå¤„ç†ç»“æœ
            st.success(f"âœ… æ­¥éª¤2: æ•°æ®å¤„ç†å®Œæˆï¼æœ‰æ•ˆæ•°æ® {processed_count} è¡Œ")
            
            if processed_count == 0:
                raise DataProcessingError("æ²¡æœ‰æœ‰æ•ˆçš„æƒé™æ•°æ®å¯ä»¥ä¿å­˜")
            
            # æ­¥éª¤3ï¼šåˆ›å»ºExcelæ–‡ä»¶ - ä½¿ç”¨ç»Ÿä¸€çš„Excelåˆ›å»ºå‡½æ•°
            st.info(f"ğŸ“Š æ­¥éª¤3: åˆ›å»ºExcelæ–‡ä»¶ï¼Œå…± {processed_count} æ¡æƒé™è®°å½•")
            
            # è½¬æ¢ä¸ºDataFrame
            final_df = pd.DataFrame(permissions_data[1:], columns=permissions_data[0])
            
            # ä½¿ç”¨ç»Ÿä¸€çš„Excelåˆ›å»ºå‡½æ•°
            excel_content, row_count, col_count = create_excel_buffer(final_df, "æƒé™æ•°æ®", "æƒé™è¡¨")
            
            # æ­¥éª¤4ï¼šä¸Šä¼ åˆ°COS - ä½¿ç”¨ç»Ÿä¸€çš„ä¸Šä¼ å‡½æ•°
            st.info(f"ğŸ“Š æ­¥éª¤4: ä¸Šä¼ åˆ°è…¾è®¯äº‘COS")
            
            # ç¡®å®šæœ€ç»ˆæ–‡ä»¶è·¯å¾„
            if permissions_file.endswith('.csv'):
                excel_permissions_file = permissions_file.replace('.csv', '.xlsx')
            elif permissions_file.endswith('.xlsx'):
                excel_permissions_file = permissions_file
            else:
                excel_permissions_file = permissions_file + '.xlsx'
            
            # å¦‚æœæ²¡æœ‰è·¯å¾„å‰ç¼€ï¼Œæ·»åŠ permissions/
            if '/' not in excel_permissions_file:
                excel_permissions_file = f"permissions/{excel_permissions_file}"
            
            # å‡†å¤‡å…ƒæ•°æ®
            metadata = {
                'upload-time': current_time,
                'record-count': str(processed_count),
                'original-count': str(processing_report['original_rows']),
                'file-format': 'excel',
                'file-type': 'permissions'
            }
            
            # ä½¿ç”¨ç»Ÿä¸€çš„ä¸Šä¼ å‡½æ•°
            upload_success = unified_upload_to_cos(
                cos_client, 
                bucket_name, 
                excel_permissions_file, 
                excel_content, 
                metadata, 
                "æƒé™è¡¨"
            )
            
            if upload_success:
                st.success(f"âœ… æ­¥éª¤4: æƒé™è¡¨ä¸Šä¼ æˆåŠŸï¼")
                logger.info(f"æƒé™æ•°æ®ä¿å­˜æˆåŠŸ: {processed_count} æ¡è®°å½•")
                
                # æ¸…é™¤ç›¸å…³ç¼“å­˜
                clear_permissions_cache()
                
                return True
            else:
                raise DataProcessingError("æƒé™è¡¨ä¸Šä¼ å¤±è´¥")
        
        return safe_cos_operation(_save_operation)

def clear_permissions_cache():
    """æ¸…é™¤æƒé™ç›¸å…³ç¼“å­˜"""
    cache_keys_to_clear = [
        get_cache_key("permissions", "load"),
        get_cache_key("store_list", "load")
    ]
    
    for cache_key in cache_keys_to_clear:
        full_key = f"cache_{cache_key}"
        if full_key in st.session_state:
            del st.session_state[full_key]
            logger.info(f"å·²æ¸…é™¤ç¼“å­˜: {cache_key}")

def load_permissions_from_cos(cos_client, bucket_name: str, permissions_file: str) -> Optional[pd.DataFrame]:
    """ä»COSåŠ è½½æƒé™æ•°æ® - ä½¿ç”¨ç»Ÿä¸€è¯»å–é€»è¾‘"""
    return load_permissions_from_cos_enhanced_v2(cos_client, bucket_name, permissions_file, force_reload=False)

def save_single_report_to_cos(df: pd.DataFrame, cos_client, bucket_name: str, store_name: str) -> bool:
    """ä¿å­˜å•ä¸ªé—¨åº—æŠ¥è¡¨åˆ°COS"""
    try:
        # æ•°æ®éªŒè¯
        if df is None or len(df) == 0:
            logger.warning(f"é—¨åº— {store_name} çš„æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
            return False
        
        # æ¸…ç†é—¨åº—åç§°ï¼Œç”¨äºæ–‡ä»¶å
        safe_store_name = "".join(c for c in store_name if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_store_name = safe_store_name.replace(' ', '_')
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"reports/{safe_store_name}_{timestamp}.xlsx"
        
        # åˆ›å»ºExcelæ–‡ä»¶
        excel_buffer = io.BytesIO()
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            # å·¥ä½œè¡¨åé™åˆ¶31å­—ç¬¦
            sheet_name = store_name[:31] if len(store_name) <= 31 else store_name[:28] + "..."
            df.to_excel(writer, index=False, sheet_name=sheet_name)
        
        excel_content = excel_buffer.getvalue()
        
        # ä¸Šä¼ åˆ°COS
        cos_client.put_object(
            Bucket=bucket_name,
            Body=excel_content,
            Key=filename,
            ContentType='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            Metadata={
                'store-name': store_name,
                'upload-time': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                'row-count': str(len(df)),
                'col-count': str(len(df.columns))
            }
        )
        
        logger.info(f"æŠ¥è¡¨ä¿å­˜æˆåŠŸ: {store_name} -> {filename}")
        return True
        
    except Exception as e:
        logger.error(f"ä¿å­˜ {store_name} æŠ¥è¡¨å¤±è´¥: {str(e)}")
        return False

def save_reports_to_cos(reports_dict: Dict[str, pd.DataFrame], cos_client, bucket_name: str) -> bool:
    """ä¿å­˜æŠ¥è¡¨æ•°æ®åˆ°COS"""
    with error_handler("ä¿å­˜æŠ¥è¡¨æ•°æ®"):
        def _save_operation():
            if not reports_dict:
                raise DataProcessingError("æ²¡æœ‰æŠ¥è¡¨æ•°æ®éœ€è¦ä¿å­˜")
            
            success_count = 0
            total_count = len(reports_dict)
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, (store_name, df) in enumerate(reports_dict.items()):
                try:
                    status_text.text(f"æ­£åœ¨ä¿å­˜ {store_name}... ({idx+1}/{total_count})")
                    
                    if save_single_report_to_cos(df, cos_client, bucket_name, store_name):
                        success_count += 1
                    
                    # æ›´æ–°è¿›åº¦
                    progress = (idx + 1) / total_count
                    progress_bar.progress(progress)
                    
                    # APIé™åˆ¶å»¶è¿Ÿ
                    time.sleep(0.3)
                    
                except Exception as e:
                    logger.error(f"ä¿å­˜é—¨åº— {store_name} æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            progress_bar.empty()
            status_text.empty()
            
            # æ¸…é™¤ç›¸å…³ç¼“å­˜
            clear_reports_cache()
            
            logger.info(f"æŠ¥è¡¨æ•°æ®ä¿å­˜å®Œæˆ: {success_count}/{total_count}")
            return success_count > 0  # åªè¦æœ‰ä¸€ä¸ªæˆåŠŸå°±ç®—æˆåŠŸ
        
        return safe_cos_operation(_save_operation)

def clear_reports_cache():
    """æ¸…é™¤æŠ¥è¡¨ç›¸å…³ç¼“å­˜"""
    cache_keys_to_clear = []
    
    # æ¸…é™¤æ‰€æœ‰ä»¥cache_å¼€å¤´çš„é”®
    for key in list(st.session_state.keys()):
        if key.startswith('cache_'):
            cache_keys_to_clear.append(key)
    
    for key in cache_keys_to_clear:
        del st.session_state[key]
        logger.info(f"å·²æ¸…é™¤ç¼“å­˜: {key}")

def get_store_list_from_cos(cos_client, bucket_name: str) -> List[str]:
    """ä»COSè·å–é—¨åº—åˆ—è¡¨ - ä¼˜åŒ–ç‰ˆ"""
    cache_key = get_cache_key("store_list", "load")
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        return cached_data
    
    with error_handler("åŠ è½½é—¨åº—åˆ—è¡¨"):
        def _load_operation():
            try:
                store_set = set()
                marker = ''
                
                # åˆ†é¡µè·å–æ‰€æœ‰æ–‡ä»¶
                while True:
                    list_params = {
                        'Bucket': bucket_name,
                        'Prefix': 'reports/',
                        'MaxKeys': 1000
                    }
                    
                    if marker:
                        list_params['Marker'] = marker
                    
                    response = cos_client.list_objects(**list_params)
                    
                    if 'Contents' not in response:
                        break
                    
                    # ä»æ–‡ä»¶åæå–é—¨åº—åç§°
                    for obj in response['Contents']:
                        key = obj['Key']
                        if key.endswith('.xlsx') and '/' in key:
                            # ä»æ–‡ä»¶åæå–é—¨åº—åç§°
                            filename = key.split('/')[-1]  # è·å–æ–‡ä»¶å
                            if '_' in filename:
                                store_name = filename.split('_')[0]  # æå–é—¨åº—åç§°
                                # è¿˜åŸä¸‹åˆ’çº¿ä¸ºç©ºæ ¼
                                store_name = store_name.replace('_', ' ')
                                if store_name:
                                    store_set.add(store_name)
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
                    if response.get('IsTruncated') == 'true':
                        marker = response.get('NextMarker', '')
                        if not marker and response['Contents']:
                            marker = response['Contents'][-1]['Key']
                    else:
                        break
                
                store_list = sorted(list(store_set))
                logger.info(f"é—¨åº—åˆ—è¡¨åŠ è½½æˆåŠŸ: {len(store_list)} ä¸ªé—¨åº—")
                
                # è®¾ç½®ç¼“å­˜
                set_cache(cache_key, store_list)
                return store_list
                
            except CosServiceError as e:
                logger.error(f"COSæ“ä½œå¤±è´¥: {e.get_error_code()} - {e.get_error_msg()}")
                return []
            except Exception as e:
                logger.error(f"è·å–é—¨åº—åˆ—è¡¨å¤±è´¥: {str(e)}")
                return []
        
        return safe_cos_operation(_load_operation)

def get_single_report_from_cos(cos_client, bucket_name: str, store_name: str) -> Optional[pd.DataFrame]:
    """ä»COSè·å–å•ä¸ªé—¨åº—çš„æŠ¥è¡¨æ•°æ® - ä½¿ç”¨ç»Ÿä¸€è¯»å–é€»è¾‘"""
    return get_single_report_from_cos_v2(cos_client, bucket_name, store_name)

def process_report_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """å¤„ç†æŠ¥è¡¨DataFrame - ç»Ÿä¸€çš„æ•°æ®æ¸…ç†é€»è¾‘"""
    if df is None or len(df) == 0:
        return pd.DataFrame()
    
    try:
        # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯é—¨åº—åç§°
        if len(df) > 0:
            first_row = df.iloc[0]
            non_empty_count = sum(1 for val in first_row if pd.notna(val) and str(val).strip() != '')
            
            # å¦‚æœç¬¬ä¸€è¡Œåªæœ‰1-2ä¸ªéç©ºå€¼ï¼Œå¯èƒ½æ˜¯é—¨åº—åç§°è¡Œï¼Œè·³è¿‡
            if non_empty_count <= 2 and len(df) > 1:
                df = df.iloc[1:].reset_index(drop=True)
        
        # å¤„ç†è¡¨å¤´
        if len(df) > 1:
            header_row = df.iloc[0].fillna('').astype(str).tolist()
            data_rows = df.iloc[1:].copy()
            
            # æ¸…ç†åˆ—åå¹¶å¤„ç†é‡å¤
            cols = []
            for i, col in enumerate(header_row):
                col = str(col).strip()
                if col == '' or col == 'nan' or col == '0':
                    col = f'åˆ—{i+1}' if i > 0 else 'é¡¹ç›®åç§°'
                
                # å¤„ç†é‡å¤åˆ—å
                original_col = col
                counter = 1
                while col in cols:
                    col = f"{original_col}_{counter}"
                    counter += 1
                cols.append(col)
            
            # ç¡®ä¿åˆ—æ•°åŒ¹é…
            min_cols = min(len(data_rows.columns), len(cols))
            cols = cols[:min_cols]
            data_rows = data_rows.iloc[:, :min_cols]
            
            data_rows.columns = cols
            df = data_rows.reset_index(drop=True).fillna('')
        else:
            # å¤„ç†å°‘äº3è¡Œçš„æ•°æ®
            df = df.fillna('')
            default_cols = []
            for i in range(len(df.columns)):
                col_name = f'åˆ—{i+1}' if i > 0 else 'é¡¹ç›®åç§°'
                default_cols.append(col_name)
            df.columns = default_cols
        
        return df
        
    except Exception as e:
        logger.error(f"å¤„ç†DataFrameæ—¶å‡ºé”™: {str(e)}")
        return df.fillna('')

def analyze_receivable_data(df: pd.DataFrame) -> Dict[str, Any]:
    """åˆ†æåº”æ”¶æœªæ”¶é¢æ•°æ® - ä¸“é—¨æŸ¥æ‰¾ç¬¬69è¡Œ"""
    result = {}
    
    if len(df.columns) == 0 or len(df) == 0:
        return result
    
    # ä½¿ç”¨å¤„ç†åçš„æ•°æ®
    processed_df = df.copy()
    
    # æŸ¥æ‰¾ç¬¬69è¡Œ
    target_row_index = 68  # ç¬¬69è¡Œï¼ˆä»0å¼€å§‹ç´¢å¼•ï¼‰
    
    if len(processed_df) > target_row_index:
        row = processed_df.iloc[target_row_index]
        first_col_value = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
        
        # æ£€æŸ¥å…³é”®è¯
        keywords = ['åº”æ”¶-æœªæ”¶é¢', 'åº”æ”¶æœªæ”¶é¢', 'åº”æ”¶-æœªæ”¶', 'åº”æ”¶æœªæ”¶']
        
        for keyword in keywords:
            if keyword in first_col_value:
                # æŸ¥æ‰¾æ•°å€¼ï¼ˆä»å³å¾€å·¦ï¼‰
                for col_idx in range(len(row)-1, 0, -1):
                    val = row.iloc[col_idx]
                    if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                        cleaned = str(val).replace(',', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                        
                        # å¤„ç†æ‹¬å·è¡¨ç¤ºè´Ÿæ•°
                        if cleaned.startswith('(') and cleaned.endswith(')'):
                            cleaned = '-' + cleaned[1:-1]
                        
                        try:
                            amount = float(cleaned)
                            if amount != 0:
                                result['åº”æ”¶-æœªæ”¶é¢'] = {
                                    'amount': amount,
                                    'column_name': str(processed_df.columns[col_idx]),
                                    'row_name': first_col_value,
                                    'row_index': target_row_index,
                                    'actual_row_number': target_row_index + 1
                                }
                                return result
                        except ValueError:
                            continue
                break
    
    # å¤‡ç”¨æŸ¥æ‰¾ç­–ç•¥
    if 'åº”æ”¶-æœªæ”¶é¢' not in result:
        keywords = ['åº”æ”¶-æœªæ”¶é¢', 'åº”æ”¶æœªæ”¶é¢', 'åº”æ”¶-æœªæ”¶', 'åº”æ”¶æœªæ”¶']
        
        for idx, row in processed_df.iterrows():
            try:
                row_name = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
                
                if not row_name.strip():
                    continue
                
                for keyword in keywords:
                    if keyword in row_name:
                        # æŸ¥æ‰¾æ•°å€¼ï¼ˆä»å³å¾€å·¦ï¼‰
                        for col_idx in range(len(row)-1, 0, -1):
                            val = row.iloc[col_idx]
                            if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                                cleaned = str(val).replace(',', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                                
                                if cleaned.startswith('(') and cleaned.endswith(')'):
                                    cleaned = '-' + cleaned[1:-1]
                                
                                try:
                                    amount = float(cleaned)
                                    if amount != 0:
                                        result['åº”æ”¶-æœªæ”¶é¢'] = {
                                            'amount': amount,
                                            'column_name': str(processed_df.columns[col_idx]),
                                            'row_name': row_name,
                                            'row_index': idx,
                                            'actual_row_number': idx + 1,
                                            'note': f'åœ¨ç¬¬{idx+1}è¡Œæ‰¾åˆ°ï¼ˆéç¬¬69è¡Œï¼‰'
                                        }
                                        return result
                                except ValueError:
                                    continue
                        break
            except Exception as e:
                logger.warning(f"åˆ†æç¬¬{idx+1}è¡Œæ—¶å‡ºé”™: {str(e)}")
                continue
    
    # è°ƒè¯•ä¿¡æ¯
    result['debug_info'] = {
        'total_rows': len(processed_df),
        'checked_row_69': len(processed_df) > target_row_index,
        'row_69_content': str(processed_df.iloc[target_row_index].iloc[0]) if len(processed_df) > target_row_index else 'N/A'
    }
    
    return result

def verify_user_permission(store_name: str, user_id: str, permissions_data: Optional[pd.DataFrame]) -> bool:
    """éªŒè¯ç”¨æˆ·æƒé™"""
    if permissions_data is None or len(permissions_data.columns) < 2:
        logger.warning("æƒé™æ•°æ®æ— æ•ˆ")
        return False
    
    try:
        store_col = permissions_data.columns[0]
        id_col = permissions_data.columns[1]
        
        # æ¸…ç†è¾“å…¥æ•°æ®
        store_name = str(store_name).strip()
        user_id = str(user_id).strip()
        
        for _, row in permissions_data.iterrows():
            try:
                stored_store = str(row[store_col]).strip()
                stored_id = str(row[id_col]).strip()
                
                # é—¨åº—åç§°æ¨¡ç³ŠåŒ¹é… + ç”¨æˆ·IDç²¾ç¡®åŒ¹é…
                store_match = (store_name in stored_store or stored_store in store_name)
                id_match = (stored_id == user_id)
                
                if store_match and id_match:
                    logger.info(f"æƒé™éªŒè¯é€šè¿‡: {store_name} - {user_id}")
                    return True
                    
            except Exception as e:
                logger.warning(f"æ£€æŸ¥æƒé™è¡Œæ—¶å‡ºé”™: {str(e)}")
                continue
        
        logger.warning(f"æƒé™éªŒè¯å¤±è´¥: {store_name} - {user_id}")
        return False
        
    except Exception as e:
        logger.error(f"æƒé™éªŒè¯å‡ºé”™: {str(e)}")
        return False

def find_matching_stores(store_name: str, store_list: List[str]) -> List[str]:
    """æŸ¥æ‰¾åŒ¹é…çš„é—¨åº—"""
    if not store_name or not store_list:
        return []
    
    matching = []
    store_name = str(store_name).strip()
    
    for store in store_list:
        store = str(store).strip()
        if store_name in store or store in store_name:
            matching.append(store)
    
    return sorted(matching)

def show_status_message(message: str, status_type: str = "info"):
    """æ˜¾ç¤ºçŠ¶æ€æ¶ˆæ¯"""
    css_class = f"status-{status_type}"
    st.markdown(f'<div class="{css_class}">{message}</div>', unsafe_allow_html=True)

def init_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    defaults = {
        'logged_in': False,
        'store_name': "",
        'user_id': "",
        'is_admin': False,
        'cos_client': None,
        'operation_status': [],
        'reports_uploader_key': 'initial_reports_uploader_key',
        'permissions_uploader_key': 'initial_permissions_uploader_key',
        'show_diagnosis': False,
        'debug_mode': False
    }
    
    for key, default_value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

# ä¸»ç¨‹åºå¼€å§‹
def main():
    try:
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        init_session_state()
        
        # ä¸»æ ‡é¢˜
        st.markdown('<h1 class="main-header">ğŸ“Š é—¨åº—æŠ¥è¡¨æŸ¥è¯¢ç³»ç»Ÿ</h1>', unsafe_allow_html=True)
        
        # åˆå§‹åŒ–è…¾è®¯äº‘COSå®¢æˆ·ç«¯
        if not st.session_state.cos_client:
            try:
                with st.spinner("æ­£åœ¨è¿æ¥è…¾è®¯äº‘å­˜å‚¨..."):
                    cos_client, bucket_name, permissions_file = get_cos_client()
                    st.session_state.cos_client = (cos_client, bucket_name, permissions_file)
                    show_status_message("âœ… è…¾è®¯äº‘å­˜å‚¨è¿æ¥æˆåŠŸï¼", "success")
            except Exception as e:
                show_status_message(f"âŒ è¿æ¥å¤±è´¥: {str(e)}", "error")
                st.error("è¯·æ£€æŸ¥ secrets.toml ä¸­çš„è…¾è®¯äº‘é…ç½®æ˜¯å¦æ­£ç¡®")
                st.stop()
        
        cos_client, bucket_name, permissions_file = st.session_state.cos_client
        
        # æ˜¾ç¤ºæ“ä½œçŠ¶æ€
        for status in st.session_state.operation_status:
            show_status_message(status['message'], status['type'])
        
        # ä¾§è¾¹æ 
        with st.sidebar:
            st.title("âš™ï¸ ç³»ç»ŸåŠŸèƒ½")
            
            # ç³»ç»ŸçŠ¶æ€
            st.subheader("ğŸ“¡ ç³»ç»ŸçŠ¶æ€")
            if cos_client:
                st.success("ğŸŸ¢ è…¾è®¯äº‘å­˜å‚¨å·²è¿æ¥")
            else:
                st.error("ğŸ”´ è…¾è®¯äº‘å­˜å‚¨æ–­å¼€")
            
            # è°ƒè¯•é€‰é¡¹
            st.subheader("ğŸ”§ è°ƒè¯•é€‰é¡¹")
            debug_mode = st.checkbox("å¯ç”¨è¯¦ç»†è°ƒè¯•", value=st.session_state.debug_mode)
            st.session_state.debug_mode = debug_mode
            
            if debug_mode:
                if st.button("ğŸ” å¯¹æ¯”æ–‡ä»¶å±æ€§"):
                    if st.session_state.logged_in:
                        compare_file_properties(cos_client, bucket_name, permissions_file, st.session_state.store_name)
                
                if st.button("ğŸ”„ å¼ºåˆ¶é‡æ–°åŠ è½½æƒé™è¡¨"):
                    clear_permissions_cache()
                    with st.spinner("é‡æ–°åŠ è½½æƒé™è¡¨..."):
                        new_data = load_permissions_from_cos_enhanced_v2(cos_client, bucket_name, permissions_file, force_reload=True)
                        if new_data is not None:
                            st.success(f"âœ… æƒé™è¡¨é‡æ–°åŠ è½½æˆåŠŸ: {len(new_data)} æ¡")
                        else:
                            st.error("âŒ æƒé™è¡¨é‡æ–°åŠ è½½å¤±è´¥")
                
                if st.button("ğŸ”„ é‡æ–°ä¸Šä¼ æƒé™è¡¨"):
                    st.warning("âš ï¸ æ­¤æ“ä½œå°†ä½¿ç”¨ç»Ÿä¸€çš„é‡è¯•æœºåˆ¶é‡æ–°ä¸Šä¼ æƒé™è¡¨ï¼Œå¯èƒ½ä¼šè§£å†³æ–‡ä»¶æŸåé—®é¢˜")
                    
                    # åˆ›å»ºç¡®è®¤æŒ‰é’®
                    confirm_key = f"confirm_reupload_{datetime.now().timestamp()}"
                    if st.button("âœ… ç¡®è®¤é‡æ–°ä¸Šä¼ ", type="primary", key=confirm_key):
                        # é¦–å…ˆå°è¯•è¯»å–ç°æœ‰æ•°æ®
                        try:
                            st.info("ğŸ“– æ­£åœ¨è¯»å–ç°æœ‰æƒé™æ•°æ®...")
                            
                            # å°è¯•ç›´æ¥ä»CSVæ ¼å¼è¯»å–ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            csv_file = permissions_file.replace('.xlsx', '.csv')
                            if '/' not in csv_file:
                                csv_paths = [csv_file, f"permissions/{csv_file}"]
                            else:
                                csv_paths = [csv_file]
                            
                            existing_data = None
                            for csv_path in csv_paths:
                                try:
                                    response = cos_client.get_object(Bucket=bucket_name, Key=csv_path)
                                    csv_content = response['Body'].read().decode('utf-8-sig')
                                    existing_data = pd.read_csv(io.StringIO(csv_content))
                                    st.success(f"âœ… ä»CSVæ ¼å¼è¯»å–æˆåŠŸ: {csv_path}")
                                    break
                                except Exception:
                                    continue
                            
                            if existing_data is None:
                                # å¦‚æœCSVä¸å­˜åœ¨ï¼Œå°è¯•å¼ºåˆ¶è¯»å–Excelï¼ˆå¯èƒ½ä¼šå¤±è´¥ï¼‰
                                st.info("ğŸ”„ CSVä¸å­˜åœ¨ï¼Œå°è¯•å¼ºåˆ¶è¯»å–Excel...")
                                existing_data = load_permissions_from_cos_enhanced_v2(cos_client, bucket_name, permissions_file, force_reload=True)
                            
                            if existing_data is not None and len(existing_data) > 0:
                                # ä½¿ç”¨ç°æœ‰æ•°æ®é‡æ–°ä¸Šä¼ 
                                st.info("ğŸ“¤ ä½¿ç”¨ç°æœ‰æ•°æ®é‡æ–°ä¸Šä¼ ...")
                                
                                # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
                                if len(existing_data.columns) >= 2:
                                    # åªå–å‰ä¸¤åˆ—
                                    upload_data = existing_data.iloc[:, :2].copy()
                                    upload_data.columns = ['é—¨åº—åç§°', 'äººå‘˜ç¼–å·']
                                    
                                    # æ¸…ç†æ•°æ®
                                    upload_data = upload_data.dropna().astype(str)
                                    upload_data = upload_data[
                                        (upload_data['é—¨åº—åç§°'] != '') & 
                                        (upload_data['äººå‘˜ç¼–å·'] != '') &
                                        (upload_data['é—¨åº—åç§°'] != 'nan') &
                                        (upload_data['äººå‘˜ç¼–å·'] != 'nan')
                                    ]
                                    
                                    if len(upload_data) > 0:
                                        st.info(f"ğŸ”„ å‡†å¤‡é‡æ–°ä¸Šä¼  {len(upload_data)} æ¡æƒé™è®°å½•...")
                                        
                                        if save_permissions_to_cos(upload_data, cos_client, bucket_name, permissions_file):
                                            st.success("âœ… æƒé™è¡¨é‡æ–°ä¸Šä¼ æˆåŠŸï¼æ–‡ä»¶æŸåé—®é¢˜å·²è§£å†³ã€‚")
                                            # æ¸…é™¤ç¼“å­˜
                                            clear_permissions_cache()
                                            st.balloons()
                                        else:
                                            st.error("âŒ æƒé™è¡¨é‡æ–°ä¸Šä¼ å¤±è´¥")
                                    else:
                                        st.error("âŒ æ•°æ®æ¸…ç†åä¸ºç©ºï¼Œæ— æ³•é‡æ–°ä¸Šä¼ ")
                                else:
                                    st.error("âŒ æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•é‡æ–°ä¸Šä¼ ")
                            else:
                                st.error("âŒ æ— æ³•è¯»å–ç°æœ‰æƒé™æ•°æ®ï¼Œè¯·æ‰‹åŠ¨ä¸Šä¼ æ–°çš„æƒé™è¡¨")
                                st.info("ğŸ’¡ å»ºè®®ï¼šè¯·åœ¨ç®¡ç†å‘˜é¢æ¿ä¸­é‡æ–°ä¸Šä¼ æƒé™è¡¨æ–‡ä»¶")
                                
                        except Exception as e:
                            st.error(f"âŒ é‡æ–°ä¸Šä¼ å¤±è´¥: {str(e)}")
                            st.info("ğŸ’¡ å»ºè®®ï¼šè¯·åœ¨ç®¡ç†å‘˜é¢æ¿ä¸­é‡æ–°ä¸Šä¼ æƒé™è¡¨æ–‡ä»¶")
                
                if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
                    cache_keys = [key for key in st.session_state.keys() if key.startswith('cache_')]
                    for key in cache_keys:
                        del st.session_state[key]
                    st.success("âœ… æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤")
                    st.rerun()
            
            # ç”¨æˆ·ç±»å‹é€‰æ‹©
            user_type = st.radio("é€‰æ‹©ç”¨æˆ·ç±»å‹", ["æ™®é€šç”¨æˆ·", "ç®¡ç†å‘˜"])
            
            if user_type == "ç®¡ç†å‘˜":
                st.subheader("ğŸ” ç®¡ç†å‘˜ç™»å½•")
                admin_password = st.text_input("ç®¡ç†å‘˜å¯†ç ", type="password")
                
                if st.button("éªŒè¯ç®¡ç†å‘˜èº«ä»½"):
                    if admin_password == ADMIN_PASSWORD:
                        st.session_state.is_admin = True
                        show_status_message("âœ… ç®¡ç†å‘˜éªŒè¯æˆåŠŸï¼", "success")
                        st.rerun()
                    else:
                        show_status_message("âŒ å¯†ç é”™è¯¯ï¼", "error")
                
                if st.session_state.is_admin:
                    st.subheader("ğŸ“ æ–‡ä»¶ç®¡ç†")
                    
                    # ä¸Šä¼ æƒé™è¡¨
                    permissions_file_upload = st.file_uploader(
                        "ä¸Šä¼ é—¨åº—æƒé™è¡¨", 
                        type=['xlsx', 'xls'],
                        key=st.session_state.permissions_uploader_key,
                        help="Excelæ–‡ä»¶ï¼Œéœ€åŒ…å«é—¨åº—åç§°å’Œäººå‘˜ç¼–å·ä¸¤åˆ—"
                    )
                    
                    if permissions_file_upload:
                        try:
                            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                            file_hash = hashlib.md5(permissions_file_upload.getvalue()).hexdigest()
                            
                            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
                            if ("last_permissions_hash" in st.session_state and 
                                st.session_state.last_permissions_hash == file_hash and 
                                st.session_state.get("permissions_upload_successful", False)):
                                st.info("â„¹ï¸ è¯¥æƒé™è¡¨å·²æˆåŠŸå¤„ç†ï¼Œæ— éœ€é‡å¤æ“ä½œã€‚")
                            else:
                                st.session_state.last_permissions_hash = file_hash
                                st.session_state.permissions_upload_successful = False
                                
                                with st.spinner("åˆ†æExcelæ–‡ä»¶ç»“æ„..."):
                                    # å°è¯•è¯»å–Excelæ–‡ä»¶çš„æ‰€æœ‰å·¥ä½œè¡¨
                                    excel_file = pd.ExcelFile(permissions_file_upload)
                                    st.info(f"ğŸ“„ å‘ç° {len(excel_file.sheet_names)} ä¸ªå·¥ä½œè¡¨ï¼š{excel_file.sheet_names}")
                                    
                                    # è®©ç”¨æˆ·é€‰æ‹©å·¥ä½œè¡¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼‰
                                    if len(excel_file.sheet_names) > 1:
                                        selected_sheet = st.selectbox(
                                            "é€‰æ‹©åŒ…å«æƒé™æ•°æ®çš„å·¥ä½œè¡¨ï¼š", 
                                            excel_file.sheet_names,
                                            key="permission_sheet_selector"
                                        )
                                    else:
                                        selected_sheet = excel_file.sheet_names[0]
                                    
                                    # è¯»å–é€‰å®šçš„å·¥ä½œè¡¨
                                    df_raw = pd.read_excel(permissions_file_upload, sheet_name=selected_sheet)
                                    st.info(f"ğŸ“Š åŸå§‹æ•°æ®ï¼š{len(df_raw)} è¡Œ Ã— {len(df_raw.columns)} åˆ—")
                                    
                                    # æ˜¾ç¤ºåŸå§‹æ•°æ®çš„å‰å‡ è¡Œï¼Œå¸®åŠ©ç”¨æˆ·ç¡®è®¤æ•°æ®ç»“æ„
                                    st.subheader("ğŸ” åŸå§‹æ•°æ®é¢„è§ˆ")
                                    st.dataframe(df_raw.head(10), use_container_width=True)
                                    
                                    # è®©ç”¨æˆ·é€‰æ‹©åŒ…å«æƒé™æ•°æ®çš„åˆ—
                                    if len(df_raw.columns) >= 2:
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            store_column = st.selectbox(
                                                "é€‰æ‹©é—¨åº—åç§°åˆ—ï¼š",
                                                df_raw.columns.tolist(),
                                                index=0,
                                                key="store_column_selector"
                                            )
                                        with col2:
                                            user_column = st.selectbox(
                                                "é€‰æ‹©äººå‘˜ç¼–å·åˆ—ï¼š",
                                                df_raw.columns.tolist(),
                                                index=1 if len(df_raw.columns) > 1 else 0,
                                                key="user_column_selector"
                                            )
                                        
                                        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨å¤´è¡Œéœ€è¦è·³è¿‡
                                        header_row = st.number_input(
                                            "æ•°æ®å¼€å§‹è¡Œï¼ˆ0è¡¨ç¤ºç¬¬ä¸€è¡Œï¼‰ï¼š",
                                            min_value=0,
                                            max_value=len(df_raw)-1,
                                            value=0,
                                            key="header_row_selector"
                                        )
                                        
                                        if st.button("ğŸš€ å¼€å§‹å¤„ç†æƒé™æ•°æ®", key="process_permissions"):
                                            try:
                                                # é‡æ–°è¯»å–Excelï¼Œè·³è¿‡æŒ‡å®šçš„è¡¨å¤´è¡Œ
                                                if header_row > 0:
                                                    df_processed = pd.read_excel(
                                                        permissions_file_upload, 
                                                        sheet_name=selected_sheet,
                                                        skiprows=header_row
                                                    )
                                                else:
                                                    df_processed = df_raw.copy()
                                                
                                                # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼Œç¡®ä¿é—¨åº—åç§°å’Œäººå‘˜ç¼–å·åœ¨å‰ä¸¤åˆ—
                                                df = pd.DataFrame({
                                                    'é—¨åº—åç§°': df_processed[store_column],
                                                    'äººå‘˜ç¼–å·': df_processed[user_column]
                                                })
                                                
                                                st.info(f"ğŸ”„ å¤„ç†åæ•°æ®ï¼š{len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
                                                
                                                with st.spinner("ä¿å­˜åˆ°è…¾è®¯äº‘..."):
                                                    if save_permissions_to_cos(df, cos_client, bucket_name, permissions_file):
                                                        st.session_state.permissions_upload_successful = True
                                                        st.balloons()
                                                        
                                                        # é‡ç½®ä¸Šä¼ å™¨
                                                        st.session_state.permissions_uploader_key = f"{datetime.now().timestamp()}_permissions"
                                                        st.rerun()
                                                    else:
                                                        show_status_message("âŒ ä¿å­˜å¤±è´¥", "error")
                                                        st.session_state.permissions_upload_successful = False
                                            
                                            except Exception as e:
                                                show_status_message(f"âŒ æ•°æ®å¤„ç†å¤±è´¥ï¼š{str(e)}", "error")
                                                st.session_state.permissions_upload_successful = False
                                    
                                    else:
                                        show_status_message("âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼šéœ€è¦è‡³å°‘ä¸¤åˆ—æ•°æ®", "error")
                                        st.session_state.permissions_upload_successful = False
                        
                        except Exception as e:
                            show_status_message(f"âŒ æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}", "error")
                            st.session_state.permissions_upload_successful = False
                    
                    # ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨
                    reports_file_upload = st.file_uploader(
                        "ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨", 
                        type=['xlsx', 'xls'],
                        key=st.session_state.reports_uploader_key,
                        help="Excelæ–‡ä»¶ï¼Œæ¯ä¸ªå·¥ä½œè¡¨ä»£è¡¨ä¸€ä¸ªé—¨åº—çš„æŠ¥è¡¨"
                    )
                    
                    if reports_file_upload:
                        try:
                            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                            file_hash = hashlib.md5(reports_file_upload.getvalue()).hexdigest()
                            
                            # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
                            if ("last_reports_hash" in st.session_state and 
                                st.session_state.last_reports_hash == file_hash and 
                                st.session_state.get("reports_upload_successful", False)):
                                st.info("â„¹ï¸ è¯¥æŠ¥è¡¨æ–‡ä»¶å·²æˆåŠŸå¤„ç†ï¼Œæ— éœ€é‡å¤æ“ä½œã€‚")
                            else:
                                st.session_state.last_reports_hash = file_hash
                                st.session_state.reports_upload_successful = False
                                
                                with st.spinner("å¤„ç†æŠ¥è¡¨æ–‡ä»¶..."):
                                    excel_file = pd.ExcelFile(reports_file_upload)
                                    reports_dict = {}
                                    
                                    for sheet in excel_file.sheet_names:
                                        try:
                                            df = pd.read_excel(reports_file_upload, sheet_name=sheet)
                                            if not df.empty:
                                                reports_dict[sheet] = df
                                                logger.info(f"è¯»å–å·¥ä½œè¡¨ '{sheet}': {len(df)} è¡Œ")
                                        except Exception as e:
                                            logger.warning(f"è·³è¿‡å·¥ä½œè¡¨ '{sheet}': {str(e)}")
                                            continue
                                    
                                    if reports_dict:
                                        with st.spinner("ä¿å­˜åˆ°è…¾è®¯äº‘..."):
                                            if save_reports_to_cos(reports_dict, cos_client, bucket_name):
                                                show_status_message(f"âœ… æŠ¥è¡¨å·²ä¸Šä¼ ï¼š{len(reports_dict)} ä¸ªé—¨åº—", "success")
                                                st.session_state.reports_upload_successful = True
                                                st.balloons()
                                                
                                                # é‡ç½®ä¸Šä¼ å™¨
                                                st.session_state.reports_uploader_key = f"{datetime.now().timestamp()}_reports"
                                                st.rerun()
                                            else:
                                                show_status_message("âŒ ä¿å­˜å¤±è´¥", "error")
                                                st.session_state.reports_upload_successful = False
                                    else:
                                        show_status_message("âŒ æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„å·¥ä½œè¡¨", "error")
                                        st.session_state.reports_upload_successful = False
                                        
                        except Exception as e:
                            show_status_message(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}", "error")
                            st.session_state.reports_upload_successful = False
                    
                    # ç¼“å­˜ç®¡ç†
                    st.subheader("ğŸ—‚ï¸ ç¼“å­˜ç®¡ç†")
                    if st.button("æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
                        cache_keys = [key for key in st.session_state.keys() if key.startswith('cache_')]
                        for key in cache_keys:
                            del st.session_state[key]
                        show_status_message("âœ… æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤", "success")
                        st.rerun()
            
            else:
                if st.session_state.logged_in:
                    st.subheader("ğŸ‘¤ å½“å‰ç™»å½•")
                    st.info(f"é—¨åº—ï¼š{st.session_state.store_name}")
                    st.info(f"ç¼–å·ï¼š{st.session_state.user_id}")
                    
                    if st.button("ğŸšª é€€å‡ºç™»å½•"):
                        st.session_state.logged_in = False
                        st.session_state.store_name = ""
                        st.session_state.user_id = ""
                        show_status_message("ğŸ‘‹ å·²é€€å‡ºç™»å½•", "success")
                        st.rerun()
        
        # æ¸…é™¤çŠ¶æ€æ¶ˆæ¯
        st.session_state.operation_status = []
        
        # ä¸»ç•Œé¢
        if user_type == "ç®¡ç†å‘˜" and st.session_state.is_admin:
            st.markdown('<div class="admin-panel"><h3>ğŸ‘¨â€ğŸ’¼ ç®¡ç†å‘˜æ§åˆ¶é¢æ¿</h3><p>æ•°æ®æ°¸ä¹…ä¿å­˜åœ¨è…¾è®¯äº‘ï¼Œæ”¯æŒé«˜æ•ˆå­˜å‚¨å’Œç¼“å­˜æœºåˆ¶</p><p>ğŸ”„ <strong>æ–°ç‰¹æ€§</strong>: é›†æˆäº†é‡è¯•æœºåˆ¶ï¼Œç¡®ä¿æ–‡ä»¶ä¸Šä¼ ä¸‹è½½çš„å®Œæ•´æ€§å’Œå¯é æ€§</p></div>', unsafe_allow_html=True)
            
            try:
                with st.spinner("åŠ è½½æ•°æ®ç»Ÿè®¡..."):
                    # ä½¿ç”¨æ–°çš„è¯»å–é€»è¾‘
                    if debug_mode:
                        st.subheader("ğŸ” æƒé™è¡¨åŠ è½½è¯Šæ–­")
                        permissions_data = load_permissions_from_cos_enhanced_v2(cos_client, bucket_name, permissions_file, force_reload=False)
                    else:
                        permissions_data = load_permissions_from_cos(cos_client, bucket_name, permissions_file)
                    
                    store_list = get_store_list_from_cos(cos_client, bucket_name)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    perms_count = len(permissions_data) if permissions_data is not None else 0
                    st.metric("æƒé™è¡¨ç”¨æˆ·æ•°", perms_count)
                with col2:
                    reports_count = len(store_list)
                    st.metric("æŠ¥è¡¨é—¨åº—æ•°", reports_count)
                with col3:
                    cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
                    st.metric("ç¼“å­˜é¡¹ç›®æ•°", cache_count)
                    
                # æ•°æ®é¢„è§ˆ
                if permissions_data is not None and len(permissions_data) > 0:
                    st.subheader("ğŸ‘¥ æƒé™æ•°æ®é¢„è§ˆ")
                    st.dataframe(permissions_data.head(10), use_container_width=True)
                    
                    if len(permissions_data) > 10:
                        st.caption(f"æ˜¾ç¤ºå‰10æ¡è®°å½•ï¼Œå…±{len(permissions_data)}æ¡")
                
                if store_list:
                    st.subheader("ğŸ“Š é—¨åº—åˆ—è¡¨é¢„è§ˆ")
                    st.write(f"å…±æœ‰ {len(store_list)} ä¸ªé—¨åº—")
                    
                    # æ˜¾ç¤ºå‰10ä¸ªé—¨åº—
                    display_stores = store_list[:10]
                    for i in range(0, len(display_stores), 5):
                        cols = st.columns(5)
                        for j, store in enumerate(display_stores[i:i+5]):
                            with cols[j]:
                                st.info(f"ğŸª {store}")
                    
                    if len(store_list) > 10:
                        st.caption(f"...ä»¥åŠå…¶ä»– {len(store_list) - 10} ä¸ªé—¨åº—")
                        
            except Exception as e:
                show_status_message(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}", "error")

        elif user_type == "ç®¡ç†å‘˜" and not st.session_state.is_admin:
            st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ç®¡ç†å‘˜å¯†ç ")

        else:
            if not st.session_state.logged_in:
                st.subheader("ğŸ” ç”¨æˆ·ç™»å½•")
                
                try:
                    with st.spinner("åŠ è½½æƒé™æ•°æ®..."):
                        # ä½¿ç”¨æ–°çš„è¯»å–é€»è¾‘
                        if debug_mode:
                            st.subheader("ğŸ” æƒé™è¡¨åŠ è½½è¯Šæ–­")
                            permissions_data = load_permissions_from_cos_enhanced_v2(cos_client, bucket_name, permissions_file, force_reload=False)
                        else:
                            permissions_data = load_permissions_from_cos(cos_client, bucket_name, permissions_file)
                    
                    if permissions_data is None:
                        st.warning("âš ï¸ ç³»ç»Ÿç»´æŠ¤ä¸­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
                    else:
                        stores = sorted(permissions_data[permissions_data.columns[0]].unique().tolist())
                        
                        with st.form("login_form"):
                            selected_store = st.selectbox("é€‰æ‹©é—¨åº—", stores)
                            user_id = st.text_input("äººå‘˜ç¼–å·")
                            submit = st.form_submit_button("ğŸš€ ç™»å½•")
                            
                            if submit and selected_store and user_id:
                                if verify_user_permission(selected_store, user_id, permissions_data):
                                    st.session_state.logged_in = True
                                    st.session_state.store_name = selected_store
                                    st.session_state.user_id = user_id
                                    show_status_message("âœ… ç™»å½•æˆåŠŸï¼", "success")
                                    st.balloons()
                                    st.rerun()
                                else:
                                    show_status_message("âŒ é—¨åº—æˆ–ç¼–å·é”™è¯¯ï¼", "error")
                                    
                except Exception as e:
                    show_status_message(f"âŒ æƒé™éªŒè¯å¤±è´¥ï¼š{str(e)}", "error")
            
            else:
                # å·²ç™»å½• - æ˜¾ç¤ºæŠ¥è¡¨
                st.markdown(f'<div class="store-info"><h3>ğŸª {st.session_state.store_name}</h3><p>æ“ä½œå‘˜ï¼š{st.session_state.user_id}</p></div>', unsafe_allow_html=True)
                
                try:
                    with st.spinner("åŠ è½½é—¨åº—åˆ—è¡¨..."):
                        store_list = get_store_list_from_cos(cos_client, bucket_name)
                        matching_stores = find_matching_stores(st.session_state.store_name, store_list)
                    
                    if matching_stores:
                        if len(matching_stores) > 1:
                            selected_store = st.selectbox("é€‰æ‹©æŠ¥è¡¨", matching_stores)
                        else:
                            selected_store = matching_stores[0]
                        
                        # ä½¿ç”¨æ–°çš„æŠ¥è¡¨è¯»å–é€»è¾‘
                        if debug_mode:
                            st.subheader("ğŸ” æŠ¥è¡¨åŠ è½½è¯Šæ–­")
                            df = get_single_report_from_cos_v2(cos_client, bucket_name, selected_store)
                        else:
                            with st.spinner(f"åŠ è½½ {selected_store} çš„æŠ¥è¡¨æ•°æ®..."):
                                df = get_single_report_from_cos(cos_client, bucket_name, selected_store)
                        
                        if df is not None:
                            # åº”æ”¶-æœªæ”¶é¢çœ‹æ¿
                            st.subheader("ğŸ’° åº”æ”¶-æœªæ”¶é¢")
                            
                            try:
                                analysis_results = analyze_receivable_data(df)
                                
                                if 'åº”æ”¶-æœªæ”¶é¢' in analysis_results:
                                    data = analysis_results['åº”æ”¶-æœªæ”¶é¢']
                                    amount = data['amount']
                                    
                                    col1, col2, col3 = st.columns([1, 2, 1])
                                    with col2:
                                        if amount > 0:
                                            st.markdown(f'''
                                                <div class="receivable-positive">
                                                    <h1 style="margin: 0; font-size: 3rem;">ğŸ’³ Â¥{amount:,.2f}</h1>
                                                    <h3 style="margin: 0.5rem 0;">é—¨åº—åº”ä»˜æ¬¾</h3>
                                                    <p style="margin: 0; font-size: 0.9rem;">æ•°æ®æ¥æº: {data['row_name']} (ç¬¬{data['actual_row_number']}è¡Œ)</p>
                                                </div>
                                            ''', unsafe_allow_html=True)
                                        
                                        elif amount < 0:
                                            st.markdown(f'''
                                                <div class="receivable-negative">
                                                    <h1 style="margin: 0; font-size: 3rem;">ğŸ’š Â¥{abs(amount):,.2f}</h1>
                                                    <h3 style="margin: 0.5rem 0;">æ€»éƒ¨åº”é€€æ¬¾</h3>
                                                    <p style="margin: 0; font-size: 0.9rem;">æ•°æ®æ¥æº: {data['row_name']} (ç¬¬{data['actual_row_number']}è¡Œ)</p>
                                                </div>
                                            ''', unsafe_allow_html=True)
                                        
                                        else:
                                            st.markdown('''
                                                <div style="background: #e8f5e8; color: #2e7d32; padding: 2rem; border-radius: 15px; text-align: center;">
                                                    <h1 style="margin: 0; font-size: 3rem;">âš–ï¸ Â¥0.00</h1>
                                                    <h3 style="margin: 0.5rem 0;">æ”¶æ”¯å¹³è¡¡</h3>
                                                    <p style="margin: 0;">åº”æ”¶æœªæ”¶é¢ä¸ºé›¶ï¼Œè´¦ç›®å¹³è¡¡</p>
                                                </div>
                                            ''', unsafe_allow_html=True)
                                
                                else:
                                    st.warning("âš ï¸ æœªæ‰¾åˆ°åº”æ”¶-æœªæ”¶é¢æ•°æ®")
                                    
                                    if debug_mode:
                                        with st.expander("ğŸ” æŸ¥çœ‹è¯¦æƒ…", expanded=False):
                                            debug_info = analysis_results.get('debug_info', {})
                                            
                                            st.markdown("### ğŸ“‹ æ•°æ®æŸ¥æ‰¾è¯´æ˜")
                                            st.write(f"- **æŠ¥è¡¨æ€»è¡Œæ•°ï¼š** {debug_info.get('total_rows', 0)} è¡Œ")
                                            
                                            if debug_info.get('checked_row_69'):
                                                st.write(f"- **ç¬¬69è¡Œå†…å®¹ï¼š** {debug_info.get('row_69_content', 'N/A')}")
                                            else:
                                                st.write("- **ç¬¬69è¡Œï¼š** æŠ¥è¡¨è¡Œæ•°ä¸è¶³69è¡Œ")
                                            
                                            st.markdown("""
                                            ### ğŸ’¡ å¯èƒ½çš„åŸå› 
                                            1. ç¬¬69è¡Œä¸åŒ…å«"åº”æ”¶-æœªæ”¶é¢"ç›¸å…³å…³é”®è¯
                                            2. ç¬¬69è¡Œçš„æ•°å€¼ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®
                                            3. æŠ¥è¡¨æ ¼å¼ä¸é¢„æœŸä¸ç¬¦
                                            
                                            ### ğŸ› ï¸ å»ºè®®
                                            - è¯·æ£€æŸ¥ExcelæŠ¥è¡¨ç¬¬69è¡Œæ˜¯å¦åŒ…å«"åº”æ”¶-æœªæ”¶é¢"
                                            - ç¡®è®¤è¯¥è¡Œæœ‰å¯¹åº”çš„é‡‘é¢æ•°æ®
                                            - å¦‚éœ€è°ƒæ•´æŸ¥æ‰¾ä½ç½®ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ
                                            """)
                            
                            except Exception as e:
                                show_status_message(f"âŒ åˆ†ææ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}", "error")
                            
                            st.divider()
                            
                            # å®Œæ•´æŠ¥è¡¨æ•°æ®
                            st.subheader("ğŸ“‹ å®Œæ•´æŠ¥è¡¨æ•°æ®")
                            
                            search_term = st.text_input("ğŸ” æœç´¢æŠ¥è¡¨å†…å®¹")
                            
                            try:
                                if search_term:
                                    search_df = df.copy()
                                    for col in search_df.columns:
                                        search_df[col] = search_df[col].astype(str).fillna('')
                                    
                                    mask = search_df.apply(
                                        lambda x: x.str.contains(search_term, case=False, na=False, regex=False)
                                    ).any(axis=1)
                                    filtered_df = df[mask]
                                    st.info(f"æ‰¾åˆ° {len(filtered_df)} æ¡åŒ…å« '{search_term}' çš„è®°å½•")
                                else:
                                    filtered_df = df
                                
                                st.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼šå…± {len(filtered_df)} æ¡è®°å½•ï¼Œ{len(df.columns)} åˆ—")
                                
                                if len(filtered_df) > 0:
                                    display_df = filtered_df.copy()
                                    
                                    # ç¡®ä¿åˆ—åå”¯ä¸€
                                    unique_columns = []
                                    for i, col in enumerate(display_df.columns):
                                        col_name = str(col)
                                        if col_name in unique_columns:
                                            col_name = f"{col_name}_{i}"
                                        unique_columns.append(col_name)
                                    display_df.columns = unique_columns
                                    
                                    # æ¸…ç†æ•°æ®å†…å®¹
                                    for col in display_df.columns:
                                        display_df[col] = display_df[col].astype(str).fillna('')
                                    
                                    st.dataframe(display_df, use_container_width=True, height=400)
                                
                                else:
                                    st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
                                    
                            except Exception as e:
                                show_status_message(f"âŒ æ•°æ®å¤„ç†æ—¶å‡ºé”™ï¼š{str(e)}", "error")
                            
                            # ä¸‹è½½åŠŸèƒ½
                            st.subheader("ğŸ“¥ æ•°æ®ä¸‹è½½")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                try:
                                    buffer = io.BytesIO()
                                    download_df = df.copy()
                                    
                                    # ç¡®ä¿åˆ—åå”¯ä¸€
                                    unique_cols = []
                                    for i, col in enumerate(download_df.columns):
                                        col_name = str(col)
                                        if col_name in unique_cols:
                                            col_name = f"{col_name}_{i}"
                                        unique_cols.append(col_name)
                                    download_df.columns = unique_cols
                                    
                                    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                        download_df.to_excel(writer, index=False)
                                    
                                    st.download_button(
                                        "ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥è¡¨ (Excel)",
                                        buffer.getvalue(),
                                        f"{st.session_state.store_name}_æŠ¥è¡¨_{datetime.now().strftime('%Y%m%d')}.xlsx",
                                        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                                except Exception as e:
                                    show_status_message(f"Excelä¸‹è½½å‡†å¤‡å¤±è´¥ï¼š{str(e)}", "error")
                            
                            with col2:
                                try:
                                    csv_df = df.copy()
                                    unique_cols = []
                                    for i, col in enumerate(csv_df.columns):
                                        col_name = str(col)
                                        if col_name in unique_cols:
                                            col_name = f"{col_name}_{i}"
                                        unique_cols.append(col_name)
                                    csv_df.columns = unique_cols
                                    
                                    csv = csv_df.to_csv(index=False, encoding='utf-8-sig')
                                    st.download_button(
                                        "ğŸ“¥ ä¸‹è½½CSVæ ¼å¼",
                                        csv,
                                        f"{st.session_state.store_name}_æŠ¥è¡¨_{datetime.now().strftime('%Y%m%d')}.csv",
                                        "text/csv"
                                    )
                                except Exception as e:
                                    show_status_message(f"CSVä¸‹è½½å‡†å¤‡å¤±è´¥ï¼š{str(e)}", "error")
                        
                        else:
                            st.error(f"âŒ æ— æ³•åŠ è½½é—¨åº— '{selected_store}' çš„æŠ¥è¡¨æ•°æ®")
                        
                    else:
                        st.error(f"âŒ æœªæ‰¾åˆ°é—¨åº— '{st.session_state.store_name}' çš„æŠ¥è¡¨")
                        
                except Exception as e:
                    show_status_message(f"âŒ æŠ¥è¡¨åŠ è½½å¤±è´¥ï¼š{str(e)}", "error")
        
        # é¡µé¢åº•éƒ¨çŠ¶æ€ä¿¡æ¯
        st.divider()
        col1, col2, col3 = st.columns(3)
        with col1:
            st.caption(f"ğŸ•’ å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        with col2:
            cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
            st.caption(f"ğŸ’¾ ç¼“å­˜é¡¹ç›®: {cache_count}")
        with col3:
            st.caption("ğŸ”§ ç‰ˆæœ¬: v4.1 (é‡è¯•æœºåˆ¶å¢å¼ºç‰ˆ)")

    except Exception as e:
        st.error(f"ç³»ç»Ÿè¿è¡Œæ—¶å‡ºé”™: {str(e)}")
        logger.error(f"Main function error: {str(e)}")
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    main()
