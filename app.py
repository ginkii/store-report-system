import streamlit as st
import pandas as pd
import io
import json
from datetime import datetime
import time
import logging
from typing import Optional, Dict, Any, List
import hashlib
import pickle
import traceback
from contextlib import contextmanager
from qcloud_cos import CosConfig, CosS3Client
from qcloud_cos.cos_exception import CosServiceError
import openpyxl

# ÈÖçÁΩÆÊó•Âøó
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# È°µÈù¢ÈÖçÁΩÆ
st.set_page_config(
    page_title="Èó®Â∫óÊä•Ë°®Êü•ËØ¢Á≥ªÁªü", 
    page_icon="üìä",
    layout="wide"
)

# Á≥ªÁªüÈÖçÁΩÆ
ADMIN_PASSWORD = "admin123"
MAX_RETRIES = 3
RETRY_DELAY = 1
CACHE_DURATION = 300  # ÁºìÂ≠ò5ÂàÜÈíü

# CSSÊ†∑Âºè
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 2rem;
    }
    .store-info {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .admin-panel {
        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #fdcb6e;
        margin: 1rem 0;
    }
    .receivable-positive {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
        color: #721c24;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #f093fb;
        margin: 1rem 0;
        text-align: center;
    }
    .receivable-negative {
        background: linear-gradient(135deg, #a8edea 0%, #d299c2 100%);
        color: #0c4128;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #48cab2;
        margin: 1rem 0;
        text-align: center;
    }
    .status-success {
        background: #d4edda;
        color: #155724;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
        margin: 0.5rem 0;
    }
    .status-error {
        background: #f8d7da;
        color: #721c24;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #f5c6cb;
        margin: 0.5rem 0;
    }
    .status-warning {
        background: #fff3cd;
        color: #856404;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

class CosOperationError(Exception):
    """ËÖæËÆØ‰∫ëCOSÊìç‰ΩúÂºÇÂ∏∏"""
    pass

class DataProcessingError(Exception):
    """Êï∞ÊçÆÂ§ÑÁêÜÂºÇÂ∏∏"""
    pass

@contextmanager
def error_handler(operation_name: str):
    """ÈÄöÁî®ÈîôËØØÂ§ÑÁêÜ‰∏ä‰∏ãÊñáÁÆ°ÁêÜÂô®"""
    try:
        yield
    except Exception as e:
        logger.error(f"{operation_name} Â§±Ë¥•: {str(e)}")
        logger.error(traceback.format_exc())
        st.error(f"‚ùå {operation_name} Â§±Ë¥•: {str(e)}")
        raise

def retry_operation(func, *args, max_retries=MAX_RETRIES, delay=RETRY_DELAY, **kwargs):
    """ÈáçËØïÊìç‰ΩúË£ÖÈ•∞Âô®"""
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if attempt == max_retries - 1:
                logger.error(f"Êìç‰ΩúÂ§±Ë¥•ÔºåÂ∑≤ÈáçËØï {max_retries} Ê¨°: {str(e)}")
                raise
            logger.warning(f"Êìç‰ΩúÂ§±Ë¥•ÔºåÁ¨¨ {attempt + 1} Ê¨°ÈáçËØï: {str(e)}")
            time.sleep(delay * (attempt + 1))  # ÈÄíÂ¢ûÂª∂Ëøü

def get_cache_key(operation: str, params: str) -> str:
    """ÁîüÊàêÁºìÂ≠òÈîÆ"""
    return hashlib.md5(f"{operation}_{params}".encode()).hexdigest()

def set_cache(key: str, data: Any, duration: int = CACHE_DURATION):
    """ËÆæÁΩÆÁºìÂ≠ò"""
    try:
        cache_data = {
            'data': data,
            'timestamp': time.time(),
            'duration': duration
        }
        st.session_state[f"cache_{key}"] = cache_data
    except Exception as e:
        logger.warning(f"ËÆæÁΩÆÁºìÂ≠òÂ§±Ë¥•: {str(e)}")

def get_cache(key: str) -> Optional[Any]:
    """Ëé∑ÂèñÁºìÂ≠ò"""
    try:
        cache_key = f"cache_{key}"
        if cache_key in st.session_state:
            cache_data = st.session_state[cache_key]
            if time.time() - cache_data['timestamp'] < cache_data['duration']:
                return cache_data['data']
            else:
                del st.session_state[cache_key]
    except Exception as e:
        logger.warning(f"Ëé∑ÂèñÁºìÂ≠òÂ§±Ë¥•: {str(e)}")
    return None

@st.cache_resource(show_spinner="ËøûÊé•ËÖæËÆØ‰∫ëÂ≠òÂÇ®...")
def get_cos_client():
    """Ëé∑ÂèñËÖæËÆØ‰∫ëCOSÂÆ¢Êà∑Á´Ø - ‰ΩøÁî®ÁºìÂ≠ò"""
    try:
        cos_config = st.secrets["tencent_cloud"]
        
        config = CosConfig(
            Region=cos_config["region"],
            SecretId=cos_config["secret_id"],
            SecretKey=cos_config["secret_key"],
        )
        
        client = CosS3Client(config)
        logger.info("ËÖæËÆØ‰∫ëCOSÂÆ¢Êà∑Á´ØÂàõÂª∫ÊàêÂäü")
        return client, cos_config["bucket_name"], cos_config["permissions_file"]
    except Exception as e:
        logger.error(f"ËÖæËÆØ‰∫ëCOSÂÆ¢Êà∑Á´ØÂàõÂª∫Â§±Ë¥•: {str(e)}")
        raise CosOperationError(f"ËøûÊé•Â§±Ë¥•: {str(e)}")

def safe_cos_operation(operation_func, *args, **kwargs):
    """ÂÆâÂÖ®ÁöÑCOSÊìç‰Ωú"""
    return retry_operation(operation_func, *args, **kwargs)

def save_permissions_to_cos(df: pd.DataFrame, cos_client, bucket_name: str, permissions_file: str) -> bool:
    """‰øùÂ≠òÊùÉÈôêÊï∞ÊçÆÂà∞COS"""
    with error_handler("‰øùÂ≠òÊùÉÈôêÊï∞ÊçÆ"):
        def _save_operation():
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # ÂáÜÂ§áCSVÊï∞ÊçÆ
            csv_data = []
            csv_data.append(['Èó®Â∫óÂêçÁß∞', '‰∫∫ÂëòÁºñÂè∑', 'Êõ¥Êñ∞Êó∂Èó¥'])
            
            for _, row in df.iterrows():
                csv_data.append([
                    str(row.iloc[0]).strip(),
                    str(row.iloc[1]).strip(),
                    current_time
                ])
            
            # ËΩ¨Êç¢‰∏∫CSVÊ†ºÂºè
            csv_buffer = io.StringIO()
            pd.DataFrame(csv_data[1:], columns=csv_data[0]).to_csv(csv_buffer, index=False, encoding='utf-8-sig')
            csv_content = csv_buffer.getvalue()
            
            # ‰∏ä‰º†Âà∞COS
            cos_client.put_object(
                Bucket=bucket_name,
                Body=csv_content.encode('utf-8-sig'),
                Key=permissions_file,
                ContentType='text/csv'
            )
            
            logger.info(f"ÊùÉÈôêÊï∞ÊçÆ‰øùÂ≠òÊàêÂäü: {len(df)} Êù°ËÆ∞ÂΩï")
            
            # Ê∏ÖÈô§Áõ∏ÂÖ≥ÁºìÂ≠ò
            cache_key = get_cache_key("permissions", "load")
            if f"cache_{cache_key}" in st.session_state:
                del st.session_state[f"cache_{cache_key}"]
            
            return True
        
        return safe_cos_operation(_save_operation)

def load_permissions_from_cos(cos_client, bucket_name: str, permissions_file: str) -> Optional[pd.DataFrame]:
    """‰ªéCOSÂä†ËΩΩÊùÉÈôêÊï∞ÊçÆ - ‰ΩøÁî®ÁºìÂ≠ò"""
    cache_key = get_cache_key("permissions", "load")
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        logger.info("‰ªéÁºìÂ≠òÂä†ËΩΩÊùÉÈôêÊï∞ÊçÆ")
        return cached_data
    
    with error_handler("Âä†ËΩΩÊùÉÈôêÊï∞ÊçÆ"):
        def _load_operation():
            try:
                # ‰ªéCOS‰∏ãËΩΩÊñá‰ª∂
                response = cos_client.get_object(
                    Bucket=bucket_name,
                    Key=permissions_file
                )
                
                # ËØªÂèñCSVÂÜÖÂÆπ
                csv_content = response['Body'].read().decode('utf-8-sig')
                df = pd.read_csv(io.StringIO(csv_content))
                
                if len(df) == 0:
                    logger.info("ÊùÉÈôêË°®‰∏∫Á©∫")
                    return None
                
                result_df = df[['Èó®Â∫óÂêçÁß∞', '‰∫∫ÂëòÁºñÂè∑']].copy()
                
                # Êï∞ÊçÆÊ∏ÖÁêÜ
                result_df['Èó®Â∫óÂêçÁß∞'] = result_df['Èó®Â∫óÂêçÁß∞'].str.strip()
                result_df['‰∫∫ÂëòÁºñÂè∑'] = result_df['‰∫∫ÂëòÁºñÂè∑'].str.strip()
                
                # ÁßªÈô§Á©∫Ë°å
                result_df = result_df[
                    (result_df['Èó®Â∫óÂêçÁß∞'] != '') & 
                    (result_df['‰∫∫ÂëòÁºñÂè∑'] != '')
                ]
                
                logger.info(f"ÊùÉÈôêÊï∞ÊçÆÂä†ËΩΩÊàêÂäü: {len(result_df)} Êù°ËÆ∞ÂΩï")
                
                # ËÆæÁΩÆÁºìÂ≠ò
                set_cache(cache_key, result_df)
                return result_df
                
            except CosServiceError as e:
                if e.get_error_code() == 'NoSuchKey':
                    logger.info("ÊùÉÈôêÊñá‰ª∂‰∏çÂ≠òÂú®")
                    return None
                else:
                    raise e
        
        return safe_cos_operation(_load_operation)

def save_report_to_cos(df: pd.DataFrame, cos_client, bucket_name: str, store_name: str) -> bool:
    """‰øùÂ≠òÂçï‰∏™Èó®Â∫óÊä•Ë°®Âà∞COS"""
    try:
        # ÁîüÊàêÊñá‰ª∂Âêç
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"reports/{store_name}_{timestamp}.xlsx"
        
        # ÂàõÂª∫ExcelÊñá‰ª∂
        excel_buffer = io.BytesIO()
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name=store_name[:31])  # ExcelÂ∑•‰ΩúË°®ÂêçÊúÄÈïø31Â≠óÁ¨¶
        
        excel_content = excel_buffer.getvalue()
        
        # ‰∏ä‰º†Âà∞COS
        cos_client.put_object(
            Bucket=bucket_name,
            Body=excel_content,
            Key=filename,
            ContentType='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        
        logger.info(f"Êä•Ë°®‰øùÂ≠òÊàêÂäü: {store_name} -> {filename}")
        return True
        
    except Exception as e:
        logger.error(f"‰øùÂ≠ò {store_name} Êä•Ë°®Â§±Ë¥•: {str(e)}")
        return False

def save_reports_to_cos(reports_dict: Dict[str, pd.DataFrame], cos_client, bucket_name: str) -> bool:
    """‰øùÂ≠òÊä•Ë°®Êï∞ÊçÆÂà∞COS"""
    with error_handler("‰øùÂ≠òÊä•Ë°®Êï∞ÊçÆ"):
        def _save_operation():
            success_count = 0
            total_count = len(reports_dict)
            
            # ÊòæÁ§∫ËøõÂ∫¶
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, (store_name, df) in enumerate(reports_dict.items()):
                status_text.text(f"‰øùÂ≠ò {store_name}...")
                
                if save_report_to_cos(df, cos_client, bucket_name, store_name):
                    success_count += 1
                
                # Êõ¥Êñ∞ËøõÂ∫¶
                progress = (idx + 1) / total_count
                progress_bar.progress(progress)
                
                # APIÈôêÂà∂Âª∂Ëøü
                time.sleep(0.5)
            
            progress_bar.empty()
            status_text.empty()
            
            # Ê∏ÖÈô§Áõ∏ÂÖ≥ÁºìÂ≠ò
            cache_key = get_cache_key("reports", "load")
            if f"cache_{cache_key}" in st.session_state:
                del st.session_state[f"cache_{cache_key}"]
            
            logger.info(f"Êä•Ë°®Êï∞ÊçÆ‰øùÂ≠òÂÆåÊàê: {success_count}/{total_count}")
            return success_count == total_count
        
        return safe_cos_operation(_save_operation)

def load_reports_from_cos(cos_client, bucket_name: str) -> Dict[str, pd.DataFrame]:
    """‰ªéCOSÂä†ËΩΩÊä•Ë°®Êï∞ÊçÆ - ‰ΩøÁî®ÁºìÂ≠ò"""
    cache_key = get_cache_key("reports", "load")
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        logger.info("‰ªéÁºìÂ≠òÂä†ËΩΩÊä•Ë°®Êï∞ÊçÆ")
        return cached_data
    
    with error_handler("Âä†ËΩΩÊä•Ë°®Êï∞ÊçÆ"):
        def _load_operation():
            try:
                reports_dict = {}
                
                # ÂàóÂá∫reportsÁõÆÂΩï‰∏ãÁöÑÊâÄÊúâÊñá‰ª∂
                response = cos_client.list_objects(
                    Bucket=bucket_name,
                    Prefix='reports/',
                    MaxKeys=1000
                )
                
                if 'Contents' not in response:
                    logger.info("Êä•Ë°®ÁõÆÂΩï‰∏∫Á©∫")
                    return {}
                
                # Â§ÑÁêÜÊØè‰∏™ExcelÊñá‰ª∂
                for obj in response['Contents']:
                    key = obj['Key']
                    if key.endswith('.xlsx') and not key.endswith('/'):
                        try:
                            # ‰ªéÊñá‰ª∂ÂêçÊèêÂèñÈó®Â∫óÂêçÁß∞
                            filename = key.split('/')[-1]  # Ëé∑ÂèñÊñá‰ª∂Âêç
                            store_name = filename.split('_')[0]  # ÊèêÂèñÈó®Â∫óÂêçÁß∞
                            
                            # ‰∏ãËΩΩÊñá‰ª∂
                            file_response = cos_client.get_object(
                                Bucket=bucket_name,
                                Key=key
                            )
                            
                            # ËØªÂèñExcelÊñá‰ª∂
                            excel_content = file_response['Body'].read()
                            df = pd.read_excel(io.BytesIO(excel_content))
                            
                            # Êï∞ÊçÆÊ∏ÖÁêÜ - ‰øùÊåÅ‰∏éÂéü‰ª£Á†ÅÁõ∏ÂêåÁöÑÈÄªËæë
                            if len(df) > 0:
                                # Ê£ÄÊü•Á¨¨‰∏ÄË°åÊòØÂê¶ÊòØÈó®Â∫óÂêçÁß∞
                                first_row = df.iloc[0]
                                non_empty_count = sum(1 for val in first_row if pd.notna(val) and str(val).strip() != '')
                                
                                if non_empty_count <= 2 and len(df) > 1:
                                    df = df.iloc[1:].reset_index(drop=True)
                            
                            # Â§ÑÁêÜË°®Â§¥
                            if len(df) > 1:
                                header_row = df.iloc[0].fillna('').astype(str).tolist()
                                data_rows = df.iloc[1:].copy()
                                
                                # Ê∏ÖÁêÜÂàóÂêçÂπ∂Â§ÑÁêÜÈáçÂ§ç
                                cols = []
                                for i, col in enumerate(header_row):
                                    col = str(col).strip()
                                    if col == '' or col == 'nan' or col == '0':
                                        col = f'Âàó{i+1}' if i > 0 else 'È°πÁõÆÂêçÁß∞'
                                    
                                    # Â§ÑÁêÜÈáçÂ§çÂàóÂêç
                                    original_col = col
                                    counter = 1
                                    while col in cols:
                                        col = f"{original_col}_{counter}"
                                        counter += 1
                                    cols.append(col)
                                
                                # Á°Æ‰øùÂàóÊï∞ÂåπÈÖç
                                min_cols = min(len(data_rows.columns), len(cols))
                                cols = cols[:min_cols]
                                data_rows = data_rows.iloc[:, :min_cols]
                                
                                data_rows.columns = cols
                                df = data_rows.reset_index(drop=True).fillna('')
                            else:
                                # Â§ÑÁêÜÂ∞ë‰∫é3Ë°åÁöÑÊï∞ÊçÆ
                                df = df.fillna('')
                                default_cols = []
                                for i in range(len(df.columns)):
                                    col_name = f'Âàó{i+1}' if i > 0 else 'È°πÁõÆÂêçÁß∞'
                                    default_cols.append(col_name)
                                df.columns = default_cols
                            
                            reports_dict[store_name] = df
                            logger.info(f"Âä†ËΩΩÊä•Ë°®: {store_name} ({len(df)} Ë°å)")
                            
                        except Exception as e:
                            logger.warning(f"Ë∑≥ËøáÊñá‰ª∂ {key}: {str(e)}")
                            continue
                
                logger.info(f"Êä•Ë°®Êï∞ÊçÆÂä†ËΩΩÊàêÂäü: {len(reports_dict)} ‰∏™Èó®Â∫ó")
                
                # ËÆæÁΩÆÁºìÂ≠ò
                set_cache(cache_key, reports_dict)
                return reports_dict
                
            except CosServiceError as e:
                logger.error(f"COSÊìç‰ΩúÂ§±Ë¥•: {str(e)}")
                return {}
        
        return safe_cos_operation(_load_operation)

def analyze_receivable_data(df: pd.DataFrame) -> Dict[str, Any]:
    """ÂàÜÊûêÂ∫îÊî∂Êú™Êî∂È¢ùÊï∞ÊçÆ - ‰∏ìÈó®Êü•ÊâæÁ¨¨69Ë°å"""
    result = {}
    
    if len(df.columns) == 0 or len(df) == 0:
        return result
    
    # Ê£ÄÊü•Á¨¨‰∏ÄË°åÊòØÂê¶ÊòØÈó®Â∫óÂêçÁß∞
    original_df = df.copy()
    first_row = df.iloc[0] if len(df) > 0 else None
    if first_row is not None:
        non_empty_count = sum(1 for val in first_row if pd.notna(val) and str(val).strip() != '')
        if non_empty_count <= 2:
            df = df.iloc[1:].reset_index(drop=True)
            result['skipped_store_name_row'] = True
    
    # Êü•ÊâæÁ¨¨69Ë°å
    target_row_index = 68  # Á¨¨69Ë°å
    
    if len(df) > target_row_index:
        row = df.iloc[target_row_index]
        first_col_value = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
        
        # Ê£ÄÊü•ÂÖ≥ÈîÆËØç
        keywords = ['Â∫îÊî∂-Êú™Êî∂È¢ù', 'Â∫îÊî∂Êú™Êî∂È¢ù', 'Â∫îÊî∂-Êú™Êî∂', 'Â∫îÊî∂Êú™Êî∂']
        
        for keyword in keywords:
            if keyword in first_col_value:
                # Êü•ÊâæÊï∞ÂÄº
                for col_idx in range(len(row)-1, 0, -1):
                    val = row.iloc[col_idx]
                    if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                        cleaned = str(val).replace(',', '').replace('¬•', '').replace('Ôø•', '').strip()
                        
                        if cleaned.startswith('(') and cleaned.endswith(')'):
                            cleaned = '-' + cleaned[1:-1]
                        
                        try:
                            amount = float(cleaned)
                            if amount != 0:
                                result['Â∫îÊî∂-Êú™Êî∂È¢ù'] = {
                                    'amount': amount,
                                    'column_name': str(df.columns[col_idx]),
                                    'row_name': first_col_value,
                                    'row_index': target_row_index,
                                    'actual_row_number': target_row_index + 1
                                }
                                return result
                        except ValueError:
                            continue
                break
    
    # Â§áÁî®Êü•Êâæ
    if 'Â∫îÊî∂-Êú™Êî∂È¢ù' not in result:
        keywords = ['Â∫îÊî∂-Êú™Êî∂È¢ù', 'Â∫îÊî∂Êú™Êî∂È¢ù', 'Â∫îÊî∂-Êú™Êî∂', 'Â∫îÊî∂Êú™Êî∂']
        
        for idx, row in df.iterrows():
            try:
                row_name = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
                
                if not row_name.strip():
                    continue
                
                for keyword in keywords:
                    if keyword in row_name:
                        for col_idx in range(len(row)-1, 0, -1):
                            val = row.iloc[col_idx]
                            if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                                cleaned = str(val).replace(',', '').replace('¬•', '').replace('Ôø•', '').strip()
                                
                                if cleaned.startswith('(') and cleaned.endswith(')'):
                                    cleaned = '-' + cleaned[1:-1]
                                
                                try:
                                    amount = float(cleaned)
                                    if amount != 0:
                                        result['Â∫îÊî∂-Êú™Êî∂È¢ù'] = {
                                            'amount': amount,
                                            'column_name': str(df.columns[col_idx]),
                                            'row_name': row_name,
                                            'row_index': idx,
                                            'actual_row_number': idx + 1,
                                            'note': f'Âú®Á¨¨{idx+1}Ë°åÊâæÂà∞ÔºàÈùûÁ¨¨69Ë°åÔºâ'
                                        }
                                        return result
                                except ValueError:
                                    continue
                        break
            except Exception:
                continue
    
    # Ë∞ÉËØï‰ø°ÊÅØ
    result['debug_info'] = {
        'total_rows': len(df),
        'checked_row_69': len(df) > target_row_index,
        'row_69_content': str(df.iloc[target_row_index].iloc[0]) if len(df) > target_row_index else 'N/A'
    }
    
    return result

def verify_user_permission(store_name: str, user_id: str, permissions_data: Optional[pd.DataFrame]) -> bool:
    """È™åËØÅÁî®Êà∑ÊùÉÈôê"""
    if permissions_data is None or len(permissions_data.columns) < 2:
        return False
    
    store_col = permissions_data.columns[0]
    id_col = permissions_data.columns[1]
    
    for _, row in permissions_data.iterrows():
        stored_store = str(row[store_col]).strip()
        stored_id = str(row[id_col]).strip()
        
        if (store_name in stored_store or stored_store in store_name) and stored_id == str(user_id):
            return True
    
    return False

def find_matching_reports(store_name: str, reports_data: Dict[str, pd.DataFrame]) -> List[str]:
    """Êü•ÊâæÂåπÈÖçÁöÑÊä•Ë°®"""
    matching = []
    for sheet_name in reports_data.keys():
        if store_name in sheet_name or sheet_name in store_name:
            matching.append(sheet_name)
    return matching

def show_status_message(message: str, status_type: str = "info"):
    """ÊòæÁ§∫Áä∂ÊÄÅÊ∂àÊÅØ"""
    css_class = f"status-{status_type}"
    st.markdown(f'<div class="{css_class}">{message}</div>', unsafe_allow_html=True)

# ÂàùÂßãÂåñ‰ºöËØùÁä∂ÊÄÅ
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False
if 'store_name' not in st.session_state:
    st.session_state.store_name = ""
if 'user_id' not in st.session_state:
    st.session_state.user_id = ""
if 'is_admin' not in st.session_state:
    st.session_state.is_admin = False
if 'cos_client' not in st.session_state:
    st.session_state.cos_client = None
if 'operation_status' not in st.session_state:
    st.session_state.operation_status = []

# ‰∏ªÊ†áÈ¢ò
st.markdown('<h1 class="main-header">üìä Èó®Â∫óÊä•Ë°®Êü•ËØ¢Á≥ªÁªü</h1>', unsafe_allow_html=True)

# ÂàùÂßãÂåñËÖæËÆØ‰∫ëCOSÂÆ¢Êà∑Á´Ø
if not st.session_state.cos_client:
    try:
        with st.spinner("ËøûÊé•ËÖæËÆØ‰∫ëÂ≠òÂÇ®..."):
            cos_client, bucket_name, permissions_file = get_cos_client()
            st.session_state.cos_client = (cos_client, bucket_name, permissions_file)
            show_status_message("‚úÖ ËÖæËÆØ‰∫ëÂ≠òÂÇ®ËøûÊé•ÊàêÂäüÔºÅ", "success")
    except Exception as e:
        show_status_message(f"‚ùå ËøûÊé•Â§±Ë¥•: {str(e)}", "error")
        st.stop()

cos_client, bucket_name, permissions_file = st.session_state.cos_client

# ÊòæÁ§∫Êìç‰ΩúÁä∂ÊÄÅ
for status in st.session_state.operation_status:
    show_status_message(status['message'], status['type'])

# ‰æßËæπÊ†è
with st.sidebar:
    st.title("‚öôÔ∏è Á≥ªÁªüÂäüËÉΩ")
    
    # Á≥ªÁªüÁä∂ÊÄÅ
    st.subheader("üì° Á≥ªÁªüÁä∂ÊÄÅ")
    if cos_client:
        st.success("üü¢ ËÖæËÆØ‰∫ëÂ≠òÂÇ®Â∑≤ËøûÊé•")
    else:
        st.error("üî¥ ËÖæËÆØ‰∫ëÂ≠òÂÇ®Êñ≠ÂºÄ")
    
    user_type = st.radio("ÈÄâÊã©Áî®Êà∑Á±ªÂûã", ["ÊôÆÈÄöÁî®Êà∑", "ÁÆ°ÁêÜÂëò"])
    
    if user_type == "ÁÆ°ÁêÜÂëò":
        st.subheader("üîê ÁÆ°ÁêÜÂëòÁôªÂΩï")
        admin_password = st.text_input("ÁÆ°ÁêÜÂëòÂØÜÁ†Å", type="password")
        
        if st.button("È™åËØÅÁÆ°ÁêÜÂëòË∫´‰ªΩ"):
            if admin_password == ADMIN_PASSWORD:
                st.session_state.is_admin = True
                show_status_message("‚úÖ ÁÆ°ÁêÜÂëòÈ™åËØÅÊàêÂäüÔºÅ", "success")
                st.rerun()
            else:
                show_status_message("‚ùå ÂØÜÁ†ÅÈîôËØØÔºÅ", "error")
        
        if st.session_state.is_admin:
            st.subheader("üìÅ Êñá‰ª∂ÁÆ°ÁêÜ")
            
            # ‰∏ä‰º†ÊùÉÈôêË°®
            permissions_file_upload = st.file_uploader("‰∏ä‰º†Èó®Â∫óÊùÉÈôêË°®", type=['xlsx', 'xls'])
            if permissions_file_upload:
                try:
                    with st.spinner("Â§ÑÁêÜÊùÉÈôêË°®Êñá‰ª∂..."):
                        df = pd.read_excel(permissions_file_upload)
                        if len(df.columns) >= 2:
                            with st.spinner("‰øùÂ≠òÂà∞ËÖæËÆØ‰∫ë..."):
                                if save_permissions_to_cos(df, cos_client, bucket_name, permissions_file):
                                    show_status_message(f"‚úÖ ÊùÉÈôêË°®Â∑≤‰∏ä‰º†Ôºö{len(df)} ‰∏™Áî®Êà∑", "success")
                                    st.balloons()
                                else:
                                    show_status_message("‚ùå ‰øùÂ≠òÂ§±Ë¥•", "error")
                        else:
                            show_status_message("‚ùå Ê†ºÂºèÈîôËØØÔºöÈúÄË¶ÅËá≥Â∞ë‰∏§ÂàóÔºàÈó®Â∫óÂêçÁß∞„ÄÅ‰∫∫ÂëòÁºñÂè∑Ôºâ", "error")
                except Exception as e:
                    show_status_message(f"‚ùå Â§ÑÁêÜÂ§±Ë¥•Ôºö{str(e)}", "error")
            
            # ‰∏ä‰º†Ë¥¢Âä°Êä•Ë°®
            reports_file_upload = st.file_uploader("‰∏ä‰º†Ë¥¢Âä°Êä•Ë°®", type=['xlsx', 'xls'])
            if reports_file_upload:
                try:
                    with st.spinner("Â§ÑÁêÜÊä•Ë°®Êñá‰ª∂..."):
                        excel_file = pd.ExcelFile(reports_file_upload)
                        reports_dict = {}
                        
                        for sheet in excel_file.sheet_names:
                            try:
                                df = pd.read_excel(reports_file_upload, sheet_name=sheet)
                                if not df.empty:
                                    reports_dict[sheet] = df
                                    logger.info(f"ËØªÂèñÂ∑•‰ΩúË°® '{sheet}': {len(df)} Ë°å")
                            except Exception as e:
                                logger.warning(f"Ë∑≥ËøáÂ∑•‰ΩúË°® '{sheet}': {str(e)}")
                                continue
                        
                        if reports_dict:
                            with st.spinner("‰øùÂ≠òÂà∞ËÖæËÆØ‰∫ë..."):
                                if save_reports_to_cos(reports_dict, cos_client, bucket_name):
                                    show_status_message(f"‚úÖ Êä•Ë°®Â∑≤‰∏ä‰º†Ôºö{len(reports_dict)} ‰∏™Èó®Â∫ó", "success")
                                    st.balloons()
                                else:
                                    show_status_message("‚ùå ‰øùÂ≠òÂ§±Ë¥•", "error")
                        else:
                            show_status_message("‚ùå Êñá‰ª∂‰∏≠Ê≤°ÊúâÊúâÊïàÁöÑÂ∑•‰ΩúË°®", "error")
                            
                except Exception as e:
                    show_status_message(f"‚ùå Â§ÑÁêÜÂ§±Ë¥•Ôºö{str(e)}", "error")
            
            # ÁºìÂ≠òÁÆ°ÁêÜ
            st.subheader("üóÇÔ∏è ÁºìÂ≠òÁÆ°ÁêÜ")
            if st.button("Ê∏ÖÈô§ÊâÄÊúâÁºìÂ≠ò"):
                cache_keys = [key for key in st.session_state.keys() if key.startswith('cache_')]
                for key in cache_keys:
                    del st.session_state[key]
                show_status_message("‚úÖ ÁºìÂ≠òÂ∑≤Ê∏ÖÈô§", "success")
                st.rerun()
    
    else:
        if st.session_state.logged_in:
            st.subheader("üë§ ÂΩìÂâçÁôªÂΩï")
            st.info(f"Èó®Â∫óÔºö{st.session_state.store_name}")
            st.info(f"ÁºñÂè∑Ôºö{st.session_state.user_id}")
            
            if st.button("üö™ ÈÄÄÂá∫ÁôªÂΩï"):
                st.session_state.logged_in = False
                st.session_state.store_name = ""
                st.session_state.user_id = ""
                show_status_message("üëã Â∑≤ÈÄÄÂá∫ÁôªÂΩï", "success")
                st.rerun()

# Ê∏ÖÈô§Áä∂ÊÄÅÊ∂àÊÅØ
st.session_state.operation_status = []

# ‰∏ªÁïåÈù¢
if user_type == "ÁÆ°ÁêÜÂëò" and st.session_state.is_admin:
    st.markdown('<div class="admin-panel"><h3>üë®‚Äçüíº ÁÆ°ÁêÜÂëòÊéßÂà∂Èù¢Êùø</h3><p>Êï∞ÊçÆÊ∞∏‰πÖ‰øùÂ≠òÂú®ËÖæËÆØ‰∫ëÔºåÊîØÊåÅÈ´òÊïàÂ≠òÂÇ®ÂíåÁºìÂ≠òÊú∫Âà∂</p></div>', unsafe_allow_html=True)
    
    try:
        with st.spinner("Âä†ËΩΩÊï∞ÊçÆÁªüËÆ°..."):
            permissions_data = load_permissions_from_cos(cos_client, bucket_name, permissions_file)
            reports_data = load_reports_from_cos(cos_client, bucket_name)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            perms_count = len(permissions_data) if permissions_data is not None else 0
            st.metric("ÊùÉÈôêË°®Áî®Êà∑Êï∞", perms_count)
        with col2:
            reports_count = len(reports_data)
            st.metric("Êä•Ë°®Èó®Â∫óÊï∞", reports_count)
        with col3:
            cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
            st.metric("ÁºìÂ≠òÈ°πÁõÆÊï∞", cache_count)
            
        # Êï∞ÊçÆÈ¢ÑËßà
        if permissions_data is not None and len(permissions_data) > 0:
            st.subheader("üë• ÊùÉÈôêÊï∞ÊçÆÈ¢ÑËßà")
            st.dataframe(permissions_data.head(10), use_container_width=True)
        
        if reports_data:
            st.subheader("üìä Êä•Ë°®Êï∞ÊçÆÈ¢ÑËßà")
            report_names = list(reports_data.keys())[:5]  # ÊòæÁ§∫Ââç5‰∏™
            for name in report_names:
                with st.expander(f"üìã {name}"):
                    df = reports_data[name]
                    st.write(f"Êï∞ÊçÆËßÑÊ®°: {len(df)} Ë°å √ó {len(df.columns)} Âàó")
                    st.dataframe(df.head(3), use_container_width=True)
                    
    except Exception as e:
        show_status_message(f"‚ùå Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•Ôºö{str(e)}", "error")

elif user_type == "ÁÆ°ÁêÜÂëò" and not st.session_state.is_admin:
    st.info("üëà ËØ∑Âú®Â∑¶‰æßËæπÊ†èËæìÂÖ•ÁÆ°ÁêÜÂëòÂØÜÁ†Å")

else:
    if not st.session_state.logged_in:
        st.subheader("üîê Áî®Êà∑ÁôªÂΩï")
        
        try:
            with st.spinner("Âä†ËΩΩÊùÉÈôêÊï∞ÊçÆ..."):
                permissions_data = load_permissions_from_cos(cos_client, bucket_name, permissions_file)
            
            if permissions_data is None:
                st.warning("‚ö†Ô∏è Á≥ªÁªüÁª¥Êä§‰∏≠ÔºåËØ∑ËÅîÁ≥ªÁÆ°ÁêÜÂëò")
            else:
                stores = sorted(permissions_data[permissions_data.columns[0]].unique().tolist())
                
                with st.form("login_form"):
                    selected_store = st.selectbox("ÈÄâÊã©Èó®Â∫ó", stores)
                    user_id = st.text_input("‰∫∫ÂëòÁºñÂè∑")
                    submit = st.form_submit_button("üöÄ ÁôªÂΩï")
                    
                    if submit and selected_store and user_id:
                        if verify_user_permission(selected_store, user_id, permissions_data):
                            st.session_state.logged_in = True
                            st.session_state.store_name = selected_store
                            st.session_state.user_id = user_id
                            show_status_message("‚úÖ ÁôªÂΩïÊàêÂäüÔºÅ", "success")
                            st.balloons()
                            st.rerun()
                        else:
                            show_status_message("‚ùå Èó®Â∫óÊàñÁºñÂè∑ÈîôËØØÔºÅ", "error")
                            
        except Exception as e:
            show_status_message(f"‚ùå ÊùÉÈôêÈ™åËØÅÂ§±Ë¥•Ôºö{str(e)}", "error")
    
    else:
        # Â∑≤ÁôªÂΩï - ÊòæÁ§∫Êä•Ë°®
        st.markdown(f'<div class="store-info"><h3>üè™ {st.session_state.store_name}</h3><p>Êìç‰ΩúÂëòÔºö{st.session_state.user_id}</p></div>', unsafe_allow_html=True)
        
        try:
            with st.spinner("Âä†ËΩΩÊä•Ë°®Êï∞ÊçÆ..."):
                reports_data = load_reports_from_cos(cos_client, bucket_name)
                matching_sheets = find_matching_reports(st.session_state.store_name, reports_data)
            
            if matching_sheets:
                if len(matching_sheets) > 1:
                    selected_sheet = st.selectbox("ÈÄâÊã©Êä•Ë°®", matching_sheets)
                else:
                    selected_sheet = matching_sheets[0]
                
                df = reports_data[selected_sheet]
                
                # Â∫îÊî∂-Êú™Êî∂È¢ùÁúãÊùø
                st.subheader("üí∞ Â∫îÊî∂-Êú™Êî∂È¢ù")
                
                try:
                    analysis_results = analyze_receivable_data(df)
                    
                    if 'Â∫îÊî∂-Êú™Êî∂È¢ù' in analysis_results:
                        data = analysis_results['Â∫îÊî∂-Êú™Êî∂È¢ù']
                        amount = data['amount']
                        
                        col1, col2, col3 = st.columns([1, 2, 1])
                        with col2:
                            if amount > 0:
                                st.markdown(f'''
                                    <div class="receivable-positive">
                                        <h1 style="margin: 0; font-size: 3rem;">üí≥ ¬•{amount:,.2f}</h1>
                                        <h3 style="margin: 0.5rem 0;">Èó®Â∫óÂ∫î‰ªòÊ¨æ</h3>
                                        <p style="margin: 0; font-size: 0.9rem;">Êï∞ÊçÆÊù•Ê∫ê: {data['row_name']} (Á¨¨{data['actual_row_number']}Ë°å)</p>
                                    </div>
                                ''', unsafe_allow_html=True)
                            
                            elif amount < 0:
                                st.markdown(f'''
                                    <div class="receivable-negative">
                                        <h1 style="margin: 0; font-size: 3rem;">üíö ¬•{abs(amount):,.2f}</h1>
                                        <h3 style="margin: 0.5rem 0;">ÊÄªÈÉ®Â∫îÈÄÄÊ¨æ</h3>
                                        <p style="margin: 0; font-size: 0.9rem;">Êï∞ÊçÆÊù•Ê∫ê: {data['row_name']} (Á¨¨{data['actual_row_number']}Ë°å)</p>
                                    </div>
                                ''', unsafe_allow_html=True)
                            
                            else:
                                st.markdown('''
                                    <div style="background: #e8f5e8; color: #2e7d32; padding: 2rem; border-radius: 15px; text-align: center;">
                                        <h1 style="margin: 0; font-size: 3rem;">‚öñÔ∏è ¬•0.00</h1>
                                        <h3 style="margin: 0.5rem 0;">Êî∂ÊîØÂπ≥Ë°°</h3>
                                        <p style="margin: 0;">Â∫îÊî∂Êú™Êî∂È¢ù‰∏∫Èõ∂ÔºåË¥¶ÁõÆÂπ≥Ë°°</p>
                                    </div>
                                ''', unsafe_allow_html=True)
                    
                    else:
                        st.warning("‚ö†Ô∏è Êú™ÊâæÂà∞Â∫îÊî∂-Êú™Êî∂È¢ùÊï∞ÊçÆ")
                        
                        with st.expander("üîç Êü•ÁúãËØ¶ÊÉÖ", expanded=False):
                            debug_info = analysis_results.get('debug_info', {})
                            
                            st.markdown("### üìã Êï∞ÊçÆÊü•ÊâæËØ¥Êòé")
                            st.write(f"- **Êä•Ë°®ÊÄªË°åÊï∞Ôºö** {debug_info.get('total_rows', 0)} Ë°å")
                            
                            if debug_info.get('checked_row_69'):
                                st.write(f"- **Á¨¨69Ë°åÂÜÖÂÆπÔºö** {debug_info.get('row_69_content', 'N/A')}")
                            else:
                                st.write("- **Á¨¨69Ë°åÔºö** Êä•Ë°®Ë°åÊï∞‰∏çË∂≥69Ë°å")
                            
                            st.markdown("""
                            ### üí° ÂèØËÉΩÁöÑÂéüÂõ†
                            1. Á¨¨69Ë°å‰∏çÂåÖÂê´"Â∫îÊî∂-Êú™Êî∂È¢ù"Áõ∏ÂÖ≥ÂÖ≥ÈîÆËØç
                            2. Á¨¨69Ë°åÁöÑÊï∞ÂÄº‰∏∫Á©∫ÊàñÊ†ºÂºè‰∏çÊ≠£Á°Æ
                            3. Êä•Ë°®Ê†ºÂºè‰∏éÈ¢ÑÊúü‰∏çÁ¨¶
                            
                            ### üõ†Ô∏è Âª∫ËÆÆ
                            - ËØ∑Ê£ÄÊü•ExcelÊä•Ë°®Á¨¨69Ë°åÊòØÂê¶ÂåÖÂê´"Â∫îÊî∂-Êú™Êî∂È¢ù"
                            - Á°ÆËÆ§ËØ•Ë°åÊúâÂØπÂ∫îÁöÑÈáëÈ¢ùÊï∞ÊçÆ
                            - Â¶ÇÈúÄË∞ÉÊï¥Êü•Êâæ‰ΩçÁΩÆÔºåËØ∑ËÅîÁ≥ªÊäÄÊúØÊîØÊåÅ
                            """)
                
                except Exception as e:
                    show_status_message(f"‚ùå ÂàÜÊûêÊï∞ÊçÆÊó∂Âá∫ÈîôÔºö{str(e)}", "error")
                
                st.divider()
                
                # ÂÆåÊï¥Êä•Ë°®Êï∞ÊçÆ
                st.subheader("üìã ÂÆåÊï¥Êä•Ë°®Êï∞ÊçÆ")
                
                search_term = st.text_input("üîç ÊêúÁ¥¢Êä•Ë°®ÂÜÖÂÆπ")
                
                try:
                    if search_term:
                        search_df = df.copy()
                        for col in search_df.columns:
                            search_df[col] = search_df[col].astype(str).fillna('')
                        
                        mask = search_df.apply(
                            lambda x: x.str.contains(search_term, case=False, na=False, regex=False)
                        ).any(axis=1)
                        filtered_df = df[mask]
                        st.info(f"ÊâæÂà∞ {len(filtered_df)} Êù°ÂåÖÂê´ '{search_term}' ÁöÑËÆ∞ÂΩï")
                    else:
                        filtered_df = df
                    
                    st.info(f"üìä Êï∞ÊçÆÁªüËÆ°ÔºöÂÖ± {len(filtered_df)} Êù°ËÆ∞ÂΩïÔºå{len(df.columns)} Âàó")
                    
                    if len(filtered_df) > 0:
                        display_df = filtered_df.copy()
                        
                        # Á°Æ‰øùÂàóÂêçÂîØ‰∏Ä
                        unique_columns = []
                        for i, col in enumerate(display_df.columns):
                            col_name = str(col)
                            if col_name in unique_columns:
                                col_name = f"{col_name}_{i}"
                            unique_columns.append(col_name)
                        display_df.columns = unique_columns
                        
                        # Ê∏ÖÁêÜÊï∞ÊçÆÂÜÖÂÆπ
                        for col in display_df.columns:
                            display_df[col] = display_df[col].astype(str).fillna('')
                        
                        st.dataframe(display_df, use_container_width=True, height=400)
                    
                    else:
                        st.warning("Ê≤°ÊúâÊâæÂà∞Á¨¶ÂêàÊù°‰ª∂ÁöÑÊï∞ÊçÆ")
                        
                except Exception as e:
                    show_status_message(f"‚ùå Êï∞ÊçÆÂ§ÑÁêÜÊó∂Âá∫ÈîôÔºö{str(e)}", "error")
                
                # ‰∏ãËΩΩÂäüËÉΩ
                st.subheader("üì• Êï∞ÊçÆ‰∏ãËΩΩ")
                
                col1, col2 = st.columns(2)
                with col1:
                    try:
                        buffer = io.BytesIO()
                        download_df = df.copy()
                        
                        # Á°Æ‰øùÂàóÂêçÂîØ‰∏Ä
                        unique_cols = []
                        for i, col in enumerate(download_df.columns):
                            col_name = str(col)
                            if col_name in unique_cols:
                                col_name = f"{col_name}_{i}"
                            unique_cols.append(col_name)
                        download_df.columns = unique_cols
                        
                        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                            download_df.to_excel(writer, index=False)
                        
                        st.download_button(
                            "üì• ‰∏ãËΩΩÂÆåÊï¥Êä•Ë°® (Excel)",
                            buffer.getvalue(),
                            f"{st.session_state.store_name}_Êä•Ë°®_{datetime.now().strftime('%Y%m%d')}.xlsx",
                            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                    except Exception as e:
                        show_status_message(f"Excel‰∏ãËΩΩÂáÜÂ§áÂ§±Ë¥•Ôºö{str(e)}", "error")
                
                with col2:
                    try:
                        csv_df = df.copy()
                        unique_cols = []
                        for i, col in enumerate(csv_df.columns):
                            col_name = str(col)
                            if col_name in unique_cols:
                                col_name = f"{col_name}_{i}"
                            unique_cols.append(col_name)
                        csv_df.columns = unique_cols
                        
                        csv = csv_df.to_csv(index=False, encoding='utf-8-sig')
                        st.download_button(
                            "üì• ‰∏ãËΩΩCSVÊ†ºÂºè",
                            csv,
                            f"{st.session_state.store_name}_Êä•Ë°®_{datetime.now().strftime('%Y%m%d')}.csv",
                            "text/csv"
                        )
                    except Exception as e:
                        show_status_message(f"CSV‰∏ãËΩΩÂáÜÂ§áÂ§±Ë¥•Ôºö{str(e)}", "error")
            
            else:
                st.error(f"‚ùå Êú™ÊâæÂà∞Èó®Â∫ó '{st.session_state.store_name}' ÁöÑÊä•Ë°®")
                
        except Exception as e:
            show_status_message(f"‚ùå Êä•Ë°®Âä†ËΩΩÂ§±Ë¥•Ôºö{str(e)}", "error")

# È°µÈù¢Â∫ïÈÉ®Áä∂ÊÄÅ‰ø°ÊÅØ
st.divider()
col1, col2, col3 = st.columns(3)
with col1:
    st.caption(f"üïí ÂΩìÂâçÊó∂Èó¥: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
with col2:
    cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
    st.caption(f"üíæ ÁºìÂ≠òÈ°πÁõÆ: {cache_count}")
with col3:
    st.caption("üîß ÁâàÊú¨: v3.0 (ËÖæËÆØ‰∫ëÁâà)")
