import streamlit as st
import pandas as pd
import io
import json
import gzip
import hashlib
from datetime import datetime, timedelta
import time
from qcloud_cos import CosConfig, CosS3Client
from qcloud_cos.cos_exception import CosServiceError, CosClientError
import logging
from typing import Optional, Dict, Any, List
import traceback
from contextlib import contextmanager
import threading
import re

# ===================== é¡µé¢é…ç½® =====================
st.set_page_config(
    page_title="é—¨åº—æŠ¥è¡¨æŸ¥è¯¢ç³»ç»Ÿ", 
    page_icon="ğŸ“Š",
    layout="wide"
)

# ===================== ç³»ç»Ÿé…ç½® =====================
ADMIN_PASSWORD = st.secrets.get("system", {}).get("admin_password", "admin123")
MAX_STORAGE_GB = 40  # 40GBå­˜å‚¨é™åˆ¶
API_RATE_LIMIT = 500  # æ¯å°æ—¶APIè°ƒç”¨é™åˆ¶
COMPRESSION_LEVEL = 6  # GZIPå‹ç¼©ç­‰çº§
RETRY_ATTEMPTS = 3  # é‡è¯•æ¬¡æ•°
RETRY_DELAY = 1  # é‡è¯•å»¶è¿Ÿ(ç§’)
MAX_RETRIES = 3
CACHE_DURATION = 300  # ç¼“å­˜5åˆ†é’Ÿ

# ===================== CSSæ ·å¼ =====================
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 2rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 700;
    }
    .store-info {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 10px 20px rgba(0, 0, 0, 0.15);
        text-align: center;
    }
    .admin-panel {
        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #fdcb6e;
        margin: 1rem 0;
        box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
    }
    .receivable-positive {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
        color: #721c24;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #f093fb;
        margin: 1rem 0;
        text-align: center;
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
    }
    .receivable-negative {
        background: linear-gradient(135deg, #a8edea 0%, #d299c2 100%);
        color: #0c4128;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #48cab2;
        margin: 1rem 0;
        text-align: center;
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
    }
    .status-success {
        background: linear-gradient(135deg, #84fab0 0%, #8fd3f4 100%);
        color: #2d3436;
        padding: 0.75rem;
        border-radius: 8px;
        border-left: 5px solid #00b894;
        margin: 0.5rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    .status-error {
        background: linear-gradient(135deg, #fd79a8 0%, #e84393 100%);
        color: white;
        padding: 0.75rem;
        border-radius: 8px;
        border-left: 5px solid #d63031;
        margin: 0.5rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    .status-warning {
        background: linear-gradient(135deg, #fdcb6e 0%, #e17055 100%);
        color: white;
        padding: 0.75rem;
        border-radius: 8px;
        border-left: 5px solid #e84393;
        margin: 0.5rem 0;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
    }
    .system-stats {
        background: linear-gradient(135deg, #00cec9 0%, #55a3ff 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        text-align: center;
    }
    .debug-info {
        background: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 8px;
        padding: 1rem;
        margin: 1rem 0;
        font-family: monospace;
        font-size: 0.9rem;
        color: #495057;
    }
    </style>
""", unsafe_allow_html=True)

# ===================== æ—¥å¿—é…ç½® =====================
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===================== å¼‚å¸¸ç±»å®šä¹‰ =====================
class CosOperationError(Exception):
    """è…¾è®¯äº‘COSæ“ä½œå¼‚å¸¸"""
    pass

class DataProcessingError(Exception):
    """æ•°æ®å¤„ç†å¼‚å¸¸"""
    pass

# ===================== è°ƒè¯•æ—¥å¿—ç®¡ç†å™¨ =====================
class DebugLogger:
    """è°ƒè¯•æ—¥å¿—ç®¡ç†å™¨ï¼Œç”¨äºè¿½è¸ªæ•°æ®æµ"""
    
    def __init__(self):
        self.logs = []
        self.max_logs = 100
    
    def log(self, level: str, message: str, data: Dict = None):
        """è®°å½•è°ƒè¯•æ—¥å¿—"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'level': level,
            'message': message,
            'data': data or {}
        }
        self.logs.append(log_entry)
        
        # ä¿æŒæ—¥å¿—æ•°é‡é™åˆ¶
        if len(self.logs) > self.max_logs:
            self.logs = self.logs[-self.max_logs:]
        
        # åŒæ—¶è®°å½•åˆ°æ ‡å‡†æ—¥å¿—
        if level == 'ERROR':
            logger.error(f"[DEBUG] {message}")
        elif level == 'WARNING':
            logger.warning(f"[DEBUG] {message}")
        else:
            logger.info(f"[DEBUG] {message}")
    
    def get_recent_logs(self, count: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„è°ƒè¯•æ—¥å¿—"""
        return self.logs[-count:] if self.logs else []
    
    def clear_logs(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.logs = []

# å…¨å±€è°ƒè¯•æ—¥å¿—å®ä¾‹
debug_logger = DebugLogger()

# ===================== å·¥å…·å‡½æ•° =====================
@contextmanager
def error_handler(operation_name: str):
    """é€šç”¨é”™è¯¯å¤„ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    try:
        debug_logger.log('INFO', f'å¼€å§‹æ‰§è¡Œ: {operation_name}')
        yield
        debug_logger.log('INFO', f'æˆåŠŸå®Œæˆ: {operation_name}')
    except Exception as e:
        error_msg = f"{operation_name} å¤±è´¥: {str(e)}"
        debug_logger.log('ERROR', error_msg)
        logger.error(error_msg)
        logger.error(traceback.format_exc())
        st.error(f"âŒ {error_msg}")
        raise

def retry_operation(func, *args, max_retries=MAX_RETRIES, delay=RETRY_DELAY, **kwargs):
    """é‡è¯•æ“ä½œè£…é¥°å™¨"""
    for attempt in range(max_retries):
        try:
            result = func(*args, **kwargs)
            debug_logger.log('INFO', f'å‡½æ•° {func.__name__} æ‰§è¡ŒæˆåŠŸ', {'attempt': attempt + 1})
            return result
        except Exception as e:
            error_msg = f"å‡½æ•° {func.__name__} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {str(e)}"
            if attempt == max_retries - 1:
                debug_logger.log('ERROR', error_msg, {'final_attempt': True})
                logger.error(error_msg)
                raise
            else:
                debug_logger.log('WARNING', error_msg, {'retry_delay': delay * (attempt + 1)})
                logger.warning(error_msg)
                time.sleep(delay * (attempt + 1))  # é€’å¢å»¶è¿Ÿ

def get_cache_key(operation: str, params: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    return hashlib.md5(f"{operation}_{params}".encode()).hexdigest()

def set_cache(key: str, data: Any, duration: int = CACHE_DURATION):
    """è®¾ç½®ç¼“å­˜"""
    try:
        cache_data = {
            'data': data,
            'timestamp': time.time(),
            'duration': duration
        }
        st.session_state[f"cache_{key}"] = cache_data
        debug_logger.log('INFO', f'ç¼“å­˜è®¾ç½®æˆåŠŸ: {key}')
    except Exception as e:
        debug_logger.log('WARNING', f'è®¾ç½®ç¼“å­˜å¤±è´¥: {str(e)}')
        logger.warning(f"è®¾ç½®ç¼“å­˜å¤±è´¥: {str(e)}")

def get_cache(key: str) -> Optional[Any]:
    """è·å–ç¼“å­˜"""
    try:
        cache_key = f"cache_{key}"
        if cache_key in st.session_state:
            cache_data = st.session_state[cache_key]
            if time.time() - cache_data['timestamp'] < cache_data['duration']:
                debug_logger.log('INFO', f'ç¼“å­˜å‘½ä¸­: {key}')
                return cache_data['data']
            else:
                del st.session_state[cache_key]
                debug_logger.log('INFO', f'ç¼“å­˜è¿‡æœŸåˆ é™¤: {key}')
    except Exception as e:
        debug_logger.log('WARNING', f'è·å–ç¼“å­˜å¤±è´¥: {str(e)}')
        logger.warning(f"è·å–ç¼“å­˜å¤±è´¥: {str(e)}")
    return None

def sanitize_filename(filename: str) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦"""
    original_filename = filename
    filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
    filename = re.sub(r'\s+', '_', filename.strip())
    filename = filename.strip('.')
    
    debug_logger.log('INFO', 'æ–‡ä»¶åæ¸…ç†', {
        'original': original_filename,
        'sanitized': filename
    })
    
    return filename

def normalize_store_name(store_name: str) -> str:
    """æ ‡å‡†åŒ–é—¨åº—åç§°ï¼Œç”¨äºæ›´å¥½çš„åŒ¹é…"""
    if not store_name:
        return ""
    
    # ç§»é™¤å‰åç©ºæ ¼
    normalized = store_name.strip()
    # ç§»é™¤å¸¸è§çš„é—¨åº—åç¼€
    suffixes = ['åº—', 'åˆ†åº—', 'é—¨åº—', 'è¥ä¸šéƒ¨', 'ä¸“å–åº—']
    for suffix in suffixes:
        if normalized.endswith(suffix):
            normalized = normalized[:-len(suffix)].strip()
            break
    
    debug_logger.log('INFO', 'é—¨åº—åç§°æ ‡å‡†åŒ–', {
        'original': store_name,
        'normalized': normalized
    })
    
    return normalized

# ===================== APIé¢‘ç‡é™åˆ¶å™¨ =====================
class SimpleRateLimiter:
    """ç®€åŒ–çš„APIé¢‘ç‡é™åˆ¶å™¨"""
    
    def __init__(self, max_calls_per_hour: int = API_RATE_LIMIT):
        self.max_calls = max_calls_per_hour
        self.calls = []
        self.lock = threading.Lock()
    
    def can_make_call(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿›è¡ŒAPIè°ƒç”¨"""
        with self.lock:
            now = datetime.now()
            # æ¸…ç†ä¸€å°æ—¶å‰çš„è®°å½•
            self.calls = [call_time for call_time in self.calls 
                         if now - call_time < timedelta(hours=1)]
            
            can_call = len(self.calls) < self.max_calls
            debug_logger.log('INFO', f'APIè°ƒç”¨æ£€æŸ¥', {
                'current_calls': len(self.calls),
                'max_calls': self.max_calls,
                'can_call': can_call
            })
            return can_call
    
    def record_call(self):
        """è®°å½•APIè°ƒç”¨"""
        with self.lock:
            self.calls.append(datetime.now())
            debug_logger.log('INFO', f'APIè°ƒç”¨è®°å½•', {
                'total_calls_in_hour': len(self.calls)
            })
    
    def get_remaining_calls(self) -> int:
        """è·å–å‰©ä½™å¯è°ƒç”¨æ¬¡æ•°"""
        with self.lock:
            now = datetime.now()
            self.calls = [call_time for call_time in self.calls 
                         if now - call_time < timedelta(hours=1)]
            return max(0, self.max_calls - len(self.calls))

# ===================== å‹ç¼©ç®¡ç†å™¨ =====================
class CompressionManager:
    """æ•°æ®å‹ç¼©ç®¡ç†å™¨"""
    
    @staticmethod
    def compress_data(data: bytes) -> bytes:
        """å‹ç¼©æ•°æ®"""
        try:
            compressed = gzip.compress(data, compresslevel=COMPRESSION_LEVEL)
            debug_logger.log('INFO', 'æ•°æ®å‹ç¼©æˆåŠŸ', {
                'original_size': len(data),
                'compressed_size': len(compressed),
                'compression_ratio': (1 - len(compressed) / len(data)) * 100
            })
            return compressed
        except Exception as e:
            debug_logger.log('ERROR', f'æ•°æ®å‹ç¼©å¤±è´¥: {str(e)}')
            logger.error(f"æ•°æ®å‹ç¼©å¤±è´¥: {str(e)}")
            return data  # å‹ç¼©å¤±è´¥æ—¶è¿”å›åŸæ•°æ®
    
    @staticmethod
    def decompress_data(data: bytes) -> bytes:
        """è§£å‹æ•°æ®ï¼Œæ”¯æŒå®¹é”™"""
        try:
            decompressed = gzip.decompress(data)
            debug_logger.log('INFO', 'æ•°æ®è§£å‹æˆåŠŸ', {
                'compressed_size': len(data),
                'decompressed_size': len(decompressed)
            })
            return decompressed
        except Exception as e:
            debug_logger.log('WARNING', f'æ•°æ®è§£å‹å¤±è´¥ï¼Œè¿”å›åŸæ•°æ®: {str(e)}')
            logger.warning(f"æ•°æ®è§£å‹å¤±è´¥ï¼Œè¿”å›åŸæ•°æ®: {str(e)}")
            return data  # è§£å‹å¤±è´¥æ—¶è¿”å›åŸæ•°æ®
    
    @staticmethod
    def compress_json(data: dict) -> bytes:
        """å‹ç¼©JSONæ•°æ®"""
        try:
            json_str = json.dumps(data, ensure_ascii=False, separators=(',', ':'))
            json_bytes = json_str.encode('utf-8')
            compressed = gzip.compress(json_bytes, compresslevel=COMPRESSION_LEVEL)
            
            debug_logger.log('INFO', 'JSONå‹ç¼©æˆåŠŸ', {
                'original_size': len(json_bytes),
                'compressed_size': len(compressed),
                'compression_ratio': (1 - len(compressed) / len(json_bytes)) * 100
            })
            return compressed
        except Exception as e:
            debug_logger.log('ERROR', f'JSONå‹ç¼©å¤±è´¥: {str(e)}')
            logger.error(f"JSONå‹ç¼©å¤±è´¥: {str(e)}")
            # è¿”å›æœªå‹ç¼©çš„JSON
            json_str = json.dumps(data, ensure_ascii=False)
            return json_str.encode('utf-8')
    
    @staticmethod
    def decompress_json(data: bytes) -> dict:
        """è§£å‹JSONæ•°æ®ï¼Œæ”¯æŒå®¹é”™"""
        try:
            # å°è¯•è§£å‹
            decompressed = gzip.decompress(data)
            result = json.loads(decompressed.decode('utf-8'))
            debug_logger.log('INFO', 'JSONè§£å‹æˆåŠŸ')
            return result
        except Exception:
            try:
                # å¯èƒ½æ˜¯æœªå‹ç¼©çš„JSON
                result = json.loads(data.decode('utf-8'))
                debug_logger.log('INFO', 'JSONç›´æ¥è§£ææˆåŠŸï¼ˆæœªå‹ç¼©ï¼‰')
                return result
            except Exception as e:
                debug_logger.log('ERROR', f'JSONè§£å‹å¤±è´¥: {str(e)}')
                logger.error(f"JSONè§£å‹å¤±è´¥: {str(e)}")
                return {}

# ===================== è…¾è®¯äº‘COSç®¡ç†å™¨ =====================
class TencentCOSManager:
    """è…¾è®¯äº‘COSç®¡ç†å™¨"""
    
    def __init__(self):
        self.client = None
        self.bucket_name = None
        self.region = None
        self.rate_limiter = SimpleRateLimiter(API_RATE_LIMIT)
        self.compression = CompressionManager()
        self.permissions_file = "system/permissions.json"
        self.metadata_file = "system/metadata.json"
        self.initialize_from_secrets()
    
    def initialize_from_secrets(self):
        """åˆå§‹åŒ–COSå®¢æˆ·ç«¯"""
        try:
            if "tencent_cos" not in st.secrets:
                raise Exception("æœªæ‰¾åˆ°è…¾è®¯äº‘COSé…ç½®")
            
            config = st.secrets["tencent_cos"]
            secret_id = config.get("secret_id")
            secret_key = config.get("secret_key")
            self.region = config.get("region", "ap-beijing")
            self.bucket_name = config.get("bucket_name")
            
            if not all([secret_id, secret_key, self.bucket_name]):
                raise Exception("è…¾è®¯äº‘COSé…ç½®ä¸å®Œæ•´")
            
            cos_config = CosConfig(
                Region=self.region,
                SecretId=secret_id,
                SecretKey=secret_key
            )
            
            self.client = CosS3Client(cos_config)
            
            debug_logger.log('INFO', 'è…¾è®¯äº‘COSåˆå§‹åŒ–æˆåŠŸ', {
                'bucket': self.bucket_name,
                'region': self.region
            })
            logger.info(f"è…¾è®¯äº‘COSåˆå§‹åŒ–æˆåŠŸ: {self.bucket_name}")
            
        except Exception as e:
            debug_logger.log('ERROR', f'è…¾è®¯äº‘COSåˆå§‹åŒ–å¤±è´¥: {str(e)}')
            logger.error(f"è…¾è®¯äº‘COSåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            raise CosOperationError(f"COSåˆå§‹åŒ–å¤±è´¥: {str(e)}")
    
    def _execute_with_limit_check(self, operation):
        """æ‰§è¡Œå¸¦é¢‘ç‡é™åˆ¶æ£€æŸ¥çš„æ“ä½œ"""
        if not self.rate_limiter.can_make_call():
            remaining = self.rate_limiter.get_remaining_calls()
            error_msg = f"APIè°ƒç”¨é¢‘ç‡è¶…é™ï¼Œå‰©ä½™: {remaining}/å°æ—¶"
            debug_logger.log('ERROR', error_msg)
            raise CosOperationError(error_msg)
        
        result = operation()
        self.rate_limiter.record_call()
        return result
    
    def upload_file(self, file_data: bytes, filename: str, compress: bool = True) -> Optional[str]:
        """ä¸Šä¼ æ–‡ä»¶åˆ°COS"""
        try:
            original_filename = filename
            filename = sanitize_filename(filename)
            
            # å‹ç¼©å¤„ç†
            upload_data = file_data
            final_filename = filename
            
            if compress:
                compressed_data = self.compression.compress_data(file_data)
                if len(compressed_data) < len(file_data):
                    upload_data = compressed_data
                    if not filename.endswith('.gz'):
                        final_filename = filename + '.gz'
                    else:
                        final_filename = filename
                    
                    compression_ratio = (1 - len(compressed_data) / len(file_data)) * 100
                    debug_logger.log('INFO', 'æ–‡ä»¶å‹ç¼©å®Œæˆ', {
                        'original_filename': original_filename,
                        'final_filename': final_filename,
                        'original_size': len(file_data),
                        'compressed_size': len(compressed_data),
                        'compression_ratio': compression_ratio
                    })
            
            # ä¸Šä¼ æ“ä½œ
            def upload_operation():
                return self.client.put_object(
                    Bucket=self.bucket_name,
                    Body=upload_data,
                    Key=final_filename,
                    ContentType='application/octet-stream'
                )
            
            retry_operation(lambda: self._execute_with_limit_check(upload_operation))
            
            file_url = f"https://{self.bucket_name}.cos.{self.region}.myqcloud.com/{final_filename}"
            
            debug_logger.log('INFO', 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ', {
                'filename': final_filename,
                'file_url': file_url,
                'file_size': len(upload_data)
            })
            logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {final_filename}")
            return file_url
            
        except Exception as e:
            debug_logger.log('ERROR', f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}', {
                'filename': filename,
                'file_size': len(file_data)
            })
            logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
            raise CosOperationError(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
    
    def download_file(self, filename: str, decompress: bool = True) -> Optional[bytes]:
        """ä»COSä¸‹è½½æ–‡ä»¶"""
        try:
            debug_logger.log('INFO', 'å¼€å§‹ä¸‹è½½æ–‡ä»¶', {'filename': filename})
            
            def download_operation():
                response = self.client.get_object(
                    Bucket=self.bucket_name,
                    Key=filename
                )
                return response['Body'].read()
            
            file_data = retry_operation(lambda: self._execute_with_limit_check(download_operation))
            
            debug_logger.log('INFO', 'æ–‡ä»¶ä¸‹è½½æˆåŠŸ', {
                'filename': filename,
                'downloaded_size': len(file_data),
                'is_compressed': filename.endswith('.gz')
            })
            
            # è§£å‹å¤„ç†
            if decompress and filename.endswith('.gz'):
                original_size = len(file_data)
                file_data = self.compression.decompress_data(file_data)
                debug_logger.log('INFO', 'æ–‡ä»¶è§£å‹å®Œæˆ', {
                    'filename': filename,
                    'compressed_size': original_size,
                    'decompressed_size': len(file_data)
                })
            
            logger.info(f"æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filename}")
            return file_data
            
        except CosServiceError as e:
            if e.get_error_code() == 'NoSuchKey':
                debug_logger.log('WARNING', f'æ–‡ä»¶ä¸å­˜åœ¨: {filename}')
                logger.info(f"æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
                return None
            
            debug_logger.log('ERROR', f'COSæœåŠ¡é”™è¯¯: {e.get_error_msg()}', {'filename': filename})
            logger.error(f"COSæœåŠ¡é”™è¯¯: {e.get_error_msg()}")
            return None
        except Exception as e:
            debug_logger.log('ERROR', f'æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}', {'filename': filename})
            logger.error(f"æ–‡ä»¶ä¸‹è½½å¤±è´¥: {str(e)}")
            return None
    
    def upload_json(self, data: dict, filename: str) -> bool:
        """ä¸Šä¼ JSONæ•°æ®"""
        try:
            json_bytes = self.compression.compress_json(data)
            
            if not filename.endswith('.gz'):
                filename = filename + '.gz'
            
            result = self.upload_file(json_bytes, filename, compress=False)
            success = result is not None
            
            debug_logger.log('INFO' if success else 'ERROR', 
                           f'JSONä¸Šä¼ {"æˆåŠŸ" if success else "å¤±è´¥"}', {
                'filename': filename,
                'data_size': len(json_bytes)
            })
            
            return success
        except Exception as e:
            debug_logger.log('ERROR', f'JSONä¸Šä¼ å¤±è´¥: {str(e)}', {'filename': filename})
            logger.error(f"JSONä¸Šä¼ å¤±è´¥: {str(e)}")
            return False
    
    def download_json(self, filename: str) -> Optional[dict]:
        """ä¸‹è½½JSONæ•°æ®"""
        try:
            possible_filenames = [filename]
            if not filename.endswith('.gz'):
                possible_filenames.append(filename + '.gz')
            if filename.endswith('.gz'):
                possible_filenames.append(filename[:-3])
            
            for fname in possible_filenames:
                debug_logger.log('INFO', f'å°è¯•ä¸‹è½½JSONæ–‡ä»¶: {fname}')
                file_data = self.download_file(fname, decompress=False)
                if file_data:
                    result = self.compression.decompress_json(file_data)
                    debug_logger.log('INFO', f'JSONä¸‹è½½æˆåŠŸ: {fname}', {
                        'data_keys': list(result.keys()) if isinstance(result, dict) else 'not_dict'
                    })
                    return result
            
            debug_logger.log('WARNING', f'JSONæ–‡ä»¶æœªæ‰¾åˆ°', {
                'attempted_filenames': possible_filenames
            })
            return None
        except Exception as e:
            debug_logger.log('ERROR', f'JSONä¸‹è½½å¤±è´¥: {str(e)}', {'filename': filename})
            logger.error(f"JSONä¸‹è½½å¤±è´¥: {str(e)}")
            return None
    
    def list_files(self, prefix: str = "") -> List[Dict]:
        """åˆ—å‡ºæ–‡ä»¶"""
        try:
            def list_operation():
                return self.client.list_objects(
                    Bucket=self.bucket_name,
                    Prefix=prefix,
                    MaxKeys=1000
                )
            
            response = retry_operation(lambda: self._execute_with_limit_check(list_operation))
            
            files = []
            if 'Contents' in response:
                for obj in response['Contents']:
                    files.append({
                        'filename': obj['Key'],
                        'size': obj['Size'],
                        'last_modified': obj['LastModified']
                    })
            
            debug_logger.log('INFO', f'æ–‡ä»¶åˆ—è¡¨è·å–æˆåŠŸ', {
                'prefix': prefix,
                'file_count': len(files)
            })
            return files
            
        except Exception as e:
            debug_logger.log('ERROR', f'åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}', {'prefix': prefix})
            logger.error(f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}")
            return []
    
    def get_storage_stats(self) -> Dict:
        """è·å–å­˜å‚¨ç»Ÿè®¡"""
        try:
            files = self.list_files()
            total_size = sum(f['size'] for f in files)
            
            report_files = [f for f in files if f['filename'].startswith('reports/')]
            system_files = [f for f in files if f['filename'].startswith('system/')]
            
            stats = {
                'total_files': len(files),
                'total_size_gb': total_size / (1024**3),
                'report_files': len(report_files),
                'system_files': len(system_files),
                'usage_percent': (total_size / (1024**3)) / MAX_STORAGE_GB * 100,
                'remaining_calls': self.rate_limiter.get_remaining_calls()
            }
            
            debug_logger.log('INFO', 'å­˜å‚¨ç»Ÿè®¡è·å–æˆåŠŸ', stats)
            return stats
        except Exception as e:
            debug_logger.log('ERROR', f'è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {str(e)}')
            logger.error(f"è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {
                'total_files': 0,
                'total_size_gb': 0,
                'report_files': 0,
                'system_files': 0,
                'usage_percent': 0,
                'remaining_calls': 0
            }

# ===================== ä¸»åº”ç”¨ç±» =====================
@st.cache_resource(show_spinner="è¿æ¥è…¾è®¯äº‘COS...")
def get_tencent_cos_client():
    """è·å–è…¾è®¯äº‘COSå®¢æˆ·ç«¯ - ä½¿ç”¨ç¼“å­˜"""
    try:
        manager = TencentCOSManager()
        debug_logger.log('INFO', 'COSå®¢æˆ·ç«¯ç¼“å­˜åˆ›å»ºæˆåŠŸ')
        logger.info("è…¾è®¯äº‘COSå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        return manager
    except Exception as e:
        debug_logger.log('ERROR', f'COSå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {str(e)}')
        logger.error(f"è…¾è®¯äº‘COSå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {str(e)}")
        raise CosOperationError(f"è¿æ¥å¤±è´¥: {str(e)}")

def clean_dataframe_for_storage(df: pd.DataFrame) -> pd.DataFrame:
    """æ¸…ç†DataFrameä»¥ä¾¿å­˜å‚¨"""
    try:
        df_cleaned = df.copy()
        
        # å¤„ç†å„ç§æ•°æ®ç±»å‹
        for col in df_cleaned.columns:
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶å¤„ç†ç‰¹æ®Šå€¼
            df_cleaned[col] = df_cleaned[col].astype(str)
            df_cleaned[col] = df_cleaned[col].replace({
                'nan': '',
                'None': '',
                'NaT': '',
                'null': '',
                '<NA>': ''
            })
            
            # å¤„ç†è¿‡é•¿çš„å­—ç¬¦ä¸²
            df_cleaned[col] = df_cleaned[col].apply(
                lambda x: x[:1000] + '...' if len(str(x)) > 1000 else x
            )
        
        debug_logger.log('INFO', f'DataFrameæ¸…ç†å®Œæˆ: {len(df_cleaned)} è¡Œ x {len(df_cleaned.columns)} åˆ—')
        return df_cleaned
        
    except Exception as e:
        debug_logger.log('ERROR', f'æ¸…ç†DataFrameå¤±è´¥: {str(e)}')
        logger.error(f"æ¸…ç†DataFrameå¤±è´¥: {str(e)}")
        raise DataProcessingError(f"æ•°æ®æ¸…ç†å¤±è´¥: {str(e)}")

def save_permissions_to_cos(df: pd.DataFrame, cos_manager: TencentCOSManager) -> bool:
    """ä¿å­˜æƒé™æ•°æ®åˆ°COS - ç®€åŒ–ç‰ˆï¼Œæ¨¡ä»¿Google Sheetsé€»è¾‘"""
    try:
        debug_logger.log('INFO', 'å¼€å§‹ä¿å­˜æƒé™æ•°æ®')
        
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        permissions_data = []
        
        # å¤„ç†æ•°æ® - ä¿æŒåŸæœ‰é€»è¾‘
        for _, row in df.iterrows():
            store_name = str(row.iloc[0]).strip()
            user_id = str(row.iloc[1]).strip()
            
            if store_name and user_id:
                permissions_data.append({
                    "store_name": store_name,
                    "user_id": user_id,
                    "created_at": current_time
                })
        
        if not permissions_data:
            st.error("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æƒé™æ•°æ®")
            return False
        
        # æ„é€ ä¿å­˜æ•°æ®
        save_data = {
            'permissions': permissions_data,
            'last_updated': current_time,
            'count': len(permissions_data)
        }
        
        # ä¿å­˜åˆ°COS
        success = cos_manager.upload_json(save_data, "permissions.json")
        
        if success:
            # ç«‹å³éªŒè¯
            verify_data = cos_manager.download_json("permissions.json")
            if verify_data and 'permissions' in verify_data and len(verify_data['permissions']) == len(permissions_data):
                # æ¸…é™¤ç¼“å­˜
                cache_key = get_cache_key("permissions", "load")
                if f"cache_{cache_key}" in st.session_state:
                    del st.session_state[f"cache_{cache_key}"]
                
                debug_logger.log('INFO', f'æƒé™æ•°æ®ä¿å­˜å¹¶éªŒè¯æˆåŠŸ: {len(permissions_data)} æ¡è®°å½•')
                return True
            else:
                debug_logger.log('ERROR', 'æƒé™æ•°æ®éªŒè¯å¤±è´¥')
                return False
        else:
            debug_logger.log('ERROR', 'æƒé™æ•°æ®ä¿å­˜å¤±è´¥')
            return False
            
    except Exception as e:
        debug_logger.log('ERROR', f'ä¿å­˜æƒé™æ•°æ®å¼‚å¸¸: {str(e)}')
        st.error(f"ä¿å­˜æƒé™æ•°æ®å¤±è´¥: {str(e)}")
        return False

def load_permissions_from_cos(cos_manager: TencentCOSManager) -> Optional[pd.DataFrame]:
    """ä»COSåŠ è½½æƒé™æ•°æ® - ç®€åŒ–ç‰ˆï¼Œæ¨¡ä»¿Google Sheetsé€»è¾‘"""
    cache_key = get_cache_key("permissions", "load")
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        debug_logger.log('INFO', "ä»ç¼“å­˜åŠ è½½æƒé™æ•°æ®")
        return cached_data
    
    try:
        debug_logger.log('INFO', 'å¼€å§‹åŠ è½½æƒé™æ•°æ®')
        
        # ä¸‹è½½æƒé™æ•°æ®
        data = cos_manager.download_json("permissions.json")
        
        if not data or 'permissions' not in data:
            debug_logger.log('WARNING', "æƒé™æ•°æ®ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯")
            return None
        
        permissions = data['permissions']
        if not permissions:
            debug_logger.log('WARNING', "æƒé™åˆ—è¡¨ä¸ºç©º")
            return None
        
        # è½¬æ¢ä¸ºDataFrame - ä¿æŒåŸæœ‰é€»è¾‘
        df_data = []
        for perm in permissions:
            store_name = perm.get('store_name', '').strip()
            user_id = perm.get('user_id', '').strip()
            
            if store_name and user_id:
                df_data.append({
                    'é—¨åº—åç§°': store_name,
                    'äººå‘˜ç¼–å·': user_id
                })
        
        if not df_data:
            debug_logger.log('WARNING', "æ²¡æœ‰æœ‰æ•ˆçš„æƒé™è®°å½•")
            return None
        
        df = pd.DataFrame(df_data)
        
        # ç§»é™¤ç©ºè¡Œ
        df = df[
            (df['é—¨åº—åç§°'] != '') & 
            (df['äººå‘˜ç¼–å·'] != '') &
            (df['é—¨åº—åç§°'].notna()) &
            (df['äººå‘˜ç¼–å·'].notna())
        ]
        
        if len(df) == 0:
            debug_logger.log('WARNING', "æ¸…ç†åæ²¡æœ‰æœ‰æ•ˆæƒé™è®°å½•")
            return None
        
        debug_logger.log('INFO', f'æƒé™æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•')
        
        # è®¾ç½®ç¼“å­˜
        set_cache(cache_key, df)
        return df
        
    except Exception as e:
        debug_logger.log('ERROR', f'åŠ è½½æƒé™æ•°æ®å¼‚å¸¸: {str(e)}')
        st.error(f"åŠ è½½æƒé™æ•°æ®å¤±è´¥: {str(e)}")
        return None

def save_reports_to_cos(reports_dict: Dict[str, pd.DataFrame], cos_manager: TencentCOSManager, original_file_data: bytes = None) -> bool:
    """ä¿å­˜æŠ¥è¡¨æ•°æ®åˆ°COS - ç®€åŒ–ç‰ˆï¼Œæ²¿ç”¨Google Sheetsåˆ†ç‰‡é€»è¾‘"""
    try:
        debug_logger.log('INFO', f'å¼€å§‹ä¿å­˜æŠ¥è¡¨æ•°æ®: {len(reports_dict)} ä¸ªé—¨åº—')
        
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        all_data = [['é—¨åº—åç§°', 'æŠ¥è¡¨æ•°æ®JSON', 'è¡Œæ•°', 'åˆ—æ•°', 'æ›´æ–°æ—¶é—´', 'åˆ†ç‰‡åºå·', 'æ€»åˆ†ç‰‡æ•°', 'æ•°æ®å“ˆå¸Œ']]
        
        # å¤„ç†æ¯ä¸ªé—¨åº—çš„æ•°æ® - æ²¿ç”¨Google Sheetsé€»è¾‘
        for store_name, df in reports_dict.items():
            try:
                debug_logger.log('INFO', f'å¤„ç†é—¨åº—: {store_name}')
                
                # æ¸…ç†æ•°æ® - ä¿æŒåŸæœ‰é€»è¾‘
                df_cleaned = clean_dataframe_for_storage(df)
                
                # è½¬æ¢ä¸ºJSON
                json_data = df_cleaned.to_json(orient='records', force_ascii=False, ensure_ascii=False)
                
                # è®¡ç®—æ•°æ®å“ˆå¸Œç”¨äºéªŒè¯
                data_hash = hashlib.md5(json_data.encode('utf-8')).hexdigest()[:16]
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†ç‰‡ - æ²¿ç”¨åŸæœ‰é€»è¾‘
                MAX_CHUNK_SIZE = 30000  # ä¿æŒåŸæœ‰åˆ†ç‰‡å¤§å°
                
                if len(json_data) <= MAX_CHUNK_SIZE:
                    # ä¸éœ€è¦åˆ†ç‰‡
                    all_data.append([
                        store_name, 
                        json_data, 
                        len(df), 
                        len(df.columns), 
                        current_time, 
                        "1", 
                        "1",
                        data_hash
                    ])
                    debug_logger.log('INFO', f'{store_name}: å•ç‰‡å­˜å‚¨')
                else:
                    # åˆ†ç‰‡å­˜å‚¨ - ä¿æŒåŸæœ‰é€»è¾‘
                    chunks = []
                    for i in range(0, len(json_data), MAX_CHUNK_SIZE):
                        chunks.append(json_data[i:i + MAX_CHUNK_SIZE])
                    
                    total_chunks = len(chunks)
                    debug_logger.log('INFO', f'{store_name}: åˆ†ç‰‡å­˜å‚¨ {total_chunks} ç‰‡')
                    
                    for idx, chunk in enumerate(chunks):
                        chunk_name = f"{store_name}_åˆ†ç‰‡{idx+1}"
                        all_data.append([
                            chunk_name, 
                            chunk, 
                            len(df), 
                            len(df.columns), 
                            current_time, 
                            str(idx+1), 
                            str(total_chunks),
                            data_hash
                        ])
                
            except Exception as e:
                debug_logger.log('ERROR', f'å¤„ç†é—¨åº— {store_name} å¤±è´¥: {str(e)}')
                # ä¿å­˜é”™è¯¯ä¿¡æ¯ - ä¿æŒåŸæœ‰é€»è¾‘
                error_data = {
                    "error": str(e),
                    "timestamp": current_time
                }
                all_data.append([
                    f"{store_name}_é”™è¯¯", 
                    json.dumps(error_data, ensure_ascii=False), 
                    0, 
                    0, 
                    current_time, 
                    "1", 
                    "1",
                    "ERROR"
                ])
                continue
        
        # æ„é€ ä¿å­˜æ•°æ® - æ¨¡ä»¿Google Sheetsç»“æ„
        save_data = {
            'reports_data': all_data,
            'last_updated': current_time,
            'total_records': len(all_data) - 1  # å‡å»æ ‡é¢˜è¡Œ
        }
        
        # ä¿å­˜åˆ°COS
        success = cos_manager.upload_json(save_data, "reports.json")
        
        if success:
            # ç«‹å³éªŒè¯
            verify_data = cos_manager.download_json("reports.json")
            if verify_data and 'reports_data' in verify_data and len(verify_data['reports_data']) == len(all_data):
                # æ¸…é™¤ç¼“å­˜
                cache_key = get_cache_key("reports", "load")
                if f"cache_{cache_key}" in st.session_state:
                    del st.session_state[f"cache_{cache_key}"]
                
                debug_logger.log('INFO', f'æŠ¥è¡¨æ•°æ®ä¿å­˜å¹¶éªŒè¯æˆåŠŸ: {len(all_data) - 1} æ¡è®°å½•')
                return True
            else:
                debug_logger.log('ERROR', 'æŠ¥è¡¨æ•°æ®éªŒè¯å¤±è´¥')
                return False
        else:
            debug_logger.log('ERROR', 'æŠ¥è¡¨æ•°æ®ä¿å­˜å¤±è´¥')
            return False
            
    except Exception as e:
        debug_logger.log('ERROR', f'ä¿å­˜æŠ¥è¡¨æ•°æ®å¼‚å¸¸: {str(e)}')
        st.error(f"ä¿å­˜æŠ¥è¡¨æ•°æ®å¤±è´¥: {str(e)}")
        return False

def load_reports_from_cos(cos_manager: TencentCOSManager) -> Dict[str, pd.DataFrame]:
    """ä»COSåŠ è½½æŠ¥è¡¨æ•°æ® - ç®€åŒ–ç‰ˆï¼Œæ²¿ç”¨Google Sheetsé‡ç»„é€»è¾‘"""
    cache_key = get_cache_key("reports", "load")
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        debug_logger.log('INFO', "ä»ç¼“å­˜åŠ è½½æŠ¥è¡¨æ•°æ®")
        return cached_data
    
    try:
        debug_logger.log('INFO', 'å¼€å§‹åŠ è½½æŠ¥è¡¨æ•°æ®')
        
        # ä¸‹è½½æŠ¥è¡¨æ•°æ®
        data = cos_manager.download_json("reports.json")
        
        if not data or 'reports_data' not in data:
            debug_logger.log('WARNING', "æŠ¥è¡¨æ•°æ®ä¸å­˜åœ¨æˆ–æ ¼å¼é”™è¯¯")
            return {}
        
        reports_raw_data = data['reports_data']
        if len(reports_raw_data) <= 1:  # åªæœ‰æ ‡é¢˜è¡Œ
            debug_logger.log('INFO', "æŠ¥è¡¨æ•°æ®ä¸ºç©º")
            return {}
        
        # è§£ææ•°æ® - æ²¿ç”¨Google Sheetsé€»è¾‘
        reports_dict = {}
        fragments_dict = {}  # å­˜å‚¨åˆ†ç‰‡æ•°æ®
        
        debug_logger.log('INFO', f'å¼€å§‹è§£æ {len(reports_raw_data) - 1} æ¡æŠ¥è¡¨è®°å½•')
        
        for row in reports_raw_data[1:]:  # è·³è¿‡æ ‡é¢˜è¡Œ
            if len(row) >= 7:  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„åˆ—
                store_name = row[0]
                json_data = row[1]
                rows_count = row[2]
                cols_count = row[3]
                update_time = row[4]
                chunk_num = row[5]
                total_chunks = row[6]
                data_hash = row[7] if len(row) > 7 else ''
                
                # è·³è¿‡é”™è¯¯æ•°æ®
                if store_name.endswith('_é”™è¯¯'):
                    debug_logger.log('WARNING', f'è·³è¿‡é”™è¯¯æ•°æ®: {store_name}')
                    continue
                
                # å¤„ç†åˆ†ç‰‡æ•°æ® - ä¿æŒåŸæœ‰é€»è¾‘
                if '_åˆ†ç‰‡' in store_name:
                    base_name = store_name.split('_åˆ†ç‰‡')[0]
                    if base_name not in fragments_dict:
                        fragments_dict[base_name] = []
                    
                    fragments_dict[base_name].append({
                        'json_data': json_data,
                        'chunk_num': chunk_num,
                        'total_chunks': total_chunks,
                        'data_hash': data_hash
                    })
                    debug_logger.log('INFO', f'æ”¶é›†åˆ†ç‰‡: {store_name} -> {base_name}')
                else:
                    # å•ç‰‡æ•°æ®
                    fragments_dict[store_name] = [{
                        'json_data': json_data,
                        'chunk_num': '1',
                        'total_chunks': '1',
                        'data_hash': data_hash
                    }]
                    debug_logger.log('INFO', f'æ”¶é›†å•ç‰‡: {store_name}')
        
        # é‡æ„æ‰€æœ‰åˆ†ç‰‡æ•°æ® - æ²¿ç”¨åŸæœ‰é€»è¾‘
        for store_name, fragments in fragments_dict.items():
            try:
                debug_logger.log('INFO', f'é‡æ„é—¨åº—æ•°æ®: {store_name} ({len(fragments)} ç‰‡)')
                df = reconstruct_fragmented_data(fragments, store_name)
                if df is not None:
                    reports_dict[store_name] = df
                    debug_logger.log('INFO', f'é—¨åº— {store_name} é‡æ„æˆåŠŸ: {len(df)} è¡Œ')
                else:
                    debug_logger.log('ERROR', f'é—¨åº— {store_name} é‡æ„å¤±è´¥')
            except Exception as e:
                debug_logger.log('ERROR', f'é‡æ„é—¨åº— {store_name} å¼‚å¸¸: {str(e)}')
                continue
        
        debug_logger.log('INFO', f'æŠ¥è¡¨æ•°æ®åŠ è½½å®Œæˆ: {len(reports_dict)} ä¸ªé—¨åº—')
        
        # è®¾ç½®ç¼“å­˜
        if reports_dict:
            set_cache(cache_key, reports_dict)
        
        return reports_dict
        
    except Exception as e:
        debug_logger.log('ERROR', f'åŠ è½½æŠ¥è¡¨æ•°æ®å¼‚å¸¸: {str(e)}')
        st.error(f"åŠ è½½æŠ¥è¡¨æ•°æ®å¤±è´¥: {str(e)}")
        return {}

def reconstruct_fragmented_data(fragments: List[Dict[str, Any]], store_name: str) -> Optional[pd.DataFrame]:
    """é‡æ„åˆ†ç‰‡æ•°æ® - æ²¿ç”¨Google SheetsåŸæœ‰é€»è¾‘"""
    try:
        debug_logger.log('INFO', f'å¼€å§‹é‡æ„åˆ†ç‰‡æ•°æ®: {store_name}')
        
        if len(fragments) == 1:
            # å•ç‰‡æ•°æ®
            json_data = fragments[0]['json_data']
            debug_logger.log('INFO', f'{store_name}: å•ç‰‡æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨')
        else:
            # å¤šç‰‡æ•°æ®éœ€è¦é‡æ„
            fragments.sort(key=lambda x: int(x['chunk_num']))
            json_data = ''.join([frag['json_data'] for frag in fragments])
            debug_logger.log('INFO', f'{store_name}: å¤šç‰‡æ•°æ®é‡æ„ï¼Œå…± {len(fragments)} ç‰‡')
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        expected_hash = fragments[0].get('data_hash', '')
        if expected_hash and expected_hash != 'ERROR':
            actual_hash = hashlib.md5(json_data.encode('utf-8')).hexdigest()[:16]
            if actual_hash != expected_hash:
                debug_logger.log('WARNING', f'{store_name} æ•°æ®å“ˆå¸Œä¸åŒ¹é…ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®æŸå')
        
        # è§£æJSON
        df = pd.read_json(json_data, orient='records')
        debug_logger.log('INFO', f'{store_name}: JSONè§£ææˆåŠŸï¼Œ{len(df)} è¡Œ')
        
        # æ•°æ®åå¤„ç† - ä¿æŒåŸæœ‰é€»è¾‘
        if len(df) > 0:
            # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯é—¨åº—åç§°
            first_row = df.iloc[0]
            non_empty_count = sum(1 for val in first_row if pd.notna(val) and str(val).strip() != '')
            
            if non_empty_count <= 2 and len(df) > 1:
                df = df.iloc[1:].reset_index(drop=True)
                debug_logger.log('INFO', f'{store_name}: ç§»é™¤é—¨åº—åç§°è¡Œ')
        
        # å¤„ç†è¡¨å¤´ - ä¿æŒåŸæœ‰é€»è¾‘
        if len(df) > 1:
            header_row = df.iloc[0].fillna('').astype(str).tolist()
            data_rows = df.iloc[1:].copy()
            
            # æ¸…ç†åˆ—åå¹¶å¤„ç†é‡å¤
            cols = []
            for i, col in enumerate(header_row):
                col = str(col).strip()
                if col == '' or col == 'nan' or col == '0':
                    col = f'åˆ—{i+1}' if i > 0 else 'é¡¹ç›®åç§°'
                
                # å¤„ç†é‡å¤åˆ—å
                original_col = col
                counter = 1
                while col in cols:
                    col = f"{original_col}_{counter}"
                    counter += 1
                cols.append(col)
            
            # ç¡®ä¿åˆ—æ•°åŒ¹é…
            min_cols = min(len(data_rows.columns), len(cols))
            cols = cols[:min_cols]
            data_rows = data_rows.iloc[:, :min_cols]
            
            data_rows.columns = cols
            df = data_rows.reset_index(drop=True).fillna('')
            debug_logger.log('INFO', f'{store_name}: è¡¨å¤´å¤„ç†å®Œæˆï¼Œ{len(cols)} åˆ—')
        else:
            # å¤„ç†å°‘äº3è¡Œçš„æ•°æ®
            df = df.fillna('')
            default_cols = []
            for i in range(len(df.columns)):
                col_name = f'åˆ—{i+1}' if i > 0 else 'é¡¹ç›®åç§°'
                default_cols.append(col_name)
            df.columns = default_cols
            debug_logger.log('INFO', f'{store_name}: ä½¿ç”¨é»˜è®¤åˆ—åï¼Œ{len(default_cols)} åˆ—')
        
        debug_logger.log('INFO', f'{store_name} æ•°æ®é‡æ„æˆåŠŸ: {len(df)} è¡Œ x {len(df.columns)} åˆ—')
        return df
        
    except Exception as e:
        debug_logger.log('ERROR', f'é‡æ„ {store_name} æ•°æ®å¤±è´¥: {str(e)}')
        return None

def analyze_receivable_data(df: pd.DataFrame) -> Dict[str, Any]:
    """åˆ†æåº”æ”¶æœªæ”¶é¢æ•°æ® - ä¸“é—¨æŸ¥æ‰¾ç¬¬69è¡Œ"""
    result = {}
    
    try:
        if len(df.columns) == 0 or len(df) == 0:
            return result
        
        # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯é—¨åº—åç§°
        original_df = df.copy()
        first_row = df.iloc[0] if len(df) > 0 else None
        if first_row is not None:
            non_empty_count = sum(1 for val in first_row if pd.notna(val) and str(val).strip() != '')
            if non_empty_count <= 2:
                df = df.iloc[1:].reset_index(drop=True)
                result['skipped_store_name_row'] = True
        
        # æŸ¥æ‰¾ç¬¬69è¡Œ
        target_row_index = 68  # ç¬¬69è¡Œ
        
        if len(df) > target_row_index:
            row = df.iloc[target_row_index]
            first_col_value = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
            
            debug_logger.log('INFO', 'åˆ†æç¬¬69è¡Œåº”æ”¶-æœªæ”¶é¢', {
                'first_col_value': first_col_value,
                'row_data_sample': [str(row.iloc[i]) if pd.notna(row.iloc[i]) else '' for i in range(min(5, len(row)))]
            })
            
            # æ£€æŸ¥å…³é”®è¯
            keywords = ['åº”æ”¶-æœªæ”¶é¢', 'åº”æ”¶æœªæ”¶é¢', 'åº”æ”¶-æœªæ”¶', 'åº”æ”¶æœªæ”¶']
            
            for keyword in keywords:
                if keyword in first_col_value:
                    debug_logger.log('INFO', f'æ‰¾åˆ°å…³é”®è¯: {keyword}')
                    
                    # æŸ¥æ‰¾æ•°å€¼
                    for col_idx in range(len(row)-1, 0, -1):
                        val = row.iloc[col_idx]
                        if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                            cleaned = str(val).replace(',', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                            
                            if cleaned.startswith('(') and cleaned.endswith(')'):
                                cleaned = '-' + cleaned[1:-1]
                            
                            try:
                                amount = float(cleaned)
                                if amount != 0:
                                    result['åº”æ”¶-æœªæ”¶é¢'] = {
                                        'amount': amount,
                                        'column_name': str(df.columns[col_idx]),
                                        'row_name': first_col_value,
                                        'row_index': target_row_index,
                                        'actual_row_number': target_row_index + 1
                                    }
                                    
                                    debug_logger.log('INFO', 'æˆåŠŸåˆ†æåº”æ”¶-æœªæ”¶é¢', {
                                        'amount': amount,
                                        'column_name': str(df.columns[col_idx]),
                                        'column_index': col_idx
                                    })
                                    return result
                            except ValueError:
                                continue
                    break
        
        # å¤‡ç”¨æŸ¥æ‰¾
        if 'åº”æ”¶-æœªæ”¶é¢' not in result:
            keywords = ['åº”æ”¶-æœªæ”¶é¢', 'åº”æ”¶æœªæ”¶é¢', 'åº”æ”¶-æœªæ”¶', 'åº”æ”¶æœªæ”¶']
            
            for idx, row in df.iterrows():
                try:
                    row_name = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
                    
                    if not row_name.strip():
                        continue
                    
                    for keyword in keywords:
                        if keyword in row_name:
                            for col_idx in range(len(row)-1, 0, -1):
                                val = row.iloc[col_idx]
                                if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                                    cleaned = str(val).replace(',', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                                    
                                    if cleaned.startswith('(') and cleaned.endswith(')'):
                                        cleaned = '-' + cleaned[1:-1]
                                    
                                    try:
                                        amount = float(cleaned)
                                        if amount != 0:
                                            result['åº”æ”¶-æœªæ”¶é¢'] = {
                                                'amount': amount,
                                                'column_name': str(df.columns[col_idx]),
                                                'row_name': row_name,
                                                'row_index': idx,
                                                'actual_row_number': idx + 1,
                                                'note': f'åœ¨ç¬¬{idx+1}è¡Œæ‰¾åˆ°ï¼ˆéç¬¬69è¡Œï¼‰'
                                            }
                                            
                                            debug_logger.log('INFO', f'å¤‡ç”¨æŸ¥æ‰¾æˆåŠŸ: ç¬¬{idx+1}è¡Œ', {
                                                'amount': amount,
                                                'row_name': row_name
                                            })
                                            return result
                                    except ValueError:
                                        continue
                            break
                except Exception:
                    continue
        
        # è°ƒè¯•ä¿¡æ¯
        result['debug_info'] = {
            'total_rows': len(df),
            'checked_row_69': len(df) > target_row_index,
            'row_69_content': str(df.iloc[target_row_index].iloc[0]) if len(df) > target_row_index else 'N/A'
        }
        
        debug_logger.log('WARNING', 'æœªæ‰¾åˆ°åº”æ”¶-æœªæ”¶é¢æ•°æ®', result['debug_info'])
        
    except Exception as e:
        debug_logger.log('ERROR', f'åˆ†æåº”æ”¶-æœªæ”¶é¢æ•°æ®æ—¶å‡ºé”™: {str(e)}')
        logger.warning(f"åˆ†æåº”æ”¶-æœªæ”¶é¢æ•°æ®æ—¶å‡ºé”™: {str(e)}")
    
    return result

def verify_user_permission(store_name: str, user_id: str, permissions_data: Optional[pd.DataFrame]) -> bool:
    """éªŒè¯ç”¨æˆ·æƒé™"""
    try:
        if permissions_data is None or len(permissions_data.columns) < 2:
            debug_logger.log('WARNING', 'æƒé™æ•°æ®æ— æ•ˆ')
            return False
        
        store_col = permissions_data.columns[0]
        id_col = permissions_data.columns[1]
        
        normalized_target_store = normalize_store_name(store_name)
        user_id_str = str(user_id).strip()
        
        for _, row in permissions_data.iterrows():
            stored_store = str(row[store_col]).strip()
            stored_id = str(row[id_col]).strip()
            normalized_stored_store = normalize_store_name(stored_store)
            
            # å¤šå±‚åŒ¹é…ç­–ç•¥
            store_match = False
            
            # 1. ç²¾ç¡®åŒ¹é…
            if stored_store == store_name:
                store_match = True
            # 2. æ ‡å‡†åŒ–ååŒ¹é…
            elif normalized_stored_store == normalized_target_store:
                store_match = True
            # 3. åŒ…å«å…³ç³»åŒ¹é…
            elif (store_name in stored_store or stored_store in store_name or
                  normalized_target_store in normalized_stored_store or 
                  normalized_stored_store in normalized_target_store):
                store_match = True
            
            # ç”¨æˆ·IDåŒ¹é…
            if store_match and stored_id == user_id_str:
                debug_logger.log('INFO', 'æƒé™éªŒè¯æˆåŠŸ', {
                    'matched_store': stored_store,
                    'matched_user_id': stored_id,
                    'match_type': 'exact' if stored_store == store_name else 'normalized'
                })
                return True
        
        debug_logger.log('WARNING', 'æƒé™éªŒè¯å¤±è´¥', {
            'store_name': store_name,
            'user_id': user_id,
            'normalized_store': normalized_target_store
        })
        return False
        
    except Exception as e:
        debug_logger.log('ERROR', f'æƒé™éªŒè¯å¼‚å¸¸: {str(e)}')
        logger.error(f"æƒé™éªŒè¯å¤±è´¥: {str(e)}")
        return False

def find_matching_reports(store_name: str, reports_data: Dict[str, pd.DataFrame]) -> List[str]:
    """æŸ¥æ‰¾åŒ¹é…çš„æŠ¥è¡¨"""
    try:
        matching = []
        normalized_target = normalize_store_name(store_name)
        
        for sheet_name in reports_data.keys():
            normalized_sheet = normalize_store_name(sheet_name)
            
            if (store_name == sheet_name or
                normalized_target == normalized_sheet or
                store_name in sheet_name or sheet_name in store_name or
                normalized_target in normalized_sheet or normalized_sheet in normalized_target):
                matching.append(sheet_name)
        
        debug_logger.log('INFO', f'æŸ¥æ‰¾åŒ¹é…æŠ¥è¡¨: {store_name}', {
            'matching_reports': matching,
            'total_reports': len(reports_data)
        })
        
        return matching
        
    except Exception as e:
        debug_logger.log('ERROR', f'æŸ¥æ‰¾åŒ¹é…æŠ¥è¡¨å¤±è´¥: {str(e)}')
        logger.error(f"æŸ¥æ‰¾åŒ¹é…æŠ¥è¡¨å¤±è´¥: {str(e)}")
        return []

def get_original_file_for_download(store_name: str, cos_manager: TencentCOSManager) -> Optional[bytes]:
    """è·å–é—¨åº—çš„åŸå§‹Excelæ–‡ä»¶ç”¨äºä¸‹è½½"""
    try:
        # è·å–å…ƒæ•°æ®
        metadata = cos_manager.download_json(cos_manager.metadata_file)
        if not metadata or 'reports' not in metadata:
            return None
        
        # æŸ¥æ‰¾åŒ¹é…çš„æŠ¥è¡¨
        normalized_target = normalize_store_name(store_name)
        matching_report = None
        
        for report in metadata['reports']:
            report_store_name = report.get('store_name', '').strip()
            normalized_report = normalize_store_name(report_store_name)
            
            if (report_store_name == store_name or 
                normalized_report == normalized_target or
                store_name in report_store_name or 
                report_store_name in store_name or
                normalized_target in normalized_report or
                normalized_report in normalized_target):
                matching_report = report
                break
        
        if not matching_report:
            debug_logger.log('WARNING', f'æœªæ‰¾åˆ°é—¨åº— {store_name} çš„åŸå§‹æ–‡ä»¶')
            return None
        
        raw_filename = matching_report.get('raw_filename')
        if not raw_filename:
            debug_logger.log('WARNING', f'é—¨åº— {store_name} æ²¡æœ‰åŸå§‹æ–‡ä»¶è®°å½•')
            return None
        
        # ä¸‹è½½åŸå§‹æ–‡ä»¶
        original_data = cos_manager.download_file(raw_filename, decompress=True)
        if original_data:
            debug_logger.log('INFO', f'åŸå§‹æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {store_name}', {
                'filename': raw_filename,
                'size': len(original_data)
            })
            return original_data
        else:
            debug_logger.log('ERROR', f'åŸå§‹æ–‡ä»¶ä¸‹è½½å¤±è´¥: {store_name}')
            return None
            
    except Exception as e:
        debug_logger.log('ERROR', f'è·å–åŸå§‹æ–‡ä»¶å¤±è´¥: {store_name}, é”™è¯¯: {str(e)}')
        logger.error(f"è·å–åŸå§‹æ–‡ä»¶å¤±è´¥ {store_name}: {str(e)}")
        return None
    """æŸ¥æ‰¾åŒ¹é…çš„æŠ¥è¡¨"""
    try:
        matching = []
        normalized_target = normalize_store_name(store_name)
        
        for sheet_name in reports_data.keys():
            normalized_sheet = normalize_store_name(sheet_name)
            
            if (store_name == sheet_name or
                normalized_target == normalized_sheet or
                store_name in sheet_name or sheet_name in store_name or
                normalized_target in normalized_sheet or normalized_sheet in normalized_target):
                matching.append(sheet_name)
        
        debug_logger.log('INFO', f'æŸ¥æ‰¾åŒ¹é…æŠ¥è¡¨: {store_name}', {
            'matching_reports': matching,
            'total_reports': len(reports_data)
        })
        
        return matching
        
    except Exception as e:
        debug_logger.log('ERROR', f'æŸ¥æ‰¾åŒ¹é…æŠ¥è¡¨å¤±è´¥: {str(e)}')
        logger.error(f"æŸ¥æ‰¾åŒ¹é…æŠ¥è¡¨å¤±è´¥: {str(e)}")
        return []

def show_status_message(message: str, status_type: str = "info"):
    """æ˜¾ç¤ºçŠ¶æ€æ¶ˆæ¯"""
    css_class = f"status-{status_type}"
    st.markdown(f'<div class="{css_class}">{message}</div>', unsafe_allow_html=True)

def show_debug_info():
    """æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯"""
    if st.session_state.get('debug_mode', False):
        with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯", expanded=False):
            recent_logs = debug_logger.get_recent_logs(20)
            
            if recent_logs:
                st.write("**æœ€è¿‘çš„è°ƒè¯•æ—¥å¿—:**")
                for log in reversed(recent_logs):  # æœ€æ–°çš„åœ¨å‰
                    level_color = {
                        'ERROR': '#ff4757',
                        'WARNING': '#ffa502',
                        'INFO': '#3742fa'
                    }.get(log['level'], '#747d8c')
                    
                    st.markdown(f'''
                    <div class="debug-info">
                    <strong style="color: {level_color};">[{log['level']}]</strong> 
                    <small>{log['timestamp'][:19]}</small><br>
                    {log['message']}
                    {f"<br><small>æ•°æ®: {json.dumps(log['data'], ensure_ascii=False, indent=2)}</small>" if log['data'] else ""}
                    </div>
                    ''', unsafe_allow_html=True)
            else:
                st.info("æš‚æ— è°ƒè¯•æ—¥å¿—")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ åˆ·æ–°æ—¥å¿—"):
                    st.rerun()
            with col2:
                if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ—¥å¿—"):
                    debug_logger.clear_logs()
                    st.rerun()

# ===================== ä¼šè¯çŠ¶æ€åˆå§‹åŒ– =====================
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False
if 'store_name' not in st.session_state:
    st.session_state.store_name = ""
if 'user_id' not in st.session_state:
    st.session_state.user_id = ""
if 'is_admin' not in st.session_state:
    st.session_state.is_admin = False
if 'cos_manager' not in st.session_state:
    st.session_state.cos_manager = None
if 'operation_status' not in st.session_state:
    st.session_state.operation_status = []
if 'debug_mode' not in st.session_state:
    st.session_state.debug_mode = False

# ===================== ä¸»ç¨‹åº =====================
# ä¸»æ ‡é¢˜
st.markdown('<h1 class="main-header">ğŸ“Š é—¨åº—æŠ¥è¡¨æŸ¥è¯¢ç³»ç»Ÿ</h1>', unsafe_allow_html=True)

# åˆå§‹åŒ–è…¾è®¯äº‘COSå®¢æˆ·ç«¯
if not st.session_state.cos_manager:
    try:
        with st.spinner("è¿æ¥è…¾è®¯äº‘COS..."):
            cos_manager = get_tencent_cos_client()
            st.session_state.cos_manager = cos_manager
            show_status_message("âœ… è…¾è®¯äº‘COSè¿æ¥æˆåŠŸï¼", "success")
            debug_logger.log('INFO', 'ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ')
    except Exception as e:
        show_status_message(f"âŒ è¿æ¥å¤±è´¥: {str(e)}", "error")
        debug_logger.log('ERROR', f'ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}')
        st.stop()

cos_manager = st.session_state.cos_manager

# æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€å’Œè°ƒè¯•ä¿¡æ¯
try:
    storage_stats = cos_manager.get_storage_stats()
    
    st.markdown(f'''
    <div class="system-stats">
    <h4>â˜ï¸ è…¾è®¯äº‘COSçŠ¶æ€ç›‘æ§</h4>
    <div style="display: flex; justify-content: space-between; flex-wrap: wrap;">
        <div style="text-align: center; flex: 1; min-width: 120px;">
            <div style="font-size: 1.5rem; font-weight: bold;">
                {storage_stats.get('total_files', 0)}
            </div>
            <div style="font-size: 0.9rem;">æ€»æ–‡ä»¶æ•°</div>
        </div>
        <div style="text-align: center; flex: 1; min-width: 120px;">
            <div style="font-size: 1.5rem; font-weight: bold;">
                {storage_stats.get('total_size_gb', 0):.1f}GB
            </div>
            <div style="font-size: 0.9rem;">å­˜å‚¨ä½¿ç”¨</div>
        </div>
        <div style="text-align: center; flex: 1; min-width: 120px;">
            <div style="font-size: 1.5rem; font-weight: bold;">
                {storage_stats.get('usage_percent', 0):.1f}%
            </div>
            <div style="font-size: 0.9rem;">ä½¿ç”¨ç‡</div>
        </div>
        <div style="text-align: center; flex: 1; min-width: 120px;">
            <div style="font-size: 1.5rem; font-weight: bold;">
                {storage_stats.get('remaining_calls', 0)}
            </div>
            <div style="font-size: 0.9rem;">APIå‰©ä½™</div>
        </div>
    </div>
    </div>
    ''', unsafe_allow_html=True)
    
    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
    show_debug_info()
    
except Exception as e:
    show_status_message(f"âŒ è·å–çŠ¶æ€å¤±è´¥: {str(e)}", "error")

# æ˜¾ç¤ºæ“ä½œçŠ¶æ€
for status in st.session_state.operation_status:
    show_status_message(status['message'], status['type'])

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»ŸåŠŸèƒ½")
    
    # ç³»ç»ŸçŠ¶æ€æ˜¾ç¤º
    st.subheader("ğŸ“¡ ç³»ç»ŸçŠ¶æ€")
    if cos_manager:
        st.success("ğŸŸ¢ è…¾è®¯äº‘COSå·²è¿æ¥")
        
        # å¿«é€ŸçŠ¶æ€æ£€æŸ¥
        try:
            with st.spinner("æ£€æŸ¥ç³»ç»ŸçŠ¶æ€..."):
                # æ£€æŸ¥æƒé™æ•°æ®
                permissions_data = load_permissions_from_cos(cos_manager)
                perms_ok = permissions_data is not None and len(permissions_data) > 0
                
                # æ£€æŸ¥æŠ¥è¡¨æ•°æ®
                reports_data = load_reports_from_cos(cos_manager)
                reports_ok = reports_data is not None and len(reports_data) > 0
                
                if perms_ok:
                    st.success(f"ğŸŸ¢ æƒé™ç³»ç»Ÿæ­£å¸¸ ({len(permissions_data)} ç”¨æˆ·)")
                else:
                    st.error("ğŸ”´ æƒé™ç³»ç»Ÿå¼‚å¸¸")
                
                if reports_ok:
                    st.success(f"ğŸŸ¢ æŠ¥è¡¨ç³»ç»Ÿæ­£å¸¸ ({len(reports_data)} é—¨åº—)")
                else:
                    st.error("ğŸ”´ æŠ¥è¡¨ç³»ç»Ÿå¼‚å¸¸")
                
                # ç³»ç»Ÿæ•´ä½“çŠ¶æ€
                if perms_ok and reports_ok:
                    st.success("âœ… ç³»ç»Ÿæ•´ä½“æ­£å¸¸")
                else:
                    st.warning("âš ï¸ ç³»ç»Ÿéƒ¨åˆ†åŠŸèƒ½å¼‚å¸¸")
                
        except Exception as e:
            st.error(f"ğŸ”´ çŠ¶æ€æ£€æŸ¥å¤±è´¥: {str(e)}")
    else:
        st.error("ğŸ”´ è…¾è®¯äº‘COSæ–­å¼€")
    
    st.divider()
    
    # è°ƒè¯•æ¨¡å¼
    st.session_state.debug_mode = st.checkbox("ğŸ” è°ƒè¯•æ¨¡å¼", value=st.session_state.debug_mode)
    if st.session_state.debug_mode:
        st.info("è°ƒè¯•æ¨¡å¼å·²å¼€å¯")
        
        # å¿«é€Ÿè¯Šæ–­æŒ‰é’®
        if st.button("ğŸ¥ å¿«é€Ÿè¯Šæ–­"):
            with st.spinner("è¿è¡Œè¯Šæ–­..."):
                st.write("**è¯Šæ–­ç»“æœ:**")
                
                # COSè¿æ¥æµ‹è¯•
                try:
                    storage_stats = cos_manager.get_storage_stats()
                    st.success(f"âœ… COSè¿æ¥æ­£å¸¸ï¼Œæ–‡ä»¶æ•°: {storage_stats.get('total_files', 0)}")
                except Exception as e:
                    st.error(f"âŒ COSè¿æ¥å¼‚å¸¸: {str(e)}")
                
                # æƒé™æ–‡ä»¶æ£€æŸ¥
                try:
                    perms_data = cos_manager.download_json(cos_manager.permissions_file)
                    if perms_data:
                        st.success(f"âœ… æƒé™æ–‡ä»¶å­˜åœ¨ï¼Œè®°å½•æ•°: {len(perms_data.get('permissions', []))}")
                    else:
                        st.error("âŒ æƒé™æ–‡ä»¶ä¸å­˜åœ¨")
                except Exception as e:
                    st.error(f"âŒ æƒé™æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {str(e)}")
                
                # å…ƒæ•°æ®æ–‡ä»¶æ£€æŸ¥
                try:
                    metadata = cos_manager.download_json(cos_manager.metadata_file)
                    if metadata:
                        st.success(f"âœ… å…ƒæ•°æ®æ–‡ä»¶å­˜åœ¨ï¼ŒæŠ¥è¡¨æ•°: {len(metadata.get('reports', []))}")
                    else:
                        st.error("âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
                except Exception as e:
                    st.error(f"âŒ å…ƒæ•°æ®æ–‡ä»¶æ£€æŸ¥å¤±è´¥: {str(e)}")
        
        # ç¼“å­˜ç®¡ç†
        cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
        st.write(f"**ç¼“å­˜çŠ¶æ€:** {cache_count} é¡¹")
        
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"):
            cache_keys = [key for key in st.session_state.keys() if key.startswith('cache_')]
            for key in cache_keys:
                del st.session_state[key]
            st.success("ç¼“å­˜å·²æ¸…ç©º")
            st.rerun()
    
    st.divider()
    
    # ç”¨æˆ·ç±»å‹é€‰æ‹©
    user_type = st.radio("é€‰æ‹©ç”¨æˆ·ç±»å‹", ["æ™®é€šç”¨æˆ·", "ç®¡ç†å‘˜"])
    
    if user_type == "ç®¡ç†å‘˜":
        st.subheader("ğŸ” ç®¡ç†å‘˜ç™»å½•")
        admin_password = st.text_input("ç®¡ç†å‘˜å¯†ç ", type="password")
        
        if st.button("éªŒè¯ç®¡ç†å‘˜èº«ä»½"):
            if admin_password == ADMIN_PASSWORD:
                st.session_state.is_admin = True
                show_status_message("âœ… ç®¡ç†å‘˜éªŒè¯æˆåŠŸï¼", "success")
                debug_logger.log('INFO', 'ç®¡ç†å‘˜ç™»å½•æˆåŠŸ')
                st.rerun()
            else:
                show_status_message("âŒ å¯†ç é”™è¯¯ï¼", "error")
                debug_logger.log('WARNING', 'ç®¡ç†å‘˜ç™»å½•å¤±è´¥ï¼šå¯†ç é”™è¯¯')
        
        if st.session_state.is_admin:
            st.success("ğŸ‘¨â€ğŸ’¼ ç®¡ç†å‘˜å·²ç™»å½•")
            
            st.subheader("ğŸ“ æ–‡ä»¶ç®¡ç†")
            
            # ä¸Šä¼ æƒé™è¡¨
            permissions_file = st.file_uploader("ä¸Šä¼ é—¨åº—æƒé™è¡¨", type=['xlsx', 'xls'])
            if permissions_file:
                if st.button("ğŸ“¤ ä¸Šä¼ æƒé™è¡¨", type="primary"):
                    try:
                        with st.spinner("å¤„ç†æƒé™è¡¨æ–‡ä»¶..."):
                            df = pd.read_excel(permissions_file)
                            if len(df.columns) >= 2:
                                with st.spinner("ä¿å­˜åˆ°è…¾è®¯äº‘COS..."):
                                    if save_permissions_to_cos(df, cos_manager):
                                        show_status_message(f"âœ… æƒé™è¡¨å·²ä¸Šä¼ ï¼š{len(df)} ä¸ªç”¨æˆ·", "success")
                                        st.balloons()
                                        # æ¸…é™¤ç¼“å­˜ä»¥ç«‹å³æ˜¾ç¤ºæ›´æ–°
                                        cache_key = get_cache_key("permissions", "load")
                                        if f"cache_{cache_key}" in st.session_state:
                                            del st.session_state[f"cache_{cache_key}"]
                                        time.sleep(1)
                                        st.rerun()
                                    else:
                                        show_status_message("âŒ æƒé™è¡¨ä¿å­˜å¤±è´¥", "error")
                            else:
                                show_status_message("âŒ æ ¼å¼é”™è¯¯ï¼šéœ€è¦è‡³å°‘ä¸¤åˆ—ï¼ˆé—¨åº—åç§°ã€äººå‘˜ç¼–å·ï¼‰", "error")
                    except Exception as e:
                        show_status_message(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}", "error")
            
            # ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨
            reports_file = st.file_uploader("ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨", type=['xlsx', 'xls'])
            if reports_file:
                if st.button("ğŸ“¤ ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨", type="primary"):
                    try:
                        with st.spinner("å¤„ç†æŠ¥è¡¨æ–‡ä»¶..."):
                            # è·å–åŸå§‹æ–‡ä»¶æ•°æ®
                            original_file_data = reports_file.getvalue()
                            
                            excel_file = pd.ExcelFile(reports_file)
                            reports_dict = {}
                            
                            for sheet in excel_file.sheet_names:
                                try:
                                    df = pd.read_excel(reports_file, sheet_name=sheet)
                                    if not df.empty:
                                        reports_dict[sheet] = df
                                        debug_logger.log('INFO', f'è¯»å–å·¥ä½œè¡¨ "{sheet}": {len(df)} è¡Œ')
                                        logger.info(f"è¯»å–å·¥ä½œè¡¨ '{sheet}': {len(df)} è¡Œ")
                                except Exception as e:
                                    debug_logger.log('WARNING', f'è·³è¿‡å·¥ä½œè¡¨ "{sheet}": {str(e)}')
                                    logger.warning(f"è·³è¿‡å·¥ä½œè¡¨ '{sheet}': {str(e)}")
                                    continue
                            
                            if reports_dict:
                                with st.spinner("ä¿å­˜åˆ°è…¾è®¯äº‘COS..."):
                                    if save_reports_to_cos(reports_dict, cos_manager, original_file_data):
                                        show_status_message(f"âœ… æŠ¥è¡¨å·²ä¸Šä¼ ï¼š{len(reports_dict)} ä¸ªé—¨åº—", "success")
                                        st.balloons()
                                        # æ¸…é™¤ç¼“å­˜ä»¥ç«‹å³æ˜¾ç¤ºæ›´æ–°
                                        cache_key = get_cache_key("reports", "load")
                                        if f"cache_{cache_key}" in st.session_state:
                                            del st.session_state[f"cache_{cache_key}"]
                                        time.sleep(1)
                                        st.rerun()
                                    else:
                                        show_status_message("âŒ æŠ¥è¡¨ä¿å­˜å¤±è´¥", "error")
                            else:
                                show_status_message("âŒ æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„å·¥ä½œè¡¨", "error")
                                
                    except Exception as e:
                        show_status_message(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}", "error")
            
            # ç³»ç»Ÿç®¡ç†
            st.subheader("ğŸ› ï¸ ç³»ç»Ÿç®¡ç†")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ”„ é‡è½½æƒé™"):
                    cache_key = get_cache_key("permissions", "load")
                    if f"cache_{cache_key}" in st.session_state:
                        del st.session_state[f"cache_{cache_key}"]
                    st.success("æƒé™ç¼“å­˜å·²æ¸…é™¤")
                    st.rerun()
            
            with col2:
                if st.button("ğŸ”„ é‡è½½æŠ¥è¡¨"):
                    cache_key = get_cache_key("reports", "load")
                    if f"cache_{cache_key}" in st.session_state:
                        del st.session_state[f"cache_{cache_key}"]
                    st.success("æŠ¥è¡¨ç¼“å­˜å·²æ¸…é™¤")
                    st.rerun()
    
    else:
        if st.session_state.logged_in:
            st.subheader("ğŸ‘¤ å½“å‰ç™»å½•")
            st.info(f"é—¨åº—ï¼š{st.session_state.store_name}")
            st.info(f"ç¼–å·ï¼š{st.session_state.user_id}")
            
            # ç”¨æˆ·å¿«é€Ÿæ“ä½œ
            if st.button("ğŸ”„ åˆ·æ–°æˆ‘çš„æ•°æ®"):
                # åªæ¸…é™¤æŠ¥è¡¨ç¼“å­˜
                cache_key = get_cache_key("reports", "load")
                if f"cache_{cache_key}" in st.session_state:
                    del st.session_state[f"cache_{cache_key}"]
                debug_logger.log('INFO', 'ç”¨æˆ·åˆ·æ–°æ•°æ®')
                st.rerun()
            
            if st.button("ğŸšª é€€å‡ºç™»å½•"):
                st.session_state.logged_in = False
                st.session_state.store_name = ""
                st.session_state.user_id = ""
                show_status_message("ğŸ‘‹ å·²é€€å‡ºç™»å½•", "success")
                debug_logger.log('INFO', 'ç”¨æˆ·é€€å‡ºç™»å½•')
                st.rerun()
        else:
            st.info("ğŸ‘ˆ è¯·åœ¨ä¸»ç•Œé¢ç™»å½•")

# æ¸…é™¤çŠ¶æ€æ¶ˆæ¯
st.session_state.operation_status = []

# ä¸»ç•Œé¢
if user_type == "ç®¡ç†å‘˜" and st.session_state.is_admin:
    st.markdown('<div class="admin-panel"><h3>ğŸ‘¨â€ğŸ’¼ ç®¡ç†å‘˜æ§åˆ¶é¢æ¿</h3><p>æ•°æ®æ°¸ä¹…ä¿å­˜åœ¨è…¾è®¯äº‘COSï¼Œæ”¯æŒé«˜æ•ˆå‹ç¼©å­˜å‚¨å’Œç¼“å­˜æœºåˆ¶</p></div>', unsafe_allow_html=True)
    
    try:
        st.markdown("#### ğŸ“Š ç³»ç»Ÿæ•°æ®ç»Ÿè®¡")
        
        with st.spinner("æ­£åœ¨åŠ è½½ç³»ç»Ÿæ•°æ®..."):
            # åŠ è½½æƒé™æ•°æ®
            permissions_data = load_permissions_from_cos(cos_manager)
            # åŠ è½½æŠ¥è¡¨æ•°æ®
            reports_data = load_reports_from_cos(cos_manager)
        
        # æ•°æ®ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            perms_count = len(permissions_data) if permissions_data is not None else 0
            perms_status = "ğŸŸ¢" if perms_count > 0 else "ğŸ”´"
            st.metric("æƒé™è¡¨ç”¨æˆ·æ•°", f"{perms_status} {perms_count}")
        
        with col2:
            reports_count = len(reports_data) if reports_data else 0
            reports_status = "ğŸŸ¢" if reports_count > 0 else "ğŸ”´"
            st.metric("æŠ¥è¡¨é—¨åº—æ•°", f"{reports_status} {reports_count}")
        
        with col3:
            cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
            st.metric("ç¼“å­˜é¡¹ç›®æ•°", cache_count)
        
        with col4:
            try:
                storage_stats = cos_manager.get_storage_stats()
                total_files = storage_stats.get('total_files', 0)
                st.metric("COSæ–‡ä»¶æ•°", total_files)
            except:
                st.metric("COSæ–‡ä»¶æ•°", "N/A")
        
        # ç³»ç»Ÿå¥åº·çŠ¶æ€
        is_healthy = (perms_count > 0) and (reports_count > 0)
        if is_healthy:
            st.success("âœ… ç³»ç»ŸçŠ¶æ€æ­£å¸¸ï¼šæƒé™å’ŒæŠ¥è¡¨æ•°æ®éƒ½å¯ç”¨")
        else:
            issues = []
            if perms_count == 0:
                issues.append("æƒé™æ•°æ®ç¼ºå¤±")
            if reports_count == 0:
                issues.append("æŠ¥è¡¨æ•°æ®ç¼ºå¤±")
            st.error(f"âŒ ç³»ç»Ÿé—®é¢˜ï¼š{', '.join(issues)}")
        
        # æ•°æ®è¯¦ç»†ä¿¡æ¯
        if permissions_data is not None and len(permissions_data) > 0:
            with st.expander("ğŸ‘¥ æƒé™æ•°æ®è¯¦æƒ…", expanded=False):
                st.write(f"**æƒé™è®°å½•æ€»æ•°ï¼š** {len(permissions_data)}")
                
                # ç»Ÿè®¡é—¨åº—æ•°é‡
                unique_stores = permissions_data[permissions_data.columns[0]].nunique()
                st.write(f"**æ¶‰åŠé—¨åº—æ•°ï¼š** {unique_stores}")
                
                # æ˜¾ç¤ºæƒé™æ•°æ®é¢„è§ˆ
                st.write("**æƒé™æ•°æ®é¢„è§ˆï¼ˆå‰10æ¡ï¼‰ï¼š**")
                st.dataframe(permissions_data.head(10), use_container_width=True)
        else:
            st.warning("âš ï¸ æƒé™æ•°æ®ä¸å¯ç”¨")
        
        if reports_data and len(reports_data) > 0:
            with st.expander("ğŸ“Š æŠ¥è¡¨æ•°æ®è¯¦æƒ…", expanded=False):
                st.write(f"**æŠ¥è¡¨æ€»æ•°ï¼š** {len(reports_data)}")
                
                # è·å–å…ƒæ•°æ®ç»Ÿè®¡
                try:
                    metadata = cos_manager.download_json(cos_manager.metadata_file)
                    if metadata and 'reports' in metadata:
                        parsed_count = sum(1 for r in metadata['reports'] if r.get('has_parsed_data', False))
                        raw_only_count = len(metadata['reports']) - parsed_count
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ€»æŠ¥è¡¨æ•°", len(metadata['reports']))
                        with col2:
                            st.metric("é¢„è§£æå¯ç”¨", parsed_count, f"{parsed_count/len(metadata['reports'])*100:.1f}%" if len(metadata['reports']) > 0 else "0%")
                        with col3:
                            st.metric("ä»…åŸå§‹æ–‡ä»¶", raw_only_count, f"{raw_only_count/len(metadata['reports'])*100:.1f}%" if len(metadata['reports']) > 0 else "0%")
                except Exception as e:
                    st.write(f"å…ƒæ•°æ®ç»Ÿè®¡è·å–å¤±è´¥: {str(e)}")
                
                # æ˜¾ç¤ºæŠ¥è¡¨åˆ—è¡¨
                st.write("**å¯ç”¨æŠ¥è¡¨é—¨åº—ï¼š**")
                report_names = list(reports_data.keys())
                for i, name in enumerate(report_names[:10], 1):  # æ˜¾ç¤ºå‰10ä¸ª
                    df = reports_data[name]
                    st.write(f"{i}. **{name}** - {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")
                
                if len(report_names) > 10:
                    st.write(f"... è¿˜æœ‰ {len(report_names) - 10} ä¸ªæŠ¥è¡¨")
        else:
            st.warning("âš ï¸ æŠ¥è¡¨æ•°æ®ä¸å¯ç”¨")
        
        # æ‰‹åŠ¨åˆ·æ–°åŠŸèƒ½
        st.divider()
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("ğŸ”„ åˆ·æ–°æƒé™æ•°æ®"):
                cache_key = get_cache_key("permissions", "load")
                if f"cache_{cache_key}" in st.session_state:
                    del st.session_state[f"cache_{cache_key}"]
                debug_logger.log('INFO', 'ç®¡ç†å‘˜æ‰‹åŠ¨åˆ·æ–°æƒé™æ•°æ®')
                st.rerun()
        
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°æŠ¥è¡¨æ•°æ®"):
                cache_key = get_cache_key("reports", "load")
                if f"cache_{cache_key}" in st.session_state:
                    del st.session_state[f"cache_{cache_key}"]
                debug_logger.log('INFO', 'ç®¡ç†å‘˜æ‰‹åŠ¨åˆ·æ–°æŠ¥è¡¨æ•°æ®')
                st.rerun()
        
        with col3:
            if st.button("ğŸ”„ åˆ·æ–°æ‰€æœ‰æ•°æ®"):
                # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
                cache_keys = [key for key in st.session_state.keys() if key.startswith('cache_')]
                for key in cache_keys:
                    del st.session_state[key]
                debug_logger.log('INFO', 'ç®¡ç†å‘˜æ‰‹åŠ¨åˆ·æ–°æ‰€æœ‰æ•°æ®')
                st.rerun()
                
    except Exception as e:
        st.error(f"âŒ æ•°æ®ç»Ÿè®¡åŠ è½½å¤±è´¥ï¼š{str(e)}")
        debug_logger.log('ERROR', f'ç®¡ç†å‘˜æ•°æ®ç»Ÿè®¡å¤±è´¥: {str(e)}')
        
        # æä¾›è¯Šæ–­ä¿¡æ¯
        if st.session_state.debug_mode:
            with st.expander("ğŸ” é”™è¯¯è¯Šæ–­ä¿¡æ¯"):
                st.write(f"**é”™è¯¯ç±»å‹:** {type(e).__name__}")
                st.write(f"**é”™è¯¯ä¿¡æ¯:** {str(e)}")
                
                # æ˜¾ç¤ºç³»ç»Ÿæ–‡ä»¶çŠ¶æ€
                try:
                    files = cos_manager.list_files("system/")
                    st.write("**ç³»ç»Ÿæ–‡ä»¶çŠ¶æ€:**")
                    for file_info in files:
                        st.write(f"- {file_info['filename']} ({file_info['size']} å­—èŠ‚)")
                except Exception as file_e:
                    st.write(f"æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨: {str(file_e)}")
        
        # æä¾›é‡è¯•æŒ‰é’®
        if st.button("ğŸ”„ é‡è¯•åŠ è½½"):
            st.rerun()

elif user_type == "ç®¡ç†å‘˜" and not st.session_state.is_admin:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ç®¡ç†å‘˜å¯†ç ")

else:
    if not st.session_state.logged_in:
        st.subheader("ğŸ” ç”¨æˆ·ç™»å½•")
        
        try:
            with st.spinner("æ­£åœ¨åŠ è½½æƒé™æ•°æ®..."):
                permissions_data = load_permissions_from_cos(cos_manager)
            
            if permissions_data is None or len(permissions_data) == 0:
                st.markdown('''
                <div class="status-warning">
                <h4>âš ï¸ ç³»ç»Ÿç»´æŠ¤ä¸­</h4>
                <p>æš‚æ— å¯ç”¨æƒé™æ•°æ®ï¼Œå¯èƒ½çš„åŸå› ï¼š</p>
                <ul>
                <li>ç®¡ç†å‘˜å°šæœªä¸Šä¼ æƒé™è¡¨</li>
                <li>æƒé™æ•°æ®æ­£åœ¨åŒæ­¥ä¸­</li>
                <li>ç³»ç»Ÿæ­£åœ¨ç»´æŠ¤</li>
                </ul>
                <p>è¯·è”ç³»ç®¡ç†å‘˜æˆ–ç¨åé‡è¯•</p>
                </div>
                ''', unsafe_allow_html=True)
                
                # è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºæ›´å¤šä¿¡æ¯
                if st.session_state.debug_mode:
                    with st.expander("ğŸ” æƒé™æ•°æ®è°ƒè¯•ä¿¡æ¯"):
                        st.write("**æƒé™æ•°æ®çŠ¶æ€:**")
                        st.write(f"- æƒé™æ•°æ®å¯¹è±¡: {type(permissions_data)}")
                        st.write(f"- æ•°æ®æ˜¯å¦ä¸ºNone: {permissions_data is None}")
                        if permissions_data is not None:
                            st.write(f"- æ•°æ®é•¿åº¦: {len(permissions_data)}")
                        
                        # å°è¯•æ˜¾ç¤ºCOSä¸­çš„æ–‡ä»¶
                        try:
                            files = cos_manager.list_files("system/")
                            st.write("**ç³»ç»Ÿæ–‡ä»¶åˆ—è¡¨:**")
                            for file_info in files:
                                st.write(f"- {file_info['filename']} ({file_info['size']} å­—èŠ‚)")
                        except:
                            st.write("- æ— æ³•è·å–ç³»ç»Ÿæ–‡ä»¶åˆ—è¡¨")
                
                # æä¾›æ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
                if st.button("ğŸ”„ é‡æ–°åŠ è½½æƒé™æ•°æ®"):
                    # æ¸…é™¤ç¼“å­˜
                    cache_key = get_cache_key("permissions", "load")
                    if f"cache_{cache_key}" in st.session_state:
                        del st.session_state[f"cache_{cache_key}"]
                    debug_logger.log('INFO', 'æ‰‹åŠ¨æ¸…é™¤æƒé™ç¼“å­˜')
                    st.rerun()
                    
            else:
                # æƒé™æ•°æ®æ­£å¸¸ï¼Œæ˜¾ç¤ºç™»å½•ç•Œé¢
                stores = []
                try:
                    stores = sorted(permissions_data[permissions_data.columns[0]].unique().tolist())
                    # è¿‡æ»¤ç©ºå€¼
                    stores = [s for s in stores if s and str(s).strip()]
                except Exception as e:
                    debug_logger.log('ERROR', f'å¤„ç†é—¨åº—åˆ—è¡¨å¤±è´¥: {str(e)}')
                    st.error(f"å¤„ç†é—¨åº—æ•°æ®å¤±è´¥: {str(e)}")
                
                if not stores:
                    st.error("âŒ æƒé™æ•°æ®ä¸­æ²¡æœ‰æœ‰æ•ˆçš„é—¨åº—ä¿¡æ¯")
                else:
                    st.success(f"âœ… å‘ç° {len(stores)} ä¸ªé—¨åº—ï¼Œ{len(permissions_data)} ä¸ªç”¨æˆ·æƒé™")
                    
                    with st.form("login_form"):
                        selected_store = st.selectbox("é€‰æ‹©é—¨åº—", stores, help="è¯·é€‰æ‹©æ‚¨æ‰€å±çš„é—¨åº—")
                        user_id = st.text_input("äººå‘˜ç¼–å·", help="è¯·è¾“å…¥æ‚¨çš„å‘˜å·¥ç¼–å·")
                        submit = st.form_submit_button("ğŸš€ ç™»å½•æŸ¥è¯¢", type="primary")
                        
                        if submit:
                            if not selected_store:
                                st.error("âŒ è¯·é€‰æ‹©é—¨åº—")
                            elif not user_id:
                                st.error("âŒ è¯·è¾“å…¥äººå‘˜ç¼–å·")
                            else:
                                debug_logger.log('INFO', 'ç”¨æˆ·å°è¯•ç™»å½•', {
                                    'store': selected_store,
                                    'user_id': user_id
                                })
                                
                                with st.spinner("æ­£åœ¨éªŒè¯æƒé™..."):
                                    if verify_user_permission(selected_store, user_id, permissions_data):
                                        st.session_state.logged_in = True
                                        st.session_state.store_name = selected_store
                                        st.session_state.user_id = user_id
                                        debug_logger.log('INFO', 'ç”¨æˆ·ç™»å½•æˆåŠŸ', {
                                            'store': selected_store,
                                            'user_id': user_id
                                        })
                                        show_status_message("âœ… ç™»å½•æˆåŠŸï¼æ­£åœ¨åŠ è½½æ•°æ®...", "success")
                                        st.balloons()
                                        time.sleep(1)
                                        st.rerun()
                                    else:
                                        show_status_message("âŒ é—¨åº—æˆ–ç¼–å·é”™è¯¯ï¼Œè¯·æ£€æŸ¥åé‡è¯•", "error")
                                        debug_logger.log('WARNING', 'ç”¨æˆ·ç™»å½•å¤±è´¥', {
                                            'store': selected_store,
                                            'user_id': user_id
                                        })
                                        
                                        # è°ƒè¯•æ¨¡å¼ä¸‹æ˜¾ç¤ºåŒ¹é…ä¿¡æ¯
                                        if st.session_state.debug_mode:
                                            with st.expander("ğŸ” æƒé™éªŒè¯è°ƒè¯•ä¿¡æ¯"):
                                                st.write(f"**æŸ¥è¯¢ä¿¡æ¯:**")
                                                st.write(f"- é—¨åº—: '{selected_store}'")
                                                st.write(f"- ç¼–å·: '{user_id}'")
                                                st.write(f"- æ ‡å‡†åŒ–é—¨åº—å: '{normalize_store_name(selected_store)}'")
                                                
                                                st.write(f"**æƒé™æ•°æ®æ ·ä¾‹ (å‰5æ¡):**")
                                                if len(permissions_data) > 0:
                                                    sample_df = permissions_data.head(5)
                                                    st.dataframe(sample_df)
                                                else:
                                                    st.write("æƒé™æ•°æ®ä¸ºç©º")
                                
        except Exception as e:
            show_status_message(f"âŒ æƒé™ç³»ç»Ÿé”™è¯¯ï¼š{str(e)}", "error")
            debug_logger.log('ERROR', f'æƒé™ç³»ç»Ÿå¼‚å¸¸: {str(e)}')
            
            # æä¾›é‡è¯•é€‰é¡¹
            if st.button("ğŸ”„ é‡è¯•"):
                st.rerun()
    
    else:
        # å·²ç™»å½• - æ˜¾ç¤ºæŠ¥è¡¨ç•Œé¢
        st.markdown(f'''
        <div class="store-info">
        <h3>ğŸª {st.session_state.store_name}</h3>
        <p>æŸ¥è¯¢å‘˜å·¥ï¼š{st.session_state.user_id}</p>
        <p>æŸ¥è¯¢æ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
        <p>æ•°æ®æ¥æºï¼šè…¾è®¯äº‘COSæ··åˆå­˜å‚¨</p>
        </div>
        ''', unsafe_allow_html=True)
        
        # æ•°æ®åˆ·æ–°å’Œé€€å‡ºæŒ‰é’®
        col1, col2, col3 = st.columns([3, 1, 1])
        with col2:
            if st.button("ğŸ”„ åˆ·æ–°æ•°æ®"):
                # æ¸…é™¤æŠ¥è¡¨ç¼“å­˜
                cache_key = get_cache_key("reports", "load")
                if f"cache_{cache_key}" in st.session_state:
                    del st.session_state[f"cache_{cache_key}"]
                debug_logger.log('INFO', 'ç”¨æˆ·æ‰‹åŠ¨åˆ·æ–°æŠ¥è¡¨æ•°æ®')
                st.rerun()
        
        with col3:
            if st.button("ğŸšª é€€å‡º"):
                st.session_state.logged_in = False
                st.session_state.store_name = ""
                st.session_state.user_id = ""
                debug_logger.log('INFO', 'ç”¨æˆ·é€€å‡ºç™»å½•')
                st.rerun()
        
        try:
            with st.spinner("æ­£åœ¨åŠ è½½æŠ¥è¡¨æ•°æ®..."):
                reports_data = load_reports_from_cos(cos_manager)
            
            if not reports_data:
                st.markdown(f'''
                <div class="status-warning">
                <h4>âš ï¸ æš‚æ— æŠ¥è¡¨æ•°æ®</h4>
                <p>é—¨åº— "<strong>{st.session_state.store_name}</strong>" çš„æŠ¥è¡¨æ•°æ®ä¸å¯ç”¨</p>
                <h5>å¯èƒ½çš„åŸå› ï¼š</h5>
                <ul>
                <li>ğŸ“‹ ç®¡ç†å‘˜å°šæœªä¸Šä¼ è¯¥é—¨åº—çš„æŠ¥è¡¨æ–‡ä»¶</li>
                <li>â³ æ•°æ®æ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨åé‡è¯•</li>
                <li>ğŸ”„ ç³»ç»Ÿæ­£åœ¨åŒæ­¥æ•°æ®</li>
                <li>ğŸ”— ç½‘ç»œè¿æ¥ä¸ç¨³å®š</li>
                </ul>
                <h5>å»ºè®®æ“ä½œï¼š</h5>
                <ul>
                <li>ğŸ”„ ç‚¹å‡»"åˆ·æ–°æ•°æ®"æŒ‰é’®é‡æ–°åŠ è½½</li>
                <li>ğŸ“ è”ç³»ç®¡ç†å‘˜ç¡®è®¤æ•°æ®çŠ¶æ€</li>
                <li>â° ç­‰å¾…5-10åˆ†é’Ÿåé‡è¯•</li>
                </ul>
                </div>
                ''', unsafe_allow_html=True)
                
                # è°ƒè¯•ä¿¡æ¯
                if st.session_state.debug_mode:
                    with st.expander("ğŸ” æŠ¥è¡¨æ•°æ®è°ƒè¯•ä¿¡æ¯"):
                        st.write("**æŠ¥è¡¨æ•°æ®çŠ¶æ€:**")
                        st.write(f"- æŠ¥è¡¨æ•°æ®ç±»å‹: {type(reports_data)}")
                        st.write(f"- æŠ¥è¡¨æ•°é‡: {len(reports_data) if reports_data else 0}")
                        
                        if reports_data:
                            st.write(f"- å¯ç”¨é—¨åº—: {list(reports_data.keys())}")
                        
                        # æ˜¾ç¤ºå…ƒæ•°æ®ä¿¡æ¯
                        try:
                            metadata = cos_manager.download_json(cos_manager.metadata_file)
                            if metadata and 'reports' in metadata:
                                st.write(f"**å…ƒæ•°æ®çŠ¶æ€:**")
                                st.write(f"- å…ƒæ•°æ®è®°å½•æ•°: {len(metadata['reports'])}")
                                st.write(f"- è®°å½•çš„é—¨åº—: {[r.get('store_name') for r in metadata['reports'][:5]]}")
                        except Exception as e:
                            st.write(f"- å…ƒæ•°æ®è·å–å¤±è´¥: {str(e)}")
                
            else:
                # æŸ¥æ‰¾åŒ¹é…çš„æŠ¥è¡¨
                matching_sheets = find_matching_reports(st.session_state.store_name, reports_data)
                
                if not matching_sheets:
                    st.markdown(f'''
                    <div class="status-error">
                    <h4>âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æŠ¥è¡¨</h4>
                    <p>é—¨åº— "<strong>{st.session_state.store_name}</strong>" æ²¡æœ‰åŒ¹é…çš„æŠ¥è¡¨æ•°æ®</p>
                    </div>
                    ''', unsafe_allow_html=True)
                    
                    # æ˜¾ç¤ºå¯ç”¨çš„æŠ¥è¡¨ä¾›å‚è€ƒ
                    if st.session_state.debug_mode:
                        with st.expander("ğŸ” æŠ¥è¡¨åŒ¹é…è°ƒè¯•ä¿¡æ¯"):
                            st.write(f"**æŸ¥è¯¢é—¨åº—:** '{st.session_state.store_name}'")
                            st.write(f"**æ ‡å‡†åŒ–åç§°:** '{normalize_store_name(st.session_state.store_name)}'")
                            st.write(f"**ç³»ç»Ÿä¸­çš„é—¨åº— (å‰10ä¸ª):**")
                            available_stores = list(reports_data.keys())[:10]
                            for store in available_stores:
                                normalized = normalize_store_name(store)
                                st.write(f"- '{store}' â†’ '{normalized}'")
                else:
                    # æˆåŠŸæ‰¾åˆ°åŒ¹é…çš„æŠ¥è¡¨
                    if len(matching_sheets) > 1:
                        st.info(f"æ‰¾åˆ° {len(matching_sheets)} ä¸ªåŒ¹é…çš„æŠ¥è¡¨")
                        selected_sheet = st.selectbox("é€‰æ‹©æŠ¥è¡¨", matching_sheets)
                    else:
                        selected_sheet = matching_sheets[0]
                        st.success(f"âœ… æˆåŠŸåŠ è½½æŠ¥è¡¨ï¼š{selected_sheet}")
                    
                    df = reports_data[selected_sheet]
                    
                    # æ˜¾ç¤ºæŠ¥è¡¨æ•°æ®å’Œåˆ†æï¼ˆä¿æŒåŸæœ‰çš„æ˜¾ç¤ºé€»è¾‘ï¼‰
                    # åº”æ”¶-æœªæ”¶é¢åˆ†æ
                    st.subheader("ğŸ’° åº”æ”¶-æœªæ”¶é¢")
                    
                    try:
                        analysis_results = analyze_receivable_data(df)
                        
                        if 'åº”æ”¶-æœªæ”¶é¢' in analysis_results:
                            data = analysis_results['åº”æ”¶-æœªæ”¶é¢']
                            amount = data['amount']
                            
                            col1, col2, col3 = st.columns([1, 2, 1])
                            with col2:
                                if amount > 0:
                                    st.markdown(f'''
                                        <div class="receivable-positive">
                                            <h1 style="margin: 0; font-size: 3rem;">ğŸ’³ Â¥{amount:,.2f}</h1>
                                            <h3 style="margin: 0.5rem 0;">é—¨åº—åº”ä»˜æ¬¾</h3>
                                            <p style="margin: 0; font-size: 0.9rem;">æ•°æ®æ¥æº: {data['row_name']} (ç¬¬{data['actual_row_number']}è¡Œ)</p>
                                        </div>
                                    ''', unsafe_allow_html=True)
                                
                                elif amount < 0:
                                    st.markdown(f'''
                                        <div class="receivable-negative">
                                            <h1 style="margin: 0; font-size: 3rem;">ğŸ’š Â¥{abs(amount):,.2f}</h1>
                                            <h3 style="margin: 0.5rem 0;">æ€»éƒ¨åº”é€€æ¬¾</h3>
                                            <p style="margin: 0; font-size: 0.9rem;">æ•°æ®æ¥æº: {data['row_name']} (ç¬¬{data['actual_row_number']}è¡Œ)</p>
                                        </div>
                                    ''', unsafe_allow_html=True)
                                
                                else:
                                    st.markdown('''
                                        <div style="background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%); color: #2e7d32; padding: 2rem; border-radius: 15px; text-align: center; box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);">
                                            <h1 style="margin: 0; font-size: 3rem;">âš–ï¸ Â¥0.00</h1>
                                            <h3 style="margin: 0.5rem 0;">æ”¶æ”¯å¹³è¡¡</h3>
                                            <p style="margin: 0;">åº”æ”¶æœªæ”¶é¢ä¸ºé›¶ï¼Œè´¦ç›®å¹³è¡¡</p>
                                        </div>
                                    ''', unsafe_allow_html=True)
                        
                        else:
                            st.warning("âš ï¸ æœªæ‰¾åˆ°åº”æ”¶-æœªæ”¶é¢æ•°æ®")
                            
                            with st.expander("ğŸ” æŸ¥çœ‹è¯¦æƒ…", expanded=False):
                                debug_info = analysis_results.get('debug_info', {})
                                
                                st.markdown("### ğŸ“‹ æ•°æ®æŸ¥æ‰¾è¯´æ˜")
                                st.write(f"- **æŠ¥è¡¨æ€»è¡Œæ•°ï¼š** {debug_info.get('total_rows', 0)} è¡Œ")
                                
                                if debug_info.get('checked_row_69'):
                                    st.write(f"- **ç¬¬69è¡Œå†…å®¹ï¼š** {debug_info.get('row_69_content', 'N/A')}")
                                else:
                                    st.write("- **ç¬¬69è¡Œï¼š** æŠ¥è¡¨è¡Œæ•°ä¸è¶³69è¡Œ")
                                
                                st.markdown("""
                                ### ğŸ’¡ å¯èƒ½çš„åŸå› 
                                1. ç¬¬69è¡Œä¸åŒ…å«"åº”æ”¶-æœªæ”¶é¢"ç›¸å…³å…³é”®è¯
                                2. ç¬¬69è¡Œçš„æ•°å€¼ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®
                                3. æŠ¥è¡¨æ ¼å¼ä¸é¢„æœŸä¸ç¬¦
                                
                                ### ğŸ› ï¸ å»ºè®®
                                - è¯·æ£€æŸ¥ExcelæŠ¥è¡¨ç¬¬69è¡Œæ˜¯å¦åŒ…å«"åº”æ”¶-æœªæ”¶é¢"
                                - ç¡®è®¤è¯¥è¡Œæœ‰å¯¹åº”çš„é‡‘é¢æ•°æ®
                                - å¦‚éœ€è°ƒæ•´æŸ¥æ‰¾ä½ç½®ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ
                                """)
                    
                    except Exception as e:
                        show_status_message(f"âŒ åˆ†ææ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}", "error")
                        debug_logger.log('ERROR', f'åº”æ”¶-æœªæ”¶é¢åˆ†æå¤±è´¥: {str(e)}')
                    
                    st.divider()
                    
                    # å®Œæ•´æŠ¥è¡¨æ•°æ®å±•ç¤ºï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    st.subheader("ğŸ“‹ å®Œæ•´æŠ¥è¡¨æ•°æ®")
                    
                    search_term = st.text_input("ğŸ” æœç´¢æŠ¥è¡¨å†…å®¹")
                    
                    try:
                        if search_term:
                            search_df = df.copy()
                            for col in search_df.columns:
                                search_df[col] = search_df[col].astype(str).fillna('')
                            
                            mask = search_df.apply(
                                lambda x: x.str.contains(search_term, case=False, na=False, regex=False)
                            ).any(axis=1)
                            filtered_df = df[mask]
                            st.info(f"æ‰¾åˆ° {len(filtered_df)} æ¡åŒ…å« '{search_term}' çš„è®°å½•")
                        else:
                            filtered_df = df
                        
                        st.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼šå…± {len(filtered_df)} æ¡è®°å½•ï¼Œ{len(df.columns)} åˆ—")
                        
                        if len(filtered_df) > 0:
                            display_df = filtered_df.copy()
                            
                            # ç¡®ä¿åˆ—åå”¯ä¸€
                            unique_columns = []
                            for i, col in enumerate(display_df.columns):
                                col_name = str(col)
                                if col_name in unique_columns:
                                    col_name = f"{col_name}_{i}"
                                unique_columns.append(col_name)
                            display_df.columns = unique_columns
                            
                            # æ¸…ç†æ•°æ®å†…å®¹
                            for col in display_df.columns:
                                display_df[col] = display_df[col].astype(str).fillna('')
                            
                            st.dataframe(display_df, use_container_width=True, height=400)
                        
                        else:
                            st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
                            
                    except Exception as e:
                        show_status_message(f"âŒ æ•°æ®å¤„ç†æ—¶å‡ºé”™ï¼š{str(e)}", "error")
                        debug_logger.log('ERROR', f'æ•°æ®å¤„ç†å¼‚å¸¸: {str(e)}')
                    
                    # ä¸‹è½½åŠŸèƒ½ï¼ˆä¿æŒåŸæœ‰çš„ä¸‰åˆ—ä¸‹è½½é€»è¾‘ï¼‰
                    st.subheader("ğŸ“¥ æ•°æ®ä¸‹è½½")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    # ä¸‹è½½å¤„ç†åçš„Excel
                    with col1:
                        try:
                            buffer = io.BytesIO()
                            download_df = df.copy()
                            
                            # ç¡®ä¿åˆ—åå”¯ä¸€
                            unique_cols = []
                            for i, col in enumerate(download_df.columns):
                                col_name = str(col)
                                if col_name in unique_cols:
                                    col_name = f"{col_name}_{i}"
                                unique_cols.append(col_name)
                            download_df.columns = unique_cols
                            
                            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                download_df.to_excel(writer, index=False)
                            
                            st.download_button(
                                "ğŸ“Š ä¸‹è½½å¤„ç†åExcel",
                                buffer.getvalue(),
                                f"{st.session_state.store_name}_å¤„ç†æ•°æ®_{datetime.now().strftime('%Y%m%d')}.xlsx",
                                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        except Exception as e:
                            st.error(f"å¤„ç†åExcelä¸‹è½½å¤±è´¥ï¼š{str(e)}")
                    
                    # ä¸‹è½½åŸå§‹Excelæ–‡ä»¶
                    with col2:
                        try:
                            original_data = get_original_file_for_download(st.session_state.store_name, cos_manager)
                            if original_data:
                                st.download_button(
                                    "ğŸ“„ ä¸‹è½½åŸå§‹Excel",
                                    original_data,
                                    f"{st.session_state.store_name}_åŸå§‹æ–‡ä»¶_{datetime.now().strftime('%Y%m%d')}.xlsx",
                                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                            else:
                                st.error("åŸå§‹æ–‡ä»¶ä¸å¯ç”¨")
                        except Exception as e:
                            st.error(f"åŸå§‹æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼š{str(e)}")
                    
                    # ä¸‹è½½CSVæ ¼å¼
                    with col3:
                        try:
                            csv_df = df.copy()
                            unique_cols = []
                            for i, col in enumerate(csv_df.columns):
                                col_name = str(col)
                                if col_name in unique_cols:
                                    col_name = f"{col_name}_{i}"
                                unique_cols.append(col_name)
                            csv_df.columns = unique_cols
                            
                            csv = csv_df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                "ğŸ“‹ ä¸‹è½½CSVæ ¼å¼",
                                csv,
                                f"{st.session_state.store_name}_æŠ¥è¡¨_{datetime.now().strftime('%Y%m%d')}.csv",
                                "text/csv"
                            )
                        except Exception as e:
                            st.error(f"CSVä¸‹è½½å¤±è´¥ï¼š{str(e)}")
                
        except Exception as e:
            show_status_message(f"âŒ æŠ¥è¡¨ç³»ç»Ÿé”™è¯¯ï¼š{str(e)}", "error")
            debug_logger.log('ERROR', f'æŠ¥è¡¨ç³»ç»Ÿå¼‚å¸¸: {str(e)}')
            
            # æä¾›é‡è¯•é€‰é¡¹
            if st.button("ğŸ”„ é‡æ–°åŠ è½½"):
                st.rerun()

# é¡µé¢åº•éƒ¨çŠ¶æ€ä¿¡æ¯
st.divider()
col1, col2, col3, col4 = st.columns(4)
with col1:
    st.caption(f"ğŸ•’ å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
with col2:
    cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
    st.caption(f"ğŸ’¾ ç¼“å­˜é¡¹ç›®: {cache_count}")
with col3:
    st.caption("â˜ï¸ è…¾è®¯äº‘COSå­˜å‚¨")
with col4:
    st.caption(f"ğŸ”§ ç‰ˆæœ¬: v2.1 (COSç‰ˆ) | API: {API_RATE_LIMIT}/h")
