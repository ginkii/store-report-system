import streamlit as st
import pandas as pd
import io
import json
from datetime import datetime
import time
import logging
from typing import Optional, Dict, Any, List
import hashlib
import pickle
import traceback
from contextlib import contextmanager
from qcloud_cos import CosConfig, CosS3Client
from qcloud_cos.cos_exception import CosServiceError
import openpyxl

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="é—¨åº—æŠ¥è¡¨æŸ¥è¯¢ç³»ç»Ÿ", 
    page_icon="ğŸ“Š",
    layout="wide"
)

# ç³»ç»Ÿé…ç½®
ADMIN_PASSWORD = "admin123"
MAX_RETRIES = 3
RETRY_DELAY = 1
CACHE_DURATION = 300  # ç¼“å­˜5åˆ†é’Ÿ

# CSSæ ·å¼
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
        margin-bottom: 2rem;
    }
    .store-info {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    }
    .admin-panel {
        background: linear-gradient(135deg, #ffeaa7 0%, #fab1a0 100%);
        padding: 1.5rem;
        border-radius: 10px;
        border: 2px solid #fdcb6e;
        margin: 1rem 0;
    }
    .receivable-positive {
        background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
        color: #721c24;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #f093fb;
        margin: 1rem 0;
        text-align: center;
    }
    .receivable-negative {
        background: linear-gradient(135deg, #a8edea 0%, #d299c2 100%);
        color: #0c4128;
        padding: 2rem;
        border-radius: 15px;
        border: 3px solid #48cab2;
        margin: 1rem 0;
        text-align: center;
    }
    .status-success {
        background: #d4edda;
        color: #155724;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #c3e6cb;
        margin: 0.5rem 0;
    }
    .status-error {
        background: #f8d7da;
        color: #721c24;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #f5c6cb;
        margin: 0.5rem 0;
    }
    .status-warning {
        background: #fff3cd;
        color: #856404;
        padding: 0.75rem;
        border-radius: 5px;
        border: 1px solid #ffeaa7;
        margin: 0.5rem 0;
    }
    </style>
""", unsafe_allow_html=True)

class CosOperationError(Exception):
    """è…¾è®¯äº‘COSæ“ä½œå¼‚å¸¸"""
    pass

class DataProcessingError(Exception):
    """æ•°æ®å¤„ç†å¼‚å¸¸"""
    pass

@contextmanager
def error_handler(operation_name: str):
    """é€šç”¨é”™è¯¯å¤„ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    try:
        yield
    except Exception as e:
        logger.error(f"{operation_name} å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        st.error(f"âŒ {operation_name} å¤±è´¥: {str(e)}")
        raise

def retry_operation(func, *args, max_retries=MAX_RETRIES, delay=RETRY_DELAY, **kwargs):
    """é‡è¯•æ“ä½œè£…é¥°å™¨"""
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if attempt == max_retries - 1:
                logger.error(f"æ“ä½œå¤±è´¥ï¼Œå·²é‡è¯• {max_retries} æ¬¡: {str(e)}")
                raise
            logger.warning(f"æ“ä½œå¤±è´¥ï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•: {str(e)}")
            time.sleep(delay * (attempt + 1))  # é€’å¢å»¶è¿Ÿ

def get_cache_key(operation: str, params: str) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    return hashlib.md5(f"{operation}_{params}".encode()).hexdigest()

def set_cache(key: str, data: Any, duration: int = CACHE_DURATION):
    """è®¾ç½®ç¼“å­˜"""
    try:
        cache_data = {
            'data': data,
            'timestamp': time.time(),
            'duration': duration
        }
        st.session_state[f"cache_{key}"] = cache_data
    except Exception as e:
        logger.warning(f"è®¾ç½®ç¼“å­˜å¤±è´¥: {str(e)}")

def get_cache(key: str) -> Optional[Any]:
    """è·å–ç¼“å­˜"""
    try:
        cache_key = f"cache_{key}"
        if cache_key in st.session_state:
            cache_data = st.session_state[cache_key]
            if time.time() - cache_data['timestamp'] < cache_data['duration']:
                return cache_data['data']
            else:
                del st.session_state[cache_key]
    except Exception as e:
        logger.warning(f"è·å–ç¼“å­˜å¤±è´¥: {str(e)}")
    return None

@st.cache_resource(show_spinner="è¿æ¥è…¾è®¯äº‘å­˜å‚¨...")
def get_cos_client():
    """è·å–è…¾è®¯äº‘COSå®¢æˆ·ç«¯ - ä½¿ç”¨ç¼“å­˜"""
    try:
        cos_config = st.secrets["tencent_cloud"]
        
        config = CosConfig(
            Region=cos_config["region"],
            SecretId=cos_config["secret_id"],
            SecretKey=cos_config["secret_key"],
        )
        
        client = CosS3Client(config)
        logger.info("è…¾è®¯äº‘COSå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
        return client, cos_config["bucket_name"], cos_config["permissions_file"]
    except Exception as e:
        logger.error(f"è…¾è®¯äº‘COSå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {str(e)}")
        raise CosOperationError(f"è¿æ¥å¤±è´¥: {str(e)}")

def safe_cos_operation(operation_func, *args, **kwargs):
    """å®‰å…¨çš„COSæ“ä½œ"""
    return retry_operation(operation_func, *args, **kwargs)

def save_permissions_to_cos(df: pd.DataFrame, cos_client, bucket_name: str, permissions_file: str) -> bool:
    """ä¿å­˜æƒé™æ•°æ®åˆ°COS - å¢å¼ºé”™è¯¯æ’æŸ¥ç‰ˆ"""
    with error_handler("ä¿å­˜æƒé™æ•°æ®"):
        def _save_operation():
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # æ•°æ®éªŒè¯
            if df.empty:
                error_msg = "æƒé™æ•°æ®ä¸ºç©ºï¼Œæ— æ³•ä¿å­˜"
                logger.error(error_msg)
                st.session_state.operation_status.append({
                    "message": f"âŒ {error_msg}", 
                    "type": "error"
                })
                return False
            
            if len(df.columns) < 2:
                error_msg = f"æƒé™æ•°æ®æ ¼å¼é”™è¯¯ï¼šéœ€è¦è‡³å°‘2åˆ—ï¼Œå½“å‰åªæœ‰ {len(df.columns)} åˆ—"
                logger.error(error_msg)
                st.session_state.operation_status.append({
                    "message": f"âŒ {error_msg}", 
                    "type": "error"
                })
                return False
            
            # å‡†å¤‡CSVæ•°æ®
            try:
                csv_data = []
                csv_data.append(['é—¨åº—åç§°', 'äººå‘˜ç¼–å·', 'æ›´æ–°æ—¶é—´'])
                
                valid_rows = 0
                for _, row in df.iterrows():
                    store_name = str(row.iloc[0]).strip()
                    user_id = str(row.iloc[1]).strip()
                    
                    if store_name and user_id and store_name != 'nan' and user_id != 'nan':
                        csv_data.append([store_name, user_id, current_time])
                        valid_rows += 1
                
                if valid_rows == 0:
                    error_msg = "æƒé™æ•°æ®ä¸­æ²¡æœ‰æœ‰æ•ˆçš„é—¨åº—åç§°å’Œäººå‘˜ç¼–å·ç»„åˆ"
                    logger.error(error_msg)
                    st.session_state.operation_status.append({
                        "message": f"âŒ {error_msg}", 
                        "type": "error"
                    })
                    return False
                
            except Exception as data_error:
                error_msg = f"æƒé™æ•°æ®å¤„ç†å¤±è´¥: {str(data_error)}"
                logger.error(error_msg, exc_info=True)
                st.session_state.operation_status.append({
                    "message": f"âŒ {error_msg}", 
                    "type": "error"
                })
                return False
            
            # è½¬æ¢ä¸ºCSVæ ¼å¼
            try:
                csv_buffer = io.StringIO()
                pd.DataFrame(csv_data[1:], columns=csv_data[0]).to_csv(csv_buffer, index=False, encoding='utf-8-sig')
                csv_content = csv_buffer.getvalue()
                
                if not csv_content:
                    error_msg = "ç”Ÿæˆçš„CSVå†…å®¹ä¸ºç©º"
                    logger.error(error_msg)
                    st.session_state.operation_status.append({
                        "message": f"âŒ {error_msg}", 
                        "type": "error"
                    })
                    return False
                    
            except Exception as csv_error:
                error_msg = f"CSVæ ¼å¼è½¬æ¢å¤±è´¥: {str(csv_error)}"
                logger.error(error_msg, exc_info=True)
                st.session_state.operation_status.append({
                    "message": f"âŒ {error_msg}", 
                    "type": "error"
                })
                return False
            
            # ä¸Šä¼ åˆ°COS
            try:
                cos_client.put_object(
                    Bucket=bucket_name,
                    Body=csv_content.encode('utf-8-sig'),
                    Key=permissions_file,
                    ContentType='text/csv'
                )
                
            except CosServiceError as cos_error:
                error_msg = f"æƒé™æ–‡ä»¶COSä¸Šä¼ å¤±è´¥: {cos_error.get_error_msg()}"
                logger.error(error_msg, exc_info=True)
                st.session_state.operation_status.append({
                    "message": f"âŒ {error_msg}", 
                    "type": "error"
                })
                return False
            
            success_msg = f"æƒé™æ•°æ®ä¿å­˜æˆåŠŸ: {valid_rows} æ¡æœ‰æ•ˆè®°å½•å·²ä¿å­˜åˆ° {permissions_file}"
            logger.info(success_msg)
            st.session_state.operation_status.append({
                "message": f"âœ… {success_msg}", 
                "type": "success"
            })
            
            # æ¸…é™¤ç›¸å…³ç¼“å­˜
            cache_key = get_cache_key("permissions", "load")
            if f"cache_{cache_key}" in st.session_state:
                del st.session_state[f"cache_{cache_key}"]
            
            return True
        
        return safe_cos_operation(_save_operation)

def load_permissions_from_cos(cos_client, bucket_name: str, permissions_file: str) -> Optional[pd.DataFrame]:
    """ä»COSåŠ è½½æƒé™æ•°æ® - ä½¿ç”¨ç¼“å­˜"""
    cache_key = get_cache_key("permissions", "load")
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        logger.info("ä»ç¼“å­˜åŠ è½½æƒé™æ•°æ®")
        return cached_data
    
    with error_handler("åŠ è½½æƒé™æ•°æ®"):
        def _load_operation():
            try:
                # ä»COSä¸‹è½½æ–‡ä»¶
                response = cos_client.get_object(
                    Bucket=bucket_name,
                    Key=permissions_file
                )
                
                # è¯»å–CSVå†…å®¹
                csv_content = response['Body'].read().decode('utf-8-sig')
                df = pd.read_csv(io.StringIO(csv_content))
                
                if len(df) == 0:
                    logger.info("æƒé™è¡¨ä¸ºç©º")
                    return None
                
                result_df = df[['é—¨åº—åç§°', 'äººå‘˜ç¼–å·']].copy()
                
                # æ•°æ®æ¸…ç†
                result_df['é—¨åº—åç§°'] = result_df['é—¨åº—åç§°'].str.strip()
                result_df['äººå‘˜ç¼–å·'] = result_df['äººå‘˜ç¼–å·'].str.strip()
                
                # ç§»é™¤ç©ºè¡Œ
                result_df = result_df[
                    (result_df['é—¨åº—åç§°'] != '') & 
                    (result_df['äººå‘˜ç¼–å·'] != '')
                ]
                
                logger.info(f"æƒé™æ•°æ®åŠ è½½æˆåŠŸ: {len(result_df)} æ¡è®°å½•")
                
                # è®¾ç½®ç¼“å­˜
                set_cache(cache_key, result_df)
                return result_df
                
            except CosServiceError as e:
                if e.get_error_code() == 'NoSuchKey':
                    logger.info("æƒé™æ–‡ä»¶ä¸å­˜åœ¨")
                    return None
                else:
                    raise e
        
        return safe_cos_operation(_load_operation)

def save_report_to_cos(df: pd.DataFrame, cos_client, bucket_name: str, store_name: str) -> bool:
    """ä¿å­˜å•ä¸ªé—¨åº—æŠ¥è¡¨åˆ°COS - å¢å¼ºé”™è¯¯æ’æŸ¥ç‰ˆ"""
    try:
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"reports/{store_name}_{timestamp}.xlsx"
        
        # æ•°æ®éªŒè¯
        if df.empty:
            error_msg = f"é—¨åº— {store_name} çš„æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ä¸Šä¼ "
            logger.warning(error_msg)
            st.session_state.operation_status.append({
                "message": f"âš ï¸ {error_msg}", 
                "type": "warning"
            })
            return False
        
        # åˆ›å»ºExcelæ–‡ä»¶
        excel_buffer = io.BytesIO()
        try:
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name=store_name[:31])  # Excelå·¥ä½œè¡¨åæœ€é•¿31å­—ç¬¦
        except Exception as excel_error:
            error_msg = f"é—¨åº— {store_name} Excelæ–‡ä»¶åˆ›å»ºå¤±è´¥: {str(excel_error)}"
            logger.error(error_msg, exc_info=True)
            st.session_state.operation_status.append({
                "message": f"âŒ {error_msg}", 
                "type": "error"
            })
            return False
        
        excel_content = excel_buffer.getvalue()
        
        # éªŒè¯Excelæ–‡ä»¶å¤§å°
        file_size = len(excel_content)
        if file_size == 0:
            error_msg = f"é—¨åº— {store_name} ç”Ÿæˆçš„Excelæ–‡ä»¶å¤§å°ä¸º0"
            logger.error(error_msg)
            st.session_state.operation_status.append({
                "message": f"âŒ {error_msg}", 
                "type": "error"
            })
            return False
        
        # ä¸Šä¼ åˆ°COS
        try:
            cos_client.put_object(
                Bucket=bucket_name,
                Body=excel_content,
                Key=filename,
                ContentType='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
            )
        except CosServiceError as cos_error:
            error_msg = f"é—¨åº— {store_name} COSä¸Šä¼ å¤±è´¥: {cos_error.get_error_msg()}"
            logger.error(error_msg, exc_info=True)
            st.session_state.operation_status.append({
                "message": f"âŒ {error_msg}", 
                "type": "error"
            })
            return False
        
        success_msg = f"é—¨åº— {store_name} æŠ¥è¡¨ä¿å­˜æˆåŠŸ -> {filename} (å¤§å°: {file_size:,} å­—èŠ‚)"
        logger.info(success_msg)
        st.session_state.operation_status.append({
            "message": f"âœ… {success_msg}", 
            "type": "success"
        })
        return True
        
    except Exception as e:
        error_msg = f"é—¨åº— {store_name} æŠ¥è¡¨ä¿å­˜å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        st.session_state.operation_status.append({
            "message": f"âŒ {error_msg}", 
            "type": "error"
        })
        return False

def save_reports_to_cos(reports_dict: Dict[str, pd.DataFrame], cos_client, bucket_name: str) -> bool:
    """ä¿å­˜æŠ¥è¡¨æ•°æ®åˆ°COS - å¢å¼ºé”™è¯¯è¿½è¸ªç‰ˆ"""
    with error_handler("ä¿å­˜æŠ¥è¡¨æ•°æ®"):
        def _save_operation():
            success_count = 0
            total_count = len(reports_dict)
            failed_stores = []
            
            # æ¸…ç©ºä¹‹å‰çš„æ“ä½œçŠ¶æ€è®°å½•
            if hasattr(st.session_state, 'operation_status'):
                st.session_state.operation_status = []
            
            # æ˜¾ç¤ºè¿›åº¦
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # è¯¦ç»†ç»Ÿè®¡å®¹å™¨
            stats_container = st.empty()
            
            logger.info(f"å¼€å§‹æ‰¹é‡ä¸Šä¼ æŠ¥è¡¨: å…± {total_count} ä¸ªé—¨åº—")
            
            for idx, (store_name, df) in enumerate(reports_dict.items()):
                current_progress = (idx + 1) / total_count
                status_text.text(f"æ­£åœ¨å¤„ç† {store_name}... ({idx + 1}/{total_count})")
                
                # æ•°æ®é¢„æ£€æŸ¥
                if df.empty:
                    failed_stores.append(f"{store_name} (æ•°æ®ä¸ºç©º)")
                    logger.warning(f"è·³è¿‡ç©ºæ•°æ®é—¨åº—: {store_name}")
                else:
                    # å°è¯•ä¿å­˜å•ä¸ªé—¨åº—æŠ¥è¡¨
                    if save_report_to_cos(df, cos_client, bucket_name, store_name):
                        success_count += 1
                    else:
                        failed_stores.append(store_name)
                
                # æ›´æ–°è¿›åº¦å’Œç»Ÿè®¡
                progress_bar.progress(current_progress)
                
                # å®æ—¶æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                with stats_container.container():
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("âœ… æˆåŠŸ", success_count)
                    with col2:
                        st.metric("âŒ å¤±è´¥", len(failed_stores))
                    with col3:
                        st.metric("ğŸ“Š è¿›åº¦", f"{idx + 1}/{total_count}")
                
                # APIé™åˆ¶å»¶è¿Ÿ
                time.sleep(0.3)
            
            # æ¸…ç†è¿›åº¦æ˜¾ç¤º
            progress_bar.empty()
            status_text.empty()
            
            # æœ€ç»ˆç»Ÿè®¡æŠ¥å‘Š
            success_rate = (success_count / total_count * 100) if total_count > 0 else 0
            
            with stats_container.container():
                st.markdown("### ğŸ“‹ ä¸Šä¼ å®ŒæˆæŠ¥å‘Š")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»é—¨åº—æ•°", total_count)
                with col2:
                    st.metric("æˆåŠŸä¸Šä¼ ", success_count, delta=f"{success_rate:.1f}%")
                with col3:
                    st.metric("å¤±è´¥æ•°é‡", len(failed_stores))
                with col4:
                    success_rate_color = "normal" if success_rate >= 90 else "inverse"
                    st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
                
                # å¤±è´¥è¯¦æƒ…
                if failed_stores:
                    st.error(f"âŒ {len(failed_stores)} ä¸ªé—¨åº—ä¸Šä¼ å¤±è´¥:")
                    failed_text = "ã€".join(failed_stores)
                    if len(failed_text) > 200:
                        # å¦‚æœå¤±è´¥åˆ—è¡¨å¤ªé•¿ï¼Œä½¿ç”¨å±•å¼€æ¡†
                        with st.expander("æŸ¥çœ‹å¤±è´¥é—¨åº—åˆ—è¡¨", expanded=True):
                            for i, store in enumerate(failed_stores, 1):
                                st.write(f"{i}. {store}")
                    else:
                        st.write(failed_text)
                else:
                    st.success("ğŸ‰ æ‰€æœ‰é—¨åº—æŠ¥è¡¨å‡ä¸Šä¼ æˆåŠŸï¼")
            
            # æ¸…é™¤ç›¸å…³ç¼“å­˜
            cache_key = get_cache_key("store_list", "load")
            if f"cache_{cache_key}" in st.session_state:
                del st.session_state[f"cache_{cache_key}"]
            
            # è®°å½•æœ€ç»ˆç»“æœ
            final_msg = f"æ‰¹é‡ä¸Šä¼ å®Œæˆ: {success_count}/{total_count} ä¸ªé—¨åº—æˆåŠŸï¼ŒæˆåŠŸç‡ {success_rate:.1f}%"
            if success_count == total_count:
                logger.info(final_msg)
                st.session_state.operation_status.append({
                    "message": f"ğŸ‰ {final_msg}", 
                    "type": "success"
                })
            else:
                logger.warning(final_msg)
                st.session_state.operation_status.append({
                    "message": f"âš ï¸ {final_msg}", 
                    "type": "warning"
                })
            
            return success_count == total_count
        
        return safe_cos_operation(_save_operation)

def get_store_list_from_cos(cos_client, bucket_name: str) -> List[str]:
    """ä»COSè·å–é—¨åº—åˆ—è¡¨ - ä¼˜åŒ–ç‰ˆï¼Œåªåˆ—å‡ºæ–‡ä»¶åä¸ä¸‹è½½å†…å®¹"""
    cache_key = get_cache_key("store_list", "load")
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        logger.info("ä»ç¼“å­˜åŠ è½½é—¨åº—åˆ—è¡¨")
        return cached_data
    
    with error_handler("åŠ è½½é—¨åº—åˆ—è¡¨"):
        def _load_operation():
            try:
                store_list = []
                
                # åˆ—å‡ºreportsç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
                response = cos_client.list_objects(
                    Bucket=bucket_name,
                    Prefix='reports/',
                    MaxKeys=1000
                )
                
                if 'Contents' not in response:
                    logger.info("æŠ¥è¡¨ç›®å½•ä¸ºç©º")
                    return []
                
                # ä»æ–‡ä»¶åæå–é—¨åº—åç§°
                for obj in response['Contents']:
                    key = obj['Key']
                    if key.endswith('.xlsx') and not key.endswith('/'):
                        # ä»æ–‡ä»¶åæå–é—¨åº—åç§°
                        filename = key.split('/')[-1]  # è·å–æ–‡ä»¶å
                        store_name = filename.split('_')[0]  # æå–é—¨åº—åç§°
                        if store_name not in store_list:
                            store_list.append(store_name)
                
                logger.info(f"é—¨åº—åˆ—è¡¨åŠ è½½æˆåŠŸ: {len(store_list)} ä¸ªé—¨åº—")
                
                # è®¾ç½®ç¼“å­˜
                set_cache(cache_key, store_list)
                return sorted(store_list)
                
            except CosServiceError as e:
                logger.error(f"COSæ“ä½œå¤±è´¥: {str(e)}")
                return []
        
        return safe_cos_operation(_load_operation)

def get_single_report_from_cos(cos_client, bucket_name: str, store_name: str) -> Optional[pd.DataFrame]:
    """ä»COSè·å–å•ä¸ªé—¨åº—çš„æŠ¥è¡¨æ•°æ® - æŒ‰éœ€åŠ è½½ä¼˜åŒ–"""
    cache_key = get_cache_key("single_report", store_name)
    cached_data = get_cache(cache_key)
    if cached_data is not None:
        logger.info(f"ä»ç¼“å­˜åŠ è½½é—¨åº— {store_name} çš„æŠ¥è¡¨")
        return cached_data
    
    with error_handler(f"åŠ è½½é—¨åº— {store_name} çš„æŠ¥è¡¨"):
        def _load_operation():
            try:
                # åˆ—å‡ºè¯¥é—¨åº—çš„æ‰€æœ‰æŠ¥è¡¨æ–‡ä»¶
                response = cos_client.list_objects(
                    Bucket=bucket_name,
                    Prefix=f'reports/{store_name}_',
                    MaxKeys=100
                )
                
                if 'Contents' not in response or len(response['Contents']) == 0:
                    logger.info(f"é—¨åº— {store_name} æ²¡æœ‰æŠ¥è¡¨æ–‡ä»¶")
                    return None
                
                # è·å–æœ€æ–°çš„æ–‡ä»¶ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
                latest_file = None
                latest_time = None
                
                for obj in response['Contents']:
                    key = obj['Key']
                    if key.endswith('.xlsx'):
                        file_time = obj['LastModified']
                        if latest_time is None or file_time > latest_time:
                            latest_time = file_time
                            latest_file = key
                
                if latest_file is None:
                    logger.info(f"é—¨åº— {store_name} æ²¡æœ‰æœ‰æ•ˆçš„Excelæ–‡ä»¶")
                    return None
                
                # ä¸‹è½½å¹¶è§£ææœ€æ–°çš„æŠ¥è¡¨æ–‡ä»¶
                file_response = cos_client.get_object(
                    Bucket=bucket_name,
                    Key=latest_file
                )
                
                # è¯»å–Excelæ–‡ä»¶
                excel_content = file_response['Body'].read()
                df = pd.read_excel(io.BytesIO(excel_content))
                
                # æ•°æ®æ¸…ç† - ä¿æŒä¸åŸä»£ç ç›¸åŒçš„é€»è¾‘
                if len(df) > 0:
                    # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯é—¨åº—åç§°
                    first_row = df.iloc[0]
                    non_empty_count = sum(1 for val in first_row if pd.notna(val) and str(val).strip() != '')
                    
                    if non_empty_count <= 2 and len(df) > 1:
                        df = df.iloc[1:].reset_index(drop=True)
                
                # å¤„ç†è¡¨å¤´
                if len(df) > 1:
                    header_row = df.iloc[0].fillna('').astype(str).tolist()
                    data_rows = df.iloc[1:].copy()
                    
                    # æ¸…ç†åˆ—åå¹¶å¤„ç†é‡å¤
                    cols = []
                    for i, col in enumerate(header_row):
                        col = str(col).strip()
                        if col == '' or col == 'nan' or col == '0':
                            col = f'åˆ—{i+1}' if i > 0 else 'é¡¹ç›®åç§°'
                        
                        # å¤„ç†é‡å¤åˆ—å
                        original_col = col
                        counter = 1
                        while col in cols:
                            col = f"{original_col}_{counter}"
                            counter += 1
                        cols.append(col)
                    
                    # ç¡®ä¿åˆ—æ•°åŒ¹é…
                    min_cols = min(len(data_rows.columns), len(cols))
                    cols = cols[:min_cols]
                    data_rows = data_rows.iloc[:, :min_cols]
                    
                    data_rows.columns = cols
                    df = data_rows.reset_index(drop=True).fillna('')
                else:
                    # å¤„ç†å°‘äº3è¡Œçš„æ•°æ®
                    df = df.fillna('')
                    default_cols = []
                    for i in range(len(df.columns)):
                        col_name = f'åˆ—{i+1}' if i > 0 else 'é¡¹ç›®åç§°'
                        default_cols.append(col_name)
                    df.columns = default_cols
                
                logger.info(f"é—¨åº— {store_name} æŠ¥è¡¨åŠ è½½æˆåŠŸ: {len(df)} è¡Œ")
                
                # è®¾ç½®ç¼“å­˜
                set_cache(cache_key, df)
                return df
                
            except CosServiceError as e:
                logger.error(f"COSæ“ä½œå¤±è´¥: {str(e)}")
                return None
        
        return safe_cos_operation(_load_operation)

def analyze_receivable_data(df: pd.DataFrame) -> Dict[str, Any]:
    """åˆ†æåº”æ”¶æœªæ”¶é¢æ•°æ® - ä¸“é—¨æŸ¥æ‰¾ç¬¬69è¡Œ"""
    result = {}
    
    if len(df.columns) == 0 or len(df) == 0:
        return result
    
    # æ£€æŸ¥ç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯é—¨åº—åç§°
    original_df = df.copy()
    first_row = df.iloc[0] if len(df) > 0 else None
    if first_row is not None:
        non_empty_count = sum(1 for val in first_row if pd.notna(val) and str(val).strip() != '')
        if non_empty_count <= 2:
            df = df.iloc[1:].reset_index(drop=True)
            result['skipped_store_name_row'] = True
    
    # æŸ¥æ‰¾ç¬¬69è¡Œ
    target_row_index = 68  # ç¬¬69è¡Œ
    
    if len(df) > target_row_index:
        row = df.iloc[target_row_index]
        first_col_value = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
        
        # æ£€æŸ¥å…³é”®è¯
        keywords = ['åº”æ”¶-æœªæ”¶é¢', 'åº”æ”¶æœªæ”¶é¢', 'åº”æ”¶-æœªæ”¶', 'åº”æ”¶æœªæ”¶']
        
        for keyword in keywords:
            if keyword in first_col_value:
                # æŸ¥æ‰¾æ•°å€¼
                for col_idx in range(len(row)-1, 0, -1):
                    val = row.iloc[col_idx]
                    if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                        cleaned = str(val).replace(',', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                        
                        if cleaned.startswith('(') and cleaned.endswith(')'):
                            cleaned = '-' + cleaned[1:-1]
                        
                        try:
                            amount = float(cleaned)
                            if amount != 0:
                                result['åº”æ”¶-æœªæ”¶é¢'] = {
                                    'amount': amount,
                                    'column_name': str(df.columns[col_idx]),
                                    'row_name': first_col_value,
                                    'row_index': target_row_index,
                                    'actual_row_number': target_row_index + 1
                                }
                                return result
                        except ValueError:
                            continue
                break
    
    # å¤‡ç”¨æŸ¥æ‰¾
    if 'åº”æ”¶-æœªæ”¶é¢' not in result:
        keywords = ['åº”æ”¶-æœªæ”¶é¢', 'åº”æ”¶æœªæ”¶é¢', 'åº”æ”¶-æœªæ”¶', 'åº”æ”¶æœªæ”¶']
        
        for idx, row in df.iterrows():
            try:
                row_name = str(row.iloc[0]) if pd.notna(row.iloc[0]) else ""
                
                if not row_name.strip():
                    continue
                
                for keyword in keywords:
                    if keyword in row_name:
                        for col_idx in range(len(row)-1, 0, -1):
                            val = row.iloc[col_idx]
                            if pd.notna(val) and str(val).strip() not in ['', 'None', 'nan']:
                                cleaned = str(val).replace(',', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                                
                                if cleaned.startswith('(') and cleaned.endswith(')'):
                                    cleaned = '-' + cleaned[1:-1]
                                
                                try:
                                    amount = float(cleaned)
                                    if amount != 0:
                                        result['åº”æ”¶-æœªæ”¶é¢'] = {
                                            'amount': amount,
                                            'column_name': str(df.columns[col_idx]),
                                            'row_name': row_name,
                                            'row_index': idx,
                                            'actual_row_number': idx + 1,
                                            'note': f'åœ¨ç¬¬{idx+1}è¡Œæ‰¾åˆ°ï¼ˆéç¬¬69è¡Œï¼‰'
                                        }
                                        return result
                                except ValueError:
                                    continue
                        break
            except Exception:
                continue
    
    # è°ƒè¯•ä¿¡æ¯
    result['debug_info'] = {
        'total_rows': len(df),
        'checked_row_69': len(df) > target_row_index,
        'row_69_content': str(df.iloc[target_row_index].iloc[0]) if len(df) > target_row_index else 'N/A'
    }
    
    return result

def verify_user_permission(store_name: str, user_id: str, permissions_data: Optional[pd.DataFrame]) -> bool:
    """éªŒè¯ç”¨æˆ·æƒé™"""
    if permissions_data is None or len(permissions_data.columns) < 2:
        return False
    
    store_col = permissions_data.columns[0]
    id_col = permissions_data.columns[1]
    
    for _, row in permissions_data.iterrows():
        stored_store = str(row[store_col]).strip()
        stored_id = str(row[id_col]).strip()
        
        if (store_name in stored_store or stored_store in store_name) and stored_id == str(user_id):
            return True
    
    return False

def find_matching_stores(store_name: str, store_list: List[str]) -> List[str]:
    """æŸ¥æ‰¾åŒ¹é…çš„é—¨åº—"""
    matching = []
    for store in store_list:
        if store_name in store or store in store_name:
            matching.append(store)
    return matching

def show_status_message(message: str, status_type: str = "info"):
    """æ˜¾ç¤ºçŠ¶æ€æ¶ˆæ¯"""
    css_class = f"status-{status_type}"
    st.markdown(f'<div class="{css_class}">{message}</div>', unsafe_allow_html=True)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False
if 'store_name' not in st.session_state:
    st.session_state.store_name = ""
if 'user_id' not in st.session_state:
    st.session_state.user_id = ""
if 'is_admin' not in st.session_state:
    st.session_state.is_admin = False
if 'cos_client' not in st.session_state:
    st.session_state.cos_client = None
if 'operation_status' not in st.session_state:
    st.session_state.operation_status = []
# æ–‡ä»¶ä¸Šä¼ å™¨keyç®¡ç†
if 'reports_uploader_key' not in st.session_state:
    st.session_state.reports_uploader_key = 'initial_reports_uploader_key'
if 'permissions_uploader_key' not in st.session_state:
    st.session_state.permissions_uploader_key = 'initial_permissions_uploader_key'

# ä¸»æ ‡é¢˜
st.markdown('<h1 class="main-header">ğŸ“Š é—¨åº—æŠ¥è¡¨æŸ¥è¯¢ç³»ç»Ÿ</h1>', unsafe_allow_html=True)

# åˆå§‹åŒ–è…¾è®¯äº‘COSå®¢æˆ·ç«¯
if not st.session_state.cos_client:
    try:
        with st.spinner("è¿æ¥è…¾è®¯äº‘å­˜å‚¨..."):
            cos_client, bucket_name, permissions_file = get_cos_client()
            st.session_state.cos_client = (cos_client, bucket_name, permissions_file)
            show_status_message("âœ… è…¾è®¯äº‘å­˜å‚¨è¿æ¥æˆåŠŸï¼", "success")
    except Exception as e:
        show_status_message(f"âŒ è¿æ¥å¤±è´¥: {str(e)}", "error")
        st.stop()

cos_client, bucket_name, permissions_file = st.session_state.cos_client

# æ˜¾ç¤ºæ“ä½œçŠ¶æ€ - å¢å¼ºç‰ˆ
if st.session_state.operation_status:
    st.subheader("ğŸ“‹ æ“ä½œè¯¦æƒ…")
    
    # ç»Ÿè®¡ä¸åŒç±»å‹çš„æ¶ˆæ¯
    success_msgs = [msg for msg in st.session_state.operation_status if msg['type'] == 'success']
    error_msgs = [msg for msg in st.session_state.operation_status if msg['type'] == 'error']
    warning_msgs = [msg for msg in st.session_state.operation_status if msg['type'] == 'warning']
    
    # æ˜¾ç¤ºæ¦‚è§ˆç»Ÿè®¡
    if len(st.session_state.operation_status) > 5:
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("âœ… æˆåŠŸæ“ä½œ", len(success_msgs))
        with col2:
            st.metric("âŒ å¤±è´¥æ“ä½œ", len(error_msgs))
        with col3:
            st.metric("âš ï¸ è­¦å‘Šä¿¡æ¯", len(warning_msgs))
    
    # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤ºæ¶ˆæ¯
    if error_msgs:
        with st.expander(f"âŒ é”™è¯¯ä¿¡æ¯ ({len(error_msgs)})", expanded=True):
            for msg in error_msgs[-10:]:  # åªæ˜¾ç¤ºæœ€è¿‘10æ¡é”™è¯¯
                show_status_message(msg['message'], msg['type'])
    
    if warning_msgs:
        with st.expander(f"âš ï¸ è­¦å‘Šä¿¡æ¯ ({len(warning_msgs)})", expanded=False):
            for msg in warning_msgs[-10:]:  # åªæ˜¾ç¤ºæœ€è¿‘10æ¡è­¦å‘Š
                show_status_message(msg['message'], msg['type'])
    
    if success_msgs and len(success_msgs) <= 5:  # æˆåŠŸæ¶ˆæ¯è¾ƒå°‘æ—¶ç›´æ¥æ˜¾ç¤º
        for msg in success_msgs:
            show_status_message(msg['message'], msg['type'])
    elif success_msgs:  # æˆåŠŸæ¶ˆæ¯è¾ƒå¤šæ—¶æ”¾åœ¨å±•å¼€æ¡†ä¸­
        with st.expander(f"âœ… æˆåŠŸä¿¡æ¯ ({len(success_msgs)})", expanded=False):
            for msg in success_msgs[-20:]:  # æ˜¾ç¤ºæœ€è¿‘20æ¡æˆåŠŸæ¶ˆæ¯
                show_status_message(msg['message'], msg['type'])
    
    # æ¸…ç©ºæŒ‰é’®
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ“ä½œè®°å½•"):
        st.session_state.operation_status = []
        st.rerun()

# ä¾§è¾¹æ 
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»ŸåŠŸèƒ½")
    
    # ç³»ç»ŸçŠ¶æ€
    st.subheader("ğŸ“¡ ç³»ç»ŸçŠ¶æ€")
    if cos_client:
        st.success("ğŸŸ¢ è…¾è®¯äº‘å­˜å‚¨å·²è¿æ¥")
    else:
        st.error("ğŸ”´ è…¾è®¯äº‘å­˜å‚¨æ–­å¼€")
    
    user_type = st.radio("é€‰æ‹©ç”¨æˆ·ç±»å‹", ["æ™®é€šç”¨æˆ·", "ç®¡ç†å‘˜"])
    
    if user_type == "ç®¡ç†å‘˜":
        st.subheader("ğŸ” ç®¡ç†å‘˜ç™»å½•")
        admin_password = st.text_input("ç®¡ç†å‘˜å¯†ç ", type="password")
        
        if st.button("éªŒè¯ç®¡ç†å‘˜èº«ä»½"):
            if admin_password == ADMIN_PASSWORD:
                st.session_state.is_admin = True
                show_status_message("âœ… ç®¡ç†å‘˜éªŒè¯æˆåŠŸï¼", "success")
                st.rerun()
            else:
                show_status_message("âŒ å¯†ç é”™è¯¯ï¼", "error")
        
        if st.session_state.is_admin:
            st.subheader("ğŸ“ æ–‡ä»¶ç®¡ç†")
            
            # ä¸Šä¼ æƒé™è¡¨
            permissions_file_upload = st.file_uploader(
                "ä¸Šä¼ é—¨åº—æƒé™è¡¨", 
                type=['xlsx', 'xls'],
                key=st.session_state.permissions_uploader_key
            )
            if permissions_file_upload:
                try:
                    # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                    file_hash = hashlib.md5(permissions_file_upload.getvalue()).hexdigest()
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
                    if "last_permissions_hash" in st.session_state and \
                       st.session_state.last_permissions_hash == file_hash and \
                       st.session_state.get("permissions_upload_successful", False):
                        st.info("â„¹ï¸ è¯¥æƒé™è¡¨å·²æˆåŠŸå¤„ç†ï¼Œæ— éœ€é‡å¤æ“ä½œã€‚")
                    else:
                        st.session_state.last_permissions_hash = file_hash
                        st.session_state.permissions_upload_successful = False
                        
                        with st.spinner("å¤„ç†æƒé™è¡¨æ–‡ä»¶..."):
                            df = pd.read_excel(permissions_file_upload)
                            if len(df.columns) >= 2:
                                with st.spinner("ä¿å­˜åˆ°è…¾è®¯äº‘..."):
                                    if save_permissions_to_cos(df, cos_client, bucket_name, permissions_file):
                                        show_status_message(f"âœ… æƒé™è¡¨å·²ä¸Šä¼ ï¼š{len(df)} ä¸ªç”¨æˆ·", "success")
                                        st.session_state.permissions_upload_successful = True
                                        st.balloons()
                                        
                                        # é‡ç½®ä¸Šä¼ å™¨
                                        st.session_state.permissions_uploader_key = str(datetime.now()) + "_permissions_uploader"
                                        st.rerun()
                                    else:
                                        show_status_message("âŒ ä¿å­˜å¤±è´¥", "error")
                                        st.session_state.permissions_upload_successful = False
                            else:
                                show_status_message("âŒ æ ¼å¼é”™è¯¯ï¼šéœ€è¦è‡³å°‘ä¸¤åˆ—ï¼ˆé—¨åº—åç§°ã€äººå‘˜ç¼–å·ï¼‰", "error")
                                st.session_state.permissions_upload_successful = False
                except Exception as e:
                    show_status_message(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}", "error")
                    st.session_state.permissions_upload_successful = False
            
            # ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨
            reports_file_upload = st.file_uploader(
                "ä¸Šä¼ è´¢åŠ¡æŠ¥è¡¨", 
                type=['xlsx', 'xls'],
                key=st.session_state.reports_uploader_key
            )
            if reports_file_upload:
                try:
                    # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                    file_hash = hashlib.md5(reports_file_upload.getvalue()).hexdigest()
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
                    if "last_reports_hash" in st.session_state and \
                       st.session_state.last_reports_hash == file_hash and \
                       st.session_state.get("reports_upload_successful", False):
                        st.info("â„¹ï¸ è¯¥æŠ¥è¡¨æ–‡ä»¶å·²æˆåŠŸå¤„ç†ï¼Œæ— éœ€é‡å¤æ“ä½œã€‚")
                    else:
                        st.session_state.last_reports_hash = file_hash
                        st.session_state.reports_upload_successful = False
                        
                        with st.spinner("å¤„ç†æŠ¥è¡¨æ–‡ä»¶..."):
                            excel_file = pd.ExcelFile(reports_file_upload)
                            reports_dict = {}
                            
                            for sheet in excel_file.sheet_names:
                                try:
                                    df = pd.read_excel(reports_file_upload, sheet_name=sheet)
                                    if not df.empty:
                                        reports_dict[sheet] = df
                                        logger.info(f"è¯»å–å·¥ä½œè¡¨ '{sheet}': {len(df)} è¡Œ")
                                except Exception as e:
                                    logger.warning(f"è·³è¿‡å·¥ä½œè¡¨ '{sheet}': {str(e)}")
                                    continue
                            
                            if reports_dict:
                                with st.spinner("ä¿å­˜åˆ°è…¾è®¯äº‘..."):
                                    if save_reports_to_cos(reports_dict, cos_client, bucket_name):
                                        show_status_message(f"âœ… æŠ¥è¡¨å·²ä¸Šä¼ ï¼š{len(reports_dict)} ä¸ªé—¨åº—", "success")
                                        st.session_state.reports_upload_successful = True
                                        st.balloons()
                                        
                                        # é‡ç½®ä¸Šä¼ å™¨
                                        st.session_state.reports_uploader_key = str(datetime.now()) + "_reports_uploader"
                                        st.rerun()
                                    else:
                                        show_status_message("âŒ ä¿å­˜å¤±è´¥", "error")
                                        st.session_state.reports_upload_successful = False
                            else:
                                show_status_message("âŒ æ–‡ä»¶ä¸­æ²¡æœ‰æœ‰æ•ˆçš„å·¥ä½œè¡¨", "error")
                                st.session_state.reports_upload_successful = False
                                
                except Exception as e:
                    show_status_message(f"âŒ å¤„ç†å¤±è´¥ï¼š{str(e)}", "error")
                    st.session_state.reports_upload_successful = False
            
            # ç¼“å­˜ç®¡ç†
            st.subheader("ğŸ—‚ï¸ ç¼“å­˜ç®¡ç†")
            if st.button("æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
                cache_keys = [key for key in st.session_state.keys() if key.startswith('cache_')]
                for key in cache_keys:
                    del st.session_state[key]
                show_status_message("âœ… ç¼“å­˜å·²æ¸…é™¤", "success")
                st.rerun()
    
    else:
        if st.session_state.logged_in:
            st.subheader("ğŸ‘¤ å½“å‰ç™»å½•")
            st.info(f"é—¨åº—ï¼š{st.session_state.store_name}")
            st.info(f"ç¼–å·ï¼š{st.session_state.user_id}")
            
            if st.button("ğŸšª é€€å‡ºç™»å½•"):
                st.session_state.logged_in = False
                st.session_state.store_name = ""
                st.session_state.user_id = ""
                show_status_message("ğŸ‘‹ å·²é€€å‡ºç™»å½•", "success")
                st.rerun()

# æ¸…é™¤çŠ¶æ€æ¶ˆæ¯
st.session_state.operation_status = []

# ä¸»ç•Œé¢
if user_type == "ç®¡ç†å‘˜" and st.session_state.is_admin:
    st.markdown('<div class="admin-panel"><h3>ğŸ‘¨â€ğŸ’¼ ç®¡ç†å‘˜æ§åˆ¶é¢æ¿</h3><p>æ•°æ®æ°¸ä¹…ä¿å­˜åœ¨è…¾è®¯äº‘ï¼Œæ”¯æŒé«˜æ•ˆå­˜å‚¨å’Œç¼“å­˜æœºåˆ¶</p></div>', unsafe_allow_html=True)
    
    try:
        with st.spinner("åŠ è½½æ•°æ®ç»Ÿè®¡..."):
            permissions_data = load_permissions_from_cos(cos_client, bucket_name, permissions_file)
            store_list = get_store_list_from_cos(cos_client, bucket_name)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            perms_count = len(permissions_data) if permissions_data is not None else 0
            st.metric("æƒé™è¡¨ç”¨æˆ·æ•°", perms_count)
        with col2:
            reports_count = len(store_list)
            st.metric("æŠ¥è¡¨é—¨åº—æ•°", reports_count)
        with col3:
            cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
            st.metric("ç¼“å­˜é¡¹ç›®æ•°", cache_count)
            
        # æ•°æ®é¢„è§ˆ
        if permissions_data is not None and len(permissions_data) > 0:
            st.subheader("ğŸ‘¥ æƒé™æ•°æ®é¢„è§ˆ")
            st.dataframe(permissions_data.head(10), use_container_width=True)
        
        if store_list:
            st.subheader("ğŸ“Š é—¨åº—åˆ—è¡¨é¢„è§ˆ")
            st.write(f"å…±æœ‰ {len(store_list)} ä¸ªé—¨åº—")
            
            # æ˜¾ç¤ºå‰10ä¸ªé—¨åº—
            display_stores = store_list[:10]
            for i in range(0, len(display_stores), 5):
                cols = st.columns(5)
                for j, store in enumerate(display_stores[i:i+5]):
                    with cols[j]:
                        st.info(f"ğŸª {store}")
            
            if len(store_list) > 10:
                st.caption(f"...ä»¥åŠå…¶ä»– {len(store_list) - 10} ä¸ªé—¨åº—")
                    
    except Exception as e:
        show_status_message(f"âŒ æ•°æ®åŠ è½½å¤±è´¥ï¼š{str(e)}", "error")

elif user_type == "ç®¡ç†å‘˜" and not st.session_state.is_admin:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ç®¡ç†å‘˜å¯†ç ")

else:
    if not st.session_state.logged_in:
        st.subheader("ğŸ” ç”¨æˆ·ç™»å½•")
        
        try:
            with st.spinner("åŠ è½½æƒé™æ•°æ®..."):
                permissions_data = load_permissions_from_cos(cos_client, bucket_name, permissions_file)
            
            if permissions_data is None:
                st.warning("âš ï¸ ç³»ç»Ÿç»´æŠ¤ä¸­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            else:
                stores = sorted(permissions_data[permissions_data.columns[0]].unique().tolist())
                
                with st.form("login_form"):
                    selected_store = st.selectbox("é€‰æ‹©é—¨åº—", stores)
                    user_id = st.text_input("äººå‘˜ç¼–å·")
                    submit = st.form_submit_button("ğŸš€ ç™»å½•")
                    
                    if submit and selected_store and user_id:
                        if verify_user_permission(selected_store, user_id, permissions_data):
                            st.session_state.logged_in = True
                            st.session_state.store_name = selected_store
                            st.session_state.user_id = user_id
                            show_status_message("âœ… ç™»å½•æˆåŠŸï¼", "success")
                            st.balloons()
                            st.rerun()
                        else:
                            show_status_message("âŒ é—¨åº—æˆ–ç¼–å·é”™è¯¯ï¼", "error")
                            
        except Exception as e:
            show_status_message(f"âŒ æƒé™éªŒè¯å¤±è´¥ï¼š{str(e)}", "error")
    
    else:
        # å·²ç™»å½• - æ˜¾ç¤ºæŠ¥è¡¨
        st.markdown(f'<div class="store-info"><h3>ğŸª {st.session_state.store_name}</h3><p>æ“ä½œå‘˜ï¼š{st.session_state.user_id}</p></div>', unsafe_allow_html=True)
        
        try:
            with st.spinner("åŠ è½½é—¨åº—åˆ—è¡¨..."):
                store_list = get_store_list_from_cos(cos_client, bucket_name)
                matching_stores = find_matching_stores(st.session_state.store_name, store_list)
            
            if matching_stores:
                if len(matching_stores) > 1:
                    selected_store = st.selectbox("é€‰æ‹©æŠ¥è¡¨", matching_stores)
                else:
                    selected_store = matching_stores[0]
                
                # æŒ‰éœ€åŠ è½½é€‰å®šé—¨åº—çš„æŠ¥è¡¨æ•°æ®
                with st.spinner(f"åŠ è½½ {selected_store} çš„æŠ¥è¡¨æ•°æ®..."):
                    df = get_single_report_from_cos(cos_client, bucket_name, selected_store)
                
                if df is not None:
                    # åº”æ”¶-æœªæ”¶é¢çœ‹æ¿
                    st.subheader("ğŸ’° åº”æ”¶-æœªæ”¶é¢")
                    
                    try:
                        analysis_results = analyze_receivable_data(df)
                        
                        if 'åº”æ”¶-æœªæ”¶é¢' in analysis_results:
                            data = analysis_results['åº”æ”¶-æœªæ”¶é¢']
                            amount = data['amount']
                            
                            col1, col2, col3 = st.columns([1, 2, 1])
                            with col2:
                                if amount > 0:
                                    st.markdown(f'''
                                        <div class="receivable-positive">
                                            <h1 style="margin: 0; font-size: 3rem;">ğŸ’³ Â¥{amount:,.2f}</h1>
                                            <h3 style="margin: 0.5rem 0;">é—¨åº—åº”ä»˜æ¬¾</h3>
                                            <p style="margin: 0; font-size: 0.9rem;">æ•°æ®æ¥æº: {data['row_name']} (ç¬¬{data['actual_row_number']}è¡Œ)</p>
                                        </div>
                                    ''', unsafe_allow_html=True)
                                
                                elif amount < 0:
                                    st.markdown(f'''
                                        <div class="receivable-negative">
                                            <h1 style="margin: 0; font-size: 3rem;">ğŸ’š Â¥{abs(amount):,.2f}</h1>
                                            <h3 style="margin: 0.5rem 0;">æ€»éƒ¨åº”é€€æ¬¾</h3>
                                            <p style="margin: 0; font-size: 0.9rem;">æ•°æ®æ¥æº: {data['row_name']} (ç¬¬{data['actual_row_number']}è¡Œ)</p>
                                        </div>
                                    ''', unsafe_allow_html=True)
                                
                                else:
                                    st.markdown('''
                                        <div style="background: #e8f5e8; color: #2e7d32; padding: 2rem; border-radius: 15px; text-align: center;">
                                            <h1 style="margin: 0; font-size: 3rem;">âš–ï¸ Â¥0.00</h1>
                                            <h3 style="margin: 0.5rem 0;">æ”¶æ”¯å¹³è¡¡</h3>
                                            <p style="margin: 0;">åº”æ”¶æœªæ”¶é¢ä¸ºé›¶ï¼Œè´¦ç›®å¹³è¡¡</p>
                                        </div>
                                    ''', unsafe_allow_html=True)
                        
                        else:
                            st.warning("âš ï¸ æœªæ‰¾åˆ°åº”æ”¶-æœªæ”¶é¢æ•°æ®")
                            
                            with st.expander("ğŸ” æŸ¥çœ‹è¯¦æƒ…", expanded=False):
                                debug_info = analysis_results.get('debug_info', {})
                                
                                st.markdown("### ğŸ“‹ æ•°æ®æŸ¥æ‰¾è¯´æ˜")
                                st.write(f"- **æŠ¥è¡¨æ€»è¡Œæ•°ï¼š** {debug_info.get('total_rows', 0)} è¡Œ")
                                
                                if debug_info.get('checked_row_69'):
                                    st.write(f"- **ç¬¬69è¡Œå†…å®¹ï¼š** {debug_info.get('row_69_content', 'N/A')}")
                                else:
                                    st.write("- **ç¬¬69è¡Œï¼š** æŠ¥è¡¨è¡Œæ•°ä¸è¶³69è¡Œ")
                                
                                st.markdown("""
                                ### ğŸ’¡ å¯èƒ½çš„åŸå› 
                                1. ç¬¬69è¡Œä¸åŒ…å«"åº”æ”¶-æœªæ”¶é¢"ç›¸å…³å…³é”®è¯
                                2. ç¬¬69è¡Œçš„æ•°å€¼ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®
                                3. æŠ¥è¡¨æ ¼å¼ä¸é¢„æœŸä¸ç¬¦
                                
                                ### ğŸ› ï¸ å»ºè®®
                                - è¯·æ£€æŸ¥ExcelæŠ¥è¡¨ç¬¬69è¡Œæ˜¯å¦åŒ…å«"åº”æ”¶-æœªæ”¶é¢"
                                - ç¡®è®¤è¯¥è¡Œæœ‰å¯¹åº”çš„é‡‘é¢æ•°æ®
                                - å¦‚éœ€è°ƒæ•´æŸ¥æ‰¾ä½ç½®ï¼Œè¯·è”ç³»æŠ€æœ¯æ”¯æŒ
                                """)
                    
                    except Exception as e:
                        show_status_message(f"âŒ åˆ†ææ•°æ®æ—¶å‡ºé”™ï¼š{str(e)}", "error")
                    
                    st.divider()
                    
                    # å®Œæ•´æŠ¥è¡¨æ•°æ®
                    st.subheader("ğŸ“‹ å®Œæ•´æŠ¥è¡¨æ•°æ®")
                    
                    search_term = st.text_input("ğŸ” æœç´¢æŠ¥è¡¨å†…å®¹")
                    
                    try:
                        if search_term:
                            search_df = df.copy()
                            for col in search_df.columns:
                                search_df[col] = search_df[col].astype(str).fillna('')
                            
                            mask = search_df.apply(
                                lambda x: x.str.contains(search_term, case=False, na=False, regex=False)
                            ).any(axis=1)
                            filtered_df = df[mask]
                            st.info(f"æ‰¾åˆ° {len(filtered_df)} æ¡åŒ…å« '{search_term}' çš„è®°å½•")
                        else:
                            filtered_df = df
                        
                        st.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡ï¼šå…± {len(filtered_df)} æ¡è®°å½•ï¼Œ{len(df.columns)} åˆ—")
                        
                        if len(filtered_df) > 0:
                            display_df = filtered_df.copy()
                            
                            # ç¡®ä¿åˆ—åå”¯ä¸€
                            unique_columns = []
                            for i, col in enumerate(display_df.columns):
                                col_name = str(col)
                                if col_name in unique_columns:
                                    col_name = f"{col_name}_{i}"
                                unique_columns.append(col_name)
                            display_df.columns = unique_columns
                            
                            # æ¸…ç†æ•°æ®å†…å®¹
                            for col in display_df.columns:
                                display_df[col] = display_df[col].astype(str).fillna('')
                            
                            st.dataframe(display_df, use_container_width=True, height=400)
                        
                        else:
                            st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®")
                            
                    except Exception as e:
                        show_status_message(f"âŒ æ•°æ®å¤„ç†æ—¶å‡ºé”™ï¼š{str(e)}", "error")
                    
                    # ä¸‹è½½åŠŸèƒ½
                    st.subheader("ğŸ“¥ æ•°æ®ä¸‹è½½")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        try:
                            buffer = io.BytesIO()
                            download_df = df.copy()
                            
                            # ç¡®ä¿åˆ—åå”¯ä¸€
                            unique_cols = []
                            for i, col in enumerate(download_df.columns):
                                col_name = str(col)
                                if col_name in unique_cols:
                                    col_name = f"{col_name}_{i}"
                                unique_cols.append(col_name)
                            download_df.columns = unique_cols
                            
                            with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
                                download_df.to_excel(writer, index=False)
                            
                            st.download_button(
                                "ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥è¡¨ (Excel)",
                                buffer.getvalue(),
                                f"{st.session_state.store_name}_æŠ¥è¡¨_{datetime.now().strftime('%Y%m%d')}.xlsx",
                                "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                        except Exception as e:
                            show_status_message(f"Excelä¸‹è½½å‡†å¤‡å¤±è´¥ï¼š{str(e)}", "error")
                    
                    with col2:
                        try:
                            csv_df = df.copy()
                            unique_cols = []
                            for i, col in enumerate(csv_df.columns):
                                col_name = str(col)
                                if col_name in unique_cols:
                                    col_name = f"{col_name}_{i}"
                                unique_cols.append(col_name)
                            csv_df.columns = unique_cols
                            
                            csv = csv_df.to_csv(index=False, encoding='utf-8-sig')
                            st.download_button(
                                "ğŸ“¥ ä¸‹è½½CSVæ ¼å¼",
                                csv,
                                f"{st.session_state.store_name}_æŠ¥è¡¨_{datetime.now().strftime('%Y%m%d')}.csv",
                                "text/csv"
                            )
                        except Exception as e:
                            show_status_message(f"CSVä¸‹è½½å‡†å¤‡å¤±è´¥ï¼š{str(e)}", "error")
                
                else:
                    st.error(f"âŒ æ— æ³•åŠ è½½é—¨åº— '{selected_store}' çš„æŠ¥è¡¨æ•°æ®")
                
            else:
                st.error(f"âŒ æœªæ‰¾åˆ°é—¨åº— '{st.session_state.store_name}' çš„æŠ¥è¡¨")
                
        except Exception as e:
            show_status_message(f"âŒ æŠ¥è¡¨åŠ è½½å¤±è´¥ï¼š{str(e)}", "error")

# é¡µé¢åº•éƒ¨çŠ¶æ€ä¿¡æ¯
st.divider()
col1, col2, col3 = st.columns(3)
with col1:
    st.caption(f"ğŸ•’ å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
with col2:
    cache_count = len([key for key in st.session_state.keys() if key.startswith('cache_')])
    st.caption(f"ğŸ’¾ ç¼“å­˜é¡¹ç›®: {cache_count}")
with col3:
    st.caption("ğŸ”§ ç‰ˆæœ¬: v3.1 (è…¾è®¯äº‘ä¼˜åŒ–ç‰ˆ)")
