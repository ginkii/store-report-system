import pandas as pd
import pymongo
from pymongo import MongoClient
import streamlit as st
from datetime import datetime
import json
import re
from typing import Dict, List, Tuple
import hashlib
import time

class BulkReportUploader:
    def __init__(self, mongo_uri: str = None, db_name: str = None):
        """åˆå§‹åŒ–æ‰¹é‡ä¸Šä¼ å™¨"""
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œç„¶åä½¿ç”¨Streamlit secretsï¼Œæœ€åä½¿ç”¨é»˜è®¤å€¼
        if mongo_uri is None:
            if hasattr(st, 'secrets') and 'mongodb' in st.secrets:
                mongo_uri = st.secrets["mongodb"]["uri"]
            else:
                mongo_uri = os.getenv('MONGODB_URI', 'mongodb://localhost:27017/')
        
        if db_name is None:
            if hasattr(st, 'secrets') and 'mongodb' in st.secrets:
                db_name = st.secrets["mongodb"]["database_name"]
            else:
                db_name = os.getenv('DATABASE_NAME', 'store_reports')
        
        self.client = MongoClient(mongo_uri)
        self.db = self.client[db_name]
        self.stores_collection = self.db['stores']
        self.reports_collection = self.db['reports']
        
        # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
        self._create_indexes()
    
    def _create_indexes(self):
        """åˆ›å»ºæ•°æ®åº“ç´¢å¼•"""
        try:
            # é—¨åº—é›†åˆç´¢å¼•
            self.stores_collection.create_index([("store_code", 1)], unique=True)
            self.stores_collection.create_index([("store_name", 1)])
            
            # æŠ¥è¡¨é›†åˆç´¢å¼•
            self.reports_collection.create_index([
                ("store_id", 1), 
                ("report_month", -1)
            ])
            self.reports_collection.create_index([("store_code", 1)])
            self.reports_collection.create_index([("report_month", -1)])
        except Exception as e:
            print(f"åˆ›å»ºç´¢å¼•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def normalize_store_name(self, sheet_name: str) -> str:
        """æ ‡å‡†åŒ–é—¨åº—åç§°ï¼Œå»é™¤ç‰¹æ®Šå­—ç¬¦å’Œç©ºæ ¼"""
        # ç§»é™¤å¸¸è§çš„å‰ç¼€å’Œåç¼€
        name = sheet_name.strip()
        name = re.sub(r'^(çŠ€ç‰›ç™¾è´§|é—¨åº—|åº—é“º)[\(ï¼ˆ]?', '', name)
        name = re.sub(r'[\)ï¼‰]?åº—?$', '', name)
        name = re.sub(r'\s+', '', name)  # ç§»é™¤æ‰€æœ‰ç©ºæ ¼
        return name
    
    def find_store_by_name(self, sheet_name: str) -> Dict:
        """é€šè¿‡sheetåç§°æŸ¥æ‰¾é—¨åº—"""
        normalized_name = self.normalize_store_name(sheet_name)
        
        # å°è¯•å¤šç§åŒ¹é…æ–¹å¼
        search_patterns = [
            sheet_name,  # å®Œå…¨åŒ¹é…
            normalized_name,  # æ ‡å‡†åŒ–ååŒ¹é…
            f".*{normalized_name}.*",  # åŒ…å«åŒ¹é…
            f".*{sheet_name}.*"  # åŸååŒ…å«åŒ¹é…
        ]
        
        for pattern in search_patterns:
            store = self.stores_collection.find_one({
                "$or": [
                    {"store_name": {"$regex": pattern, "$options": "i"}},
                    {"store_code": {"$regex": pattern, "$options": "i"}},
                    {"aliases": {"$regex": pattern, "$options": "i"}}
                ]
            })
            if store:
                return store
        
        return None
    
    def process_excel_file(self, file_buffer, report_month: str, progress_callback=None) -> Dict:
        """å¤„ç†Excelæ–‡ä»¶å¹¶ä¸Šä¼ æŠ¥è¡¨æ•°æ®"""
        start_time = time.time()
        result = {
            'success_count': 0,
            'failed_count': 0,
            'errors': [],
            'processed_stores': [],
            'unmatched_sheets': [],
            'total_time': 0
        }
        
        try:
            # è¯»å–æ‰€æœ‰sheet
            if progress_callback:
                progress_callback(10, "æ­£åœ¨è¯»å–Excelæ–‡ä»¶...")
            
            excel_data = pd.read_excel(file_buffer, sheet_name=None, engine='openpyxl')
            total_sheets = len(excel_data)
            
            if progress_callback:
                progress_callback(20, f"å‘ç° {total_sheets} ä¸ªå·¥ä½œè¡¨ï¼Œå¼€å§‹å¤„ç†...")
            
            processed = 0
            
            for sheet_name, df in excel_data.items():
                try:
                    # æ›´æ–°è¿›åº¦
                    processed += 1
                    progress = 20 + (processed / total_sheets) * 70
                    if progress_callback:
                        progress_callback(progress, f"æ­£åœ¨å¤„ç†: {sheet_name}")
                    
                    # æŸ¥æ‰¾å¯¹åº”é—¨åº—
                    store = self.find_store_by_name(sheet_name)
                    
                    if not store:
                        result['unmatched_sheets'].append(sheet_name)
                        result['failed_count'] += 1
                        continue
                    
                    # å¤„ç†æŠ¥è¡¨æ•°æ®
                    report_data = self._process_sheet_data(df, store, report_month, sheet_name)
                    
                    if report_data:
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæœˆä»½çš„æŠ¥è¡¨
                        existing_report = self.reports_collection.find_one({
                            'store_id': store['_id'],
                            'report_month': report_month
                        })
                        
                        if existing_report:
                            # æ›´æ–°ç°æœ‰æŠ¥è¡¨
                            self.reports_collection.replace_one(
                                {'_id': existing_report['_id']},
                                report_data
                            )
                        else:
                            # æ’å…¥æ–°æŠ¥è¡¨
                            self.reports_collection.insert_one(report_data)
                        
                        result['success_count'] += 1
                        result['processed_stores'].append({
                            'sheet_name': sheet_name,
                            'store_name': store['store_name'],
                            'store_code': store['store_code']
                        })
                    else:
                        result['failed_count'] += 1
                        result['errors'].append(f"{sheet_name}: æ•°æ®å¤„ç†å¤±è´¥")
                
                except Exception as e:
                    result['failed_count'] += 1
                    result['errors'].append(f"{sheet_name}: {str(e)}")
            
            if progress_callback:
                progress_callback(100, "ä¸Šä¼ å®Œæˆï¼")
            
        except Exception as e:
            result['errors'].append(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        
        result['total_time'] = time.time() - start_time
        return result
    
    def _process_sheet_data(self, df: pd.DataFrame, store: Dict, report_month: str, sheet_name: str) -> Dict:
        """å¤„ç†å•ä¸ªå·¥ä½œè¡¨çš„æ•°æ®"""
        try:
            # æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
            df = df.dropna(how='all').dropna(axis=1, how='all')
            
            if df.empty:
                return None
            
            # æ„å»ºæŠ¥è¡¨æ•°æ®ç»“æ„
            report_data = {
                'store_id': store['_id'],
                'store_code': store['store_code'],
                'store_name': store['store_name'],
                'report_month': report_month,
                'sheet_name': sheet_name,
                'financial_data': {},
                'uploaded_at': datetime.now(),
                'uploaded_by': 'bulk_upload'
            }
            
            # è§£æè´¢åŠ¡æ•°æ® - æ ¹æ®å®é™…Excelæ ¼å¼è°ƒæ•´
            financial_data = self._extract_financial_data(df)
            report_data['financial_data'] = financial_data
            
            return report_data
            
        except Exception as e:
            print(f"å¤„ç†sheet {sheet_name} æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def _extract_financial_data(self, df: pd.DataFrame) -> Dict:
        """ä»DataFrameä¸­æå–è´¢åŠ¡æ•°æ®"""
        financial_data = {
            'revenue': {},
            'cost': {},
            'profit': {},
            'receivables': {},  # åº”æ”¶è´¦æ¬¾ç›¸å…³
            'other_metrics': {}
        }
        
        try:
            # æå–ç¬¬82è¡Œåˆè®¡åˆ—çš„åº”æ”¶æœªæ”¶é‡‘é¢
            row_82_value = None
            if len(df) >= 82:  # ç¡®ä¿æœ‰ç¬¬82è¡Œ
                # æŸ¥æ‰¾"åˆè®¡"åˆ—
                total_col_idx = None
                for col_idx, col_name in enumerate(df.columns):
                    if 'åˆè®¡' in str(col_name) or 'total' in str(col_name).lower():
                        total_col_idx = col_idx
                        break
                
                # å¦‚æœæ‰¾åˆ°åˆè®¡åˆ—ï¼Œæå–ç¬¬82è¡Œçš„å€¼
                if total_col_idx is not None and len(df) > 81:  # ç¬¬82è¡Œçš„ç´¢å¼•æ˜¯81
                    try:
                        row_82_value = float(df.iloc[81, total_col_idx])
                        financial_data['receivables']['net_amount'] = row_82_value
                        financial_data['other_metrics']['ç¬¬82è¡Œåˆè®¡'] = row_82_value
                    except (ValueError, TypeError, IndexError):
                        pass
            
            # éå†æ‰€æœ‰æ•°æ®æå–å…¶ä»–è´¢åŠ¡æŒ‡æ ‡
            for idx, row in df.iterrows():
                if len(row) < 2:
                    continue
                
                metric_name = str(row.iloc[0]).strip() if pd.notna(row.iloc[0]) else ""
                
                # å°è¯•ä»ä¸åŒåˆ—è·å–æ•°å€¼
                value = None
                for col_idx in range(1, len(row)):
                    try:
                        if pd.notna(row.iloc[col_idx]):
                            value = float(row.iloc[col_idx])
                            break
                    except (ValueError, TypeError):
                        continue
                
                if value is None:
                    value = 0
                
                # æ ¹æ®æŒ‡æ ‡åç§°åˆ†ç±»
                if any(keyword in metric_name for keyword in ['æ”¶å…¥', 'è¥æ”¶', 'é”€å”®é¢', 'è¥ä¸šæ”¶å…¥']):
                    if 'çº¿ä¸Š' in metric_name or 'ç½‘ä¸Š' in metric_name:
                        financial_data['revenue']['online_revenue'] = value
                    elif 'çº¿ä¸‹' in metric_name or 'é—¨åº—' in metric_name:
                        financial_data['revenue']['offline_revenue'] = value
                    elif 'æ€»' in metric_name or 'åˆè®¡' in metric_name:
                        financial_data['revenue']['total_revenue'] = value
                    else:
                        financial_data['revenue']['total_revenue'] = value
                
                elif any(keyword in metric_name for keyword in ['æˆæœ¬', 'è´¹ç”¨', 'æ”¯å‡º']):
                    if 'å•†å“' in metric_name or 'è´§ç‰©' in metric_name:
                        financial_data['cost']['product_cost'] = value
                    elif 'ç§Ÿé‡‘' in metric_name or 'æˆ¿ç§Ÿ' in metric_name:
                        financial_data['cost']['rent_cost'] = value
                    elif 'äººå·¥' in metric_name or 'å·¥èµ„' in metric_name or 'è–ªé…¬' in metric_name:
                        financial_data['cost']['labor_cost'] = value
                    elif 'æ€»' in metric_name or 'åˆè®¡' in metric_name:
                        financial_data['cost']['total_cost'] = value
                    else:
                        financial_data['cost']['other_cost'] = value
                
                elif any(keyword in metric_name for keyword in ['åˆ©æ¶¦', 'ç›ˆåˆ©', 'å‡€åˆ©', 'æ¯›åˆ©']):
                    if 'æ¯›åˆ©' in metric_name:
                        financial_data['profit']['gross_profit'] = value
                    elif 'å‡€åˆ©' in metric_name:
                        financial_data['profit']['net_profit'] = value
                    else:
                        financial_data['profit']['total_profit'] = value
                
                elif any(keyword in metric_name for keyword in ['åº”æ”¶', 'æœªæ”¶', 'æ¬ æ¬¾', 'åº”ä»˜', 'å¾…ä»˜']):
                    if 'åº”æ”¶' in metric_name:
                        financial_data['receivables']['accounts_receivable'] = value
                    elif 'æœªæ”¶' in metric_name:
                        financial_data['receivables']['uncollected_amount'] = value
                    elif 'é€¾æœŸ' in metric_name:
                        financial_data['receivables']['overdue_amount'] = value
                    elif 'åº”ä»˜' in metric_name:
                        financial_data['receivables']['accounts_payable'] = value
                
                # å­˜å‚¨æ‰€æœ‰æŒ‡æ ‡åˆ°other_metricsç”¨äºè°ƒè¯•
                if metric_name:
                    financial_data['other_metrics'][f"{idx+1}è¡Œ_{metric_name}"] = value
            
            # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
            total_revenue = financial_data['revenue'].get('total_revenue', 0)
            if total_revenue == 0:
                total_revenue = (financial_data['revenue'].get('online_revenue', 0) + 
                               financial_data['revenue'].get('offline_revenue', 0))
                if total_revenue > 0:
                    financial_data['revenue']['total_revenue'] = total_revenue
            
            total_cost = financial_data['cost'].get('total_cost', 0)
            if total_cost == 0:
                total_cost = (financial_data['cost'].get('product_cost', 0) + 
                             financial_data['cost'].get('rent_cost', 0) + 
                             financial_data['cost'].get('labor_cost', 0) + 
                             financial_data['cost'].get('other_cost', 0))
                if total_cost > 0:
                    financial_data['cost']['total_cost'] = total_cost
            
            if total_revenue > 0 and total_cost > 0:
                financial_data['profit']['profit_margin'] = (total_revenue - total_cost) / total_revenue
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç¬¬82è¡Œçš„å€¼ï¼Œå°è¯•ä»å…¶ä»–æ–¹å¼è·å–åº”æ”¶æœªæ”¶é‡‘é¢
            if row_82_value is None:
                for key, value in financial_data['other_metrics'].items():
                    if ('82' in key and 'åˆè®¡' in key) or ('åº”æ”¶' in key and 'åˆè®¡' in key):
                        financial_data['receivables']['net_amount'] = value
                        break
            
        except Exception as e:
            print(f"æå–è´¢åŠ¡æ•°æ®æ—¶å‡ºé”™: {e}")
        
        return financial_data
    
    def add_store_with_aliases(self, store_data: Dict, aliases: List[str] = None) -> bool:
        """æ·»åŠ é—¨åº—ä¿¡æ¯ï¼ŒåŒ…å«åˆ«å"""
        try:
            if aliases:
                store_data['aliases'] = aliases
            
            result = self.stores_collection.insert_one(store_data)
            return True
        except Exception as e:
            print(f"æ·»åŠ é—¨åº—å¤±è´¥: {e}")
            return False
    
    def get_upload_statistics(self, report_month: str = None) -> Dict:
        """è·å–ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯"""
        try:
            pipeline = []
            
            if report_month:
                pipeline.append({'$match': {'report_month': report_month}})
            
            pipeline.extend([
                {
                    '$group': {
                        '_id': None,
                        'total_reports': {'$sum': 1},
                        'total_revenue': {'$sum': '$financial_data.revenue.total_revenue'},
                        'total_receivables': {'$sum': '$financial_data.receivables.accounts_receivable'},
                        'total_uncollected': {'$sum': '$financial_data.receivables.uncollected_amount'}
                    }
                }
            ])
            
            result = list(self.reports_collection.aggregate(pipeline))
            
            if result:
                return result[0]
            else:
                return {
                    'total_reports': 0,
                    'total_revenue': 0,
                    'total_receivables': 0,
                    'total_uncollected': 0
                }
        
        except Exception as e:
            print(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def close_connection(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.client.close()

# Streamlit ä¸Šä¼ ç•Œé¢
def create_upload_interface():
    """åˆ›å»ºä¸Šä¼ ç•Œé¢"""
    st.title("ğŸ“¤ æ‰¹é‡æŠ¥è¡¨ä¸Šä¼ ç³»ç»Ÿ")
    
    # åˆå§‹åŒ–ä¸Šä¼ å™¨
    uploader = BulkReportUploader()
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ä¸Šä¼ è®¾ç½®")
        
        # æœˆä»½é€‰æ‹©
        report_month = st.text_input(
            "æŠ¥è¡¨æœˆä»½",
            value=datetime.now().strftime("%Y-%m"),
            help="æ ¼å¼ï¼šYYYY-MMï¼Œä¾‹å¦‚ï¼š2024-08"
        )
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "é€‰æ‹©Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            help="é€‰æ‹©åŒ…å«æ‰€æœ‰é—¨åº—æŠ¥è¡¨çš„Excelæ–‡ä»¶ï¼Œæ¯ä¸ªå·¥ä½œè¡¨å¯¹åº”ä¸€ä¸ªé—¨åº—"
        )
        
        if uploaded_file and report_month:
            if st.button("å¼€å§‹ä¸Šä¼ ", type="primary", use_container_width=True):
                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_progress(progress, message):
                    progress_bar.progress(progress / 100)
                    status_text.text(message)
                
                # å¤„ç†æ–‡ä»¶
                with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶..."):
                    result = uploader.process_excel_file(
                        uploaded_file, 
                        report_month, 
                        progress_callback=update_progress
                    )
                
                # æ˜¾ç¤ºç»“æœ
                st.subheader("ğŸ“Š ä¸Šä¼ ç»“æœ")
                
                col_success, col_failed, col_time = st.columns(3)
                
                with col_success:
                    st.metric("æˆåŠŸä¸Šä¼ ", result['success_count'], delta=None)
                
                with col_failed:
                    st.metric("å¤±è´¥æ•°é‡", result['failed_count'], delta=None)
                
                with col_time:
                    st.metric("è€—æ—¶(ç§’)", f"{result['total_time']:.2f}", delta=None)
                
                # æˆåŠŸä¸Šä¼ çš„é—¨åº—åˆ—è¡¨
                if result['processed_stores']:
                    st.subheader("âœ… æˆåŠŸä¸Šä¼ çš„é—¨åº—")
                    success_df = pd.DataFrame(result['processed_stores'])
                    st.dataframe(success_df, use_container_width=True)
                
                # æœªåŒ¹é…çš„å·¥ä½œè¡¨
                if result['unmatched_sheets']:
                    st.subheader("âŒ æœªåŒ¹é…çš„å·¥ä½œè¡¨")
                    st.warning(f"ä»¥ä¸‹å·¥ä½œè¡¨æœªèƒ½åŒ¹é…åˆ°é—¨åº—ï¼š")
                    for sheet in result['unmatched_sheets']:
                        st.write(f"- {sheet}")
                
                # é”™è¯¯ä¿¡æ¯
                if result['errors']:
                    st.subheader("ğŸš¨ é”™è¯¯è¯¦æƒ…")
                    for error in result['errors']:
                        st.error(error)
                
                # æ¸…ç†è¿›åº¦æ¡
                progress_bar.empty()
                status_text.empty()
    
    with col2:
        st.subheader("ğŸ“ˆ ä¸Šä¼ ç»Ÿè®¡")
        
        # è·å–å½“å‰æœˆä»½ç»Ÿè®¡
        current_stats = uploader.get_upload_statistics(report_month)
        
        if current_stats:
            st.metric("æœ¬æœˆæŠ¥è¡¨æ•°", current_stats.get('total_reports', 0))
            st.metric("æ€»æ”¶å…¥", f"Â¥{current_stats.get('total_revenue', 0):,.2f}")
            st.metric("åº”æ”¶è´¦æ¬¾", f"Â¥{current_stats.get('total_receivables', 0):,.2f}")
            st.metric("æœªæ”¶é‡‘é¢", f"Â¥{current_stats.get('total_uncollected', 0):,.2f}")
        
        # é—¨åº—ç®¡ç†
        st.subheader("ğŸª é—¨åº—ç®¡ç†")
        if st.button("æŸ¥çœ‹é—¨åº—åˆ—è¡¨"):
            stores = list(uploader.stores_collection.find({}, {'password': 0}))
            if stores:
                stores_df = pd.DataFrame(stores)
                st.dataframe(stores_df[['store_name', 'store_code', 'region']], use_container_width=True)
            else:
                st.info("æš‚æ— é—¨åº—æ•°æ®")
    
    uploader.close_connection()

if __name__ == "__main__":
    create_upload_interface()