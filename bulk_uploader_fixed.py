# bulk_uploader_fixed.py - ä¿®å¤ç‰ˆæ‰¹é‡ä¸Šä¼ å™¨
import pandas as pd
import streamlit as st
from datetime import datetime
import time
import numpy as np
from typing import Dict, List, Tuple
from database_manager import get_database
from data_models import StoreModel, ReportModel
from config import ConfigManager

class BulkReportUploader:
    def __init__(self, db=None):
        """åˆå§‹åŒ–æ‰¹é‡ä¸Šä¼ å™¨ï¼ˆå…¼å®¹ç‰ˆæœ¬ï¼‰"""
        self.db = db or get_database()
        self.stores_collection = self.db['stores']
        self.reports_collection = self.db['reports']
        
        # åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        self._create_indexes()
    
    def _create_indexes(self):
        """åˆ›å»ºæ•°æ®åº“ç´¢å¼•"""
        try:
            # è¿™äº›ç´¢å¼•å¯èƒ½å·²ç»åœ¨database_managerä¸­åˆ›å»ºï¼Œè¿™é‡Œåšé˜²é‡å¤å¤„ç†
            try:
                self.stores_collection.create_index([("store_code", 1)], unique=True, background=True)
            except Exception:
                pass  # ç´¢å¼•å·²å­˜åœ¨
            
            try:
                self.stores_collection.create_index([("store_name", 1)], background=True)
            except Exception:
                pass
            
            try:
                self.reports_collection.create_index([
                    ("store_id", 1), 
                    ("report_month", -1)
                ], background=True)
            except Exception:
                pass
                
        except Exception as e:
            print(f"åˆ›å»ºç´¢å¼•æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    def normalize_store_name(self, sheet_name: str) -> str:
        """æ ‡å‡†åŒ–é—¨åº—åç§°ï¼Œå»é™¤ç‰¹æ®Šå­—ç¬¦å’Œç©ºæ ¼"""
        # ç§»é™¤å¸¸è§çš„å‰ç¼€å’Œåç¼€
        name = sheet_name.strip()
        name = name.replace('çŠ€ç‰›ç™¾è´§', '').replace('é—¨åº—', '').replace('åº—', '')
        name = name.replace('(', '').replace(')', '').replace('ï¼ˆ', '').replace('ï¼‰', '')
        name = ''.join(name.split())  # ç§»é™¤æ‰€æœ‰ç©ºæ ¼
        return name
    
    def find_or_create_store(self, sheet_name: str) -> Dict:
        """é€šè¿‡sheetåç§°æŸ¥æ‰¾é—¨åº—ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºï¼ˆå…¼å®¹ç‰ˆæœ¬ï¼‰"""
        normalized_name = self.normalize_store_name(sheet_name)
        
        # é¦–å…ˆå°è¯•æŸ¥æ‰¾ç°æœ‰é—¨åº—
        search_patterns = [
            {"store_name": sheet_name},  # å®Œå…¨åŒ¹é…
            {"store_name": {"$regex": normalized_name, "$options": "i"}},  # æ ‡å‡†åŒ–ååŒ¹é…
            {"store_code": {"$regex": normalized_name, "$options": "i"}},  # ä»£ç åŒ¹é…
            {"aliases": {"$in": [sheet_name, normalized_name]}},  # åˆ«ååŒ¹é…
        ]
        
        for pattern in search_patterns:
            store = self.stores_collection.find_one(pattern)
            if store:
                return store
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œåˆ›å»ºæ–°é—¨åº—
        return self._create_store_from_sheet_name(sheet_name)
    
    def _create_store_from_sheet_name(self, sheet_name: str) -> Dict:
        """ä»å·¥ä½œè¡¨åç§°åˆ›å»ºæ–°é—¨åº—ï¼ˆä½¿ç”¨ç»Ÿä¸€æ•°æ®æ¨¡å‹ï¼‰"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æ¨¡å‹åˆ›å»ºé—¨åº—
            store_data = StoreModel.create_store_document(
                store_name=sheet_name.strip(),
                aliases=[sheet_name.strip(), self.normalize_store_name(sheet_name)],
                created_by='bulk_upload'
            )
            
            # æ’å…¥åˆ°æ•°æ®åº“
            self.stores_collection.insert_one(store_data)
            return store_data
            
        except Exception as e:
            print(f"åˆ›å»ºé—¨åº—å¤±è´¥: {e}")
            return None
    
    def process_excel_file(self, file_buffer, report_month: str, progress_callback=None) -> Dict:
        """å¤„ç†Excelæ–‡ä»¶å¹¶ä¸Šä¼ æŠ¥è¡¨æ•°æ®ï¼ˆå…¼å®¹ç‰ˆæœ¬ï¼‰"""
        start_time = time.time()
        result = {
            'success_count': 0,
            'failed_count': 0,
            'errors': [],
            'processed_stores': [],
            'failed_stores': [],
            'total_time': 0
        }
        
        try:
            # è¯»å–æ‰€æœ‰sheet
            if progress_callback:
                progress_callback(10, "æ­£åœ¨è¯»å–Excelæ–‡ä»¶...")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
            file_buffer.seek(0, 2)
            file_size = file_buffer.tell()
            file_buffer.seek(0)
            
            if file_size > 50 * 1024 * 1024:  # 50MBé™åˆ¶
                result['errors'].append("æ–‡ä»¶è¿‡å¤§ï¼ˆè¶…è¿‡50MBï¼‰ï¼Œè¯·åˆ†æ‰¹ä¸Šä¼ ")
                return result
            
            excel_data = pd.read_excel(file_buffer, sheet_name=None, engine='openpyxl', header=None)
            total_sheets = len(excel_data)
            
            if total_sheets > 200:
                result['errors'].append(f"å·¥ä½œè¡¨æ•°é‡è¿‡å¤šï¼ˆ{total_sheets}ä¸ªï¼‰ï¼Œè¯·åˆ†æ‰¹ä¸Šä¼ ï¼ˆå»ºè®®æ¯æ¬¡ä¸è¶…è¿‡200ä¸ªï¼‰")
                return result
            
            if progress_callback:
                progress_callback(20, f"å‘ç° {total_sheets} ä¸ªå·¥ä½œè¡¨ï¼Œå¼€å§‹å¤„ç†...")
            
            processed = 0
            
            for sheet_name, df in excel_data.items():
                try:
                    # æ›´æ–°è¿›åº¦
                    processed += 1
                    progress = 20 + (processed / total_sheets) * 70
                    if progress_callback:
                        progress_callback(progress, f"æ­£åœ¨å¤„ç†: {sheet_name}")
                    
                    # æŸ¥æ‰¾æˆ–åˆ›å»ºå¯¹åº”é—¨åº—
                    store = self.find_or_create_store(sheet_name)
                    
                    if not store:
                        result['failed_stores'].append({
                            'store_name': sheet_name,
                            'reason': 'æ— æ³•åˆ›å»ºé—¨åº—è®°å½•'
                        })
                        result['failed_count'] += 1
                        result['errors'].append(f"{sheet_name}: æ— æ³•åˆ›å»ºé—¨åº—è®°å½•")
                        continue
                    
                    # å¤„ç†æŠ¥è¡¨æ•°æ®
                    report_data = self._process_sheet_data(df, store, report_month, sheet_name)
                    
                    if report_data:
                        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæœˆä»½çš„æŠ¥è¡¨
                        existing_report = self.reports_collection.find_one({
                            'store_id': store['_id'],
                            'report_month': report_month
                        })
                        
                        if existing_report:
                            # æ›´æ–°ç°æœ‰æŠ¥è¡¨
                            self.reports_collection.replace_one(
                                {'_id': existing_report['_id']},
                                report_data
                            )
                        else:
                            # æ’å…¥æ–°æŠ¥è¡¨
                            self.reports_collection.insert_one(report_data)
                        
                        result['success_count'] += 1
                        result['processed_stores'].append({
                            'sheet_name': sheet_name,
                            'store_name': store['store_name'],
                            'store_code': store['store_code']
                        })
                    else:
                        result['failed_stores'].append({
                            'store_name': sheet_name,
                            'reason': 'æ•°æ®å¤„ç†å¤±è´¥'
                        })
                        result['failed_count'] += 1
                        result['errors'].append(f"{sheet_name}: æ•°æ®å¤„ç†å¤±è´¥")
                
                except Exception as e:
                    result['failed_stores'].append({
                        'store_name': sheet_name,
                        'reason': f"å¤„ç†é”™è¯¯: {str(e)}"
                    })
                    result['failed_count'] += 1
                    result['errors'].append(f"{sheet_name}: {str(e)}")
            
            if progress_callback:
                progress_callback(100, "ä¸Šä¼ å®Œæˆï¼")
            
        except Exception as e:
            result['errors'].append(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
        
        result['total_time'] = time.time() - start_time
        return result
    
    def _process_sheet_data(self, df: pd.DataFrame, store: Dict, report_month: str, sheet_name: str) -> Dict:
        """å¤„ç†å•ä¸ªå·¥ä½œè¡¨çš„æ•°æ®ï¼ˆå…¼å®¹ç‰ˆæœ¬ï¼‰"""
        try:
            # æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç† - ä¿ç•™æ‰€æœ‰è¡Œï¼Œåªåˆ é™¤å®Œå…¨ç©ºçš„åˆ—
            df_cleaned = df.dropna(axis=1, how='all')
            
            if df_cleaned.empty:
                return None
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æ¨¡å‹å¤„ç†Excelæ•°æ®
            standardized_data = ReportModel._dataframe_to_standard_format(df_cleaned)
            
            # æå–è´¢åŠ¡æ•°æ®
            financial_data = self._extract_financial_data(df_cleaned)
            
            # ä½¿ç”¨ç»Ÿä¸€çš„æ•°æ®æ¨¡å‹åˆ›å»ºæŠ¥è¡¨æ–‡æ¡£
            report_data = ReportModel.create_report_document(
                store_data=store,
                report_month=report_month,
                excel_data=standardized_data,
                sheet_name=sheet_name,
                financial_data=financial_data,
                uploaded_by='bulk_upload'
            )
            
            return report_data
            
        except Exception as e:
            print(f"å¤„ç†sheet {sheet_name} æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def _extract_financial_data(self, df: pd.DataFrame) -> Dict:
        """ä»DataFrameä¸­æå–è´¢åŠ¡æ•°æ®"""
        financial_data = {
            'revenue': {},
            'cost': {},
            'profit': {},
            'receivables': {},
            'other_metrics': {}
        }
        
        try:
            # æå–ç¬¬41è¡Œç¬¬2ä¸ªåˆè®¡åˆ—çš„åº”æ”¶æœªæ”¶é‡‘é¢ï¼ˆé€‚åº”æ–°çš„æŸ¥æ‰¾é€»è¾‘ï¼‰
            row_41_value = None
            if len(df) >= 41:  # ç¡®ä¿æœ‰ç¬¬41è¡Œ
                target_row_index = 40  # ç¬¬41è¡Œçš„ç´¢å¼•æ˜¯40
                
                # æŸ¥æ‰¾"åˆè®¡"åˆ—
                total_col_indices = []
                for col_idx in range(len(df.columns)):
                    if len(df) > 0:  # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨å¤´è¡Œ
                        header_value = df.iloc[0, col_idx] if not pd.isna(df.iloc[0, col_idx]) else ""
                        if 'åˆè®¡' in str(header_value) or 'total' in str(header_value).lower():
                            total_col_indices.append(col_idx)
                
                # æ£€æŸ¥ç¬¬41è¡Œæ˜¯å¦åŒ…å«åº”æ”¶æœªæ”¶å…³é”®è¯
                if len(df) > target_row_index:
                    first_col_value = str(df.iloc[target_row_index, 0]) if not pd.isna(df.iloc[target_row_index, 0]) else ""
                    keywords = ['æ€»éƒ¨åº”æ”¶æœªæ”¶é‡‘é¢', 'åº”æ”¶æœªæ”¶é‡‘é¢', 'åº”æ”¶-æœªæ”¶é¢', 'åº”æ”¶æœªæ”¶é¢', 'åº”æ”¶-æœªæ”¶', 'åº”æ”¶æœªæ”¶']
                    
                    if any(keyword in first_col_value for keyword in keywords):
                        # ä½¿ç”¨ç¬¬2ä¸ªåˆè®¡åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                        target_col_idx = None
                        if len(total_col_indices) >= 2:
                            target_col_idx = total_col_indices[1]  # ç¬¬2ä¸ªåˆè®¡åˆ—
                        elif len(total_col_indices) == 1:
                            target_col_idx = total_col_indices[0]  # åªæœ‰1ä¸ªåˆè®¡åˆ—
                        
                        if target_col_idx is not None:
                            try:
                                row_41_value = float(df.iloc[target_row_index, target_col_idx])
                                financial_data['receivables']['net_amount'] = row_41_value
                                financial_data['other_metrics']['ç¬¬41è¡Œç¬¬2ä¸ªåˆè®¡åˆ—'] = row_41_value
                            except (ValueError, TypeError, IndexError):
                                pass
            
            # éå†æ‰€æœ‰æ•°æ®æå–å…¶ä»–è´¢åŠ¡æŒ‡æ ‡
            for idx, row in df.iterrows():
                if len(row) < 2:
                    continue
                
                metric_name = str(row.iloc[0]).strip() if pd.notna(row.iloc[0]) else ""
                
                # å°è¯•ä»ä¸åŒåˆ—è·å–æ•°å€¼
                value = None
                for col_idx in range(1, len(row)):
                    try:
                        if pd.notna(row.iloc[col_idx]):
                            value = float(row.iloc[col_idx])
                            break
                    except (ValueError, TypeError):
                        continue
                
                if value is None:
                    value = 0
                
                # æ ¹æ®æŒ‡æ ‡åç§°åˆ†ç±»
                if any(keyword in metric_name for keyword in ['æ”¶å…¥', 'è¥æ”¶', 'é”€å”®é¢', 'è¥ä¸šæ”¶å…¥']):
                    if 'çº¿ä¸Š' in metric_name or 'ç½‘ä¸Š' in metric_name:
                        financial_data['revenue']['online_revenue'] = value
                    elif 'çº¿ä¸‹' in metric_name or 'é—¨åº—' in metric_name:
                        financial_data['revenue']['offline_revenue'] = value
                    elif 'æ€»' in metric_name or 'åˆè®¡' in metric_name:
                        financial_data['revenue']['total_revenue'] = value
                    else:
                        financial_data['revenue']['total_revenue'] = value
                
                elif any(keyword in metric_name for keyword in ['æˆæœ¬', 'è´¹ç”¨', 'æ”¯å‡º']):
                    if 'å•†å“' in metric_name or 'è´§ç‰©' in metric_name:
                        financial_data['cost']['product_cost'] = value
                    elif 'ç§Ÿé‡‘' in metric_name or 'æˆ¿ç§Ÿ' in metric_name:
                        financial_data['cost']['rent_cost'] = value
                    elif 'äººå·¥' in metric_name or 'å·¥èµ„' in metric_name or 'è–ªé…¬' in metric_name:
                        financial_data['cost']['labor_cost'] = value
                    elif 'æ€»' in metric_name or 'åˆè®¡' in metric_name:
                        financial_data['cost']['total_cost'] = value
                    else:
                        financial_data['cost']['other_cost'] = value
                
                elif any(keyword in metric_name for keyword in ['åˆ©æ¶¦', 'ç›ˆåˆ©', 'å‡€åˆ©', 'æ¯›åˆ©']):
                    if 'æ¯›åˆ©' in metric_name:
                        financial_data['profit']['gross_profit'] = value
                    elif 'å‡€åˆ©' in metric_name:
                        financial_data['profit']['net_profit'] = value
                    else:
                        financial_data['profit']['total_profit'] = value
                
                elif any(keyword in metric_name for keyword in ['åº”æ”¶', 'æœªæ”¶', 'æ¬ æ¬¾', 'åº”ä»˜', 'å¾…ä»˜']):
                    if 'åº”æ”¶' in metric_name:
                        financial_data['receivables']['accounts_receivable'] = value
                    elif 'æœªæ”¶' in metric_name:
                        financial_data['receivables']['uncollected_amount'] = value
                    elif 'é€¾æœŸ' in metric_name:
                        financial_data['receivables']['overdue_amount'] = value
                    elif 'åº”ä»˜' in metric_name:
                        financial_data['receivables']['accounts_payable'] = value
                
                # å­˜å‚¨æ‰€æœ‰æŒ‡æ ‡åˆ°other_metricsç”¨äºè°ƒè¯•
                if metric_name:
                    financial_data['other_metrics'][f"{idx+1}è¡Œ_{metric_name}"] = value
            
            # è®¡ç®—æ´¾ç”ŸæŒ‡æ ‡
            total_revenue = financial_data['revenue'].get('total_revenue', 0)
            if total_revenue == 0:
                total_revenue = (financial_data['revenue'].get('online_revenue', 0) + 
                               financial_data['revenue'].get('offline_revenue', 0))
                if total_revenue > 0:
                    financial_data['revenue']['total_revenue'] = total_revenue
            
            total_cost = financial_data['cost'].get('total_cost', 0)
            if total_cost == 0:
                total_cost = (financial_data['cost'].get('product_cost', 0) + 
                             financial_data['cost'].get('rent_cost', 0) + 
                             financial_data['cost'].get('labor_cost', 0) + 
                             financial_data['cost'].get('other_cost', 0))
                if total_cost > 0:
                    financial_data['cost']['total_cost'] = total_cost
            
            if total_revenue > 0 and total_cost > 0:
                financial_data['profit']['profit_margin'] = (total_revenue - total_cost) / total_revenue
            
        except Exception as e:
            print(f"æå–è´¢åŠ¡æ•°æ®æ—¶å‡ºé”™: {e}")
        
        return financial_data
    
    def get_upload_statistics(self, report_month: str = None) -> Dict:
        """è·å–ä¸Šä¼ ç»Ÿè®¡ä¿¡æ¯"""
        try:
            pipeline = []
            
            if report_month:
                pipeline.append({'$match': {'report_month': report_month}})
            
            pipeline.extend([
                {
                    '$group': {
                        '_id': None,
                        'total_reports': {'$sum': 1},
                        'total_revenue': {'$sum': '$financial_data.revenue.total_revenue'},
                        'total_receivables': {'$sum': '$financial_data.receivables.accounts_receivable'},
                        'total_uncollected': {'$sum': '$financial_data.receivables.uncollected_amount'}
                    }
                }
            ])
            
            result = list(self.reports_collection.aggregate(pipeline))
            
            if result:
                return result[0]
            else:
                return {
                    'total_reports': 0,
                    'total_revenue': 0,
                    'total_receivables': 0,
                    'total_uncollected': 0
                }
        
        except Exception as e:
            print(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}

# ç®¡ç†å‘˜éªŒè¯
def verify_admin_password(password: str) -> bool:
    """éªŒè¯ç®¡ç†å‘˜å¯†ç """
    return password == ConfigManager.get_admin_password()

# Streamlit ä¸Šä¼ ç•Œé¢
def create_upload_interface():
    """åˆ›å»ºä¸Šä¼ ç•Œé¢"""
    st.title("ğŸ“¤ æ‰¹é‡æŠ¥è¡¨ä¸Šä¼ ç³»ç»Ÿ")
    
    # æ£€æŸ¥ç®¡ç†å‘˜ç™»å½•çŠ¶æ€
    if 'admin_authenticated_bulk' not in st.session_state:
        st.session_state.admin_authenticated_bulk = False
    
    if not st.session_state.admin_authenticated_bulk:
        # ç®¡ç†å‘˜ç™»å½•é¡µé¢
        st.subheader("ğŸ” ç®¡ç†å‘˜ç™»å½•")
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            admin_password = st.text_input(
                "ç®¡ç†å‘˜å¯†ç ", 
                type="password", 
                placeholder="è¯·è¾“å…¥ç®¡ç†å‘˜å¯†ç ",
                key="bulk_admin_password"
            )
            
            if st.button("ç™»å½•", use_container_width=True, key="bulk_admin_login"):
                if admin_password:
                    if verify_admin_password(admin_password):
                        st.session_state.admin_authenticated_bulk = True
                        st.success("ç®¡ç†å‘˜ç™»å½•æˆåŠŸï¼")
                        st.rerun()
                    else:
                        st.error("ç®¡ç†å‘˜å¯†ç é”™è¯¯")
                else:
                    st.warning("è¯·è¾“å…¥ç®¡ç†å‘˜å¯†ç ")
        return
    
    # åˆå§‹åŒ–ä¸Šä¼ å™¨
    db = get_database()
    uploader = BulkReportUploader(db)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ä¸Šä¼ è®¾ç½®")
        
        # æœˆä»½é€‰æ‹©
        report_month = st.text_input(
            "æŠ¥è¡¨æœˆä»½",
            value=datetime.now().strftime("%Y-%m"),
            help="æ ¼å¼ï¼šYYYY-MMï¼Œä¾‹å¦‚ï¼š2024-08"
        )
        
        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "é€‰æ‹©Excelæ–‡ä»¶",
            type=['xlsx', 'xls'],
            help="é€‰æ‹©åŒ…å«æ‰€æœ‰é—¨åº—æŠ¥è¡¨çš„Excelæ–‡ä»¶ï¼Œæ¯ä¸ªå·¥ä½œè¡¨å¯¹åº”ä¸€ä¸ªé—¨åº—"
        )
        
        if uploaded_file and report_month:
            if st.button("å¼€å§‹ä¸Šä¼ ", type="primary", use_container_width=True):
                # åˆ›å»ºè¿›åº¦æ¡
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def update_progress(progress, message):
                    progress_bar.progress(progress / 100)
                    status_text.text(message)
                
                # å¤„ç†æ–‡ä»¶
                with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶..."):
                    result = uploader.process_excel_file(
                        uploaded_file, 
                        report_month, 
                        progress_callback=update_progress
                    )
                
                # æ˜¾ç¤ºç»“æœ
                st.subheader("ğŸ“Š ä¸Šä¼ ç»“æœ")
                
                col_success, col_failed, col_time = st.columns(3)
                
                with col_success:
                    st.metric("æˆåŠŸä¸Šä¼ ", result['success_count'], delta=None)
                
                with col_failed:
                    st.metric("å¤±è´¥æ•°é‡", result['failed_count'], delta=None)
                
                with col_time:
                    st.metric("è€—æ—¶(ç§’)", f"{result['total_time']:.2f}", delta=None)
                
                # æˆåŠŸä¸Šä¼ çš„é—¨åº—åˆ—è¡¨
                if result['processed_stores']:
                    st.subheader("âœ… æˆåŠŸä¸Šä¼ çš„é—¨åº—")
                    success_df = pd.DataFrame(result['processed_stores'])
                    st.dataframe(success_df, use_container_width=True)
                
                # ä¸Šä¼ å¤±è´¥ä¿¡æ¯
                if result['failed_stores']:
                    st.subheader("âŒ ä¸Šä¼ å¤±è´¥")
                    st.error(f"å…± {result['failed_count']} ä¸ªé—¨åº—ä¸Šä¼ å¤±è´¥")
                    
                    # æ˜¾ç¤ºå¤±è´¥çš„é—¨åº—åˆ—è¡¨
                    failed_df = pd.DataFrame(result['failed_stores'])
                    st.dataframe(failed_df, use_container_width=True)
                
                # æ¸…ç†è¿›åº¦æ¡
                progress_bar.empty()
                status_text.empty()
    
    with col2:
        st.subheader("ğŸ“ˆ ä¸Šä¼ ç»Ÿè®¡")
        
        # è·å–å½“å‰æœˆä»½ç»Ÿè®¡
        current_stats = uploader.get_upload_statistics(report_month)
        
        if current_stats:
            st.metric("æœ¬æœˆæŠ¥è¡¨æ•°", current_stats.get('total_reports', 0))
            st.metric("æ€»æ”¶å…¥", f"Â¥{current_stats.get('total_revenue', 0):,.2f}")
            st.metric("åº”æ”¶è´¦æ¬¾", f"Â¥{current_stats.get('total_receivables', 0):,.2f}")
            st.metric("æœªæ”¶é‡‘é¢", f"Â¥{current_stats.get('total_uncollected', 0):,.2f}")
        
        # é—¨åº—ç®¡ç†
        st.subheader("ğŸª é—¨åº—ç®¡ç†")
        if st.button("æŸ¥çœ‹é—¨åº—åˆ—è¡¨"):
            stores = list(uploader.stores_collection.find({}, {'_id': 1, 'store_name': 1, 'store_code': 1, 'region': 1}))
            if stores:
                stores_df = pd.DataFrame(stores)
                st.dataframe(stores_df[['store_name', 'store_code', 'region']], use_container_width=True)
            else:
                st.info("æš‚æ— é—¨åº—æ•°æ®")
        
        # ç®¡ç†å‘˜é€€å‡ºç™»å½•
        st.markdown("---")
        if st.button("é€€å‡ºç®¡ç†å‘˜ç™»å½•", type="secondary"):
            st.session_state.admin_authenticated_bulk = False
            st.rerun()

if __name__ == "__main__":
    create_upload_interface()
